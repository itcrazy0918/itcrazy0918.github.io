<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="记录技术路上的点滴"><title>Kafka 源码解析之 Server 1+N+M 网络处理模型（一） | Steffen's Blog</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.3.1/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Kafka 源码解析之 Server 1+N+M 网络处理模型（一）</h1><a id="logo" href="/.">Steffen's Blog</a><p class="description">唐良运</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Kafka 源码解析之 Server 1+N+M 网络处理模型（一）</h1><div class="post-meta">Nov 24, 2018<span> | </span><span class="category"><a href="/categories/大数据/">大数据</a></span></div><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Kafka网络通信模型概述"><span class="toc-number">1.</span> <span class="toc-text">Kafka网络通信模型概述</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Kafka网络通信层的设计与具体实现"><span class="toc-number">2.</span> <span class="toc-text">Kafka网络通信层的设计与具体实现</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Server-网络模型整体流程"><span class="toc-number">2.1.</span> <span class="toc-text">Server 网络模型整体流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#SocketServer"><span class="toc-number">2.2.</span> <span class="toc-text">SocketServer</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#SocketServer-初始化"><span class="toc-number">2.2.1.</span> <span class="toc-text">SocketServer 初始化</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Acceptor"><span class="toc-number">2.3.</span> <span class="toc-text">Acceptor</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Processor"><span class="toc-number">2.4.</span> <span class="toc-text">Processor</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#configureNewConnections"><span class="toc-number">2.4.1.</span> <span class="toc-text">configureNewConnections</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#processNewResponses"><span class="toc-number">2.4.2.</span> <span class="toc-text">processNewResponses</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#processCompletedReceives"><span class="toc-number">2.4.3.</span> <span class="toc-text">processCompletedReceives</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#processCompletedSends"><span class="toc-number">2.4.4.</span> <span class="toc-text">processCompletedSends</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#KafkaRequestHandlerPool"><span class="toc-number">2.5.</span> <span class="toc-text">KafkaRequestHandlerPool</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#KafkaRequestHandler"><span class="toc-number">2.5.1.</span> <span class="toc-text">KafkaRequestHandler</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#KafkaApis"><span class="toc-number">2.6.</span> <span class="toc-text">KafkaApis</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Replication-Subsystem"><span class="toc-number">2.6.1.</span> <span class="toc-text">Replication Subsystem</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Log-Subsystem"><span class="toc-number">2.6.2.</span> <span class="toc-text">Log Subsystem</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#OffsetManager"><span class="toc-number">2.6.3.</span> <span class="toc-text">OffsetManager</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#TopicConfigManager"><span class="toc-number">2.6.4.</span> <span class="toc-text">TopicConfigManager</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#RequestChannel"><span class="toc-number">2.7.</span> <span class="toc-text">RequestChannel</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#参考"><span class="toc-number">3.</span> <span class="toc-text">参考</span></a></li></ol></div></div><div class="post-content"><p>开源分布式消息队列—Kafka，具备高吞吐量和高并发的特性，其网络通信层是如何做到消息的高效传输的呢？为了解开自己心中的疑虑，就查阅了Kafka的Network通信模块的源码，乘机会写本篇文章。<br> 本文主要通过对Kafka源码的分析来简述其Reactor的多线程网络通信模型和总体框架结构，同时简要介绍Kafka网络通信层的设计与具体实现。</p>
<h1 id="Kafka网络通信模型概述"><a href="#Kafka网络通信模型概述" class="headerlink" title="Kafka网络通信模型概述"></a>Kafka网络通信模型概述</h1><p>Kafka的网络通信模型是基于NIO的Reactor多线程模型来设计的。这里先引用Kafka源码中注释的一段话：</p>
<blockquote>
<p>An NIO socket server. The threading model is<br> <code>1 Acceptor thread</code> that handles new connections.<br> Acceptor has <code>N Processor threads</code> that each have their own selector and read requests from sockets.<br> <code>M Handler threads</code> that handle requests and produce responses back to the processor threads for writing.</p>
</blockquote>
<p>相信大家看了上面的这段引文注释后，大致可以了解到Kafka的网络通信层模型，主要采用了1（<code>1个Acceptor线程</code>）+N（<code>N个Processor线程</code>）+M（<code>M个业务处理线程</code>）。下面的表格简要的列举了下（这里先简单的看下后面还会详细说明）：</p>
<table>
<thead>
<tr>
<th style="text-align:center">线程数</th>
<th style="text-align:center">线程名</th>
<th style="text-align:center">线程具体说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">kafka-socket-acceptor_%x</td>
<td style="text-align:center">Acceptor线程，负责监听Client端发起的请求</td>
</tr>
<tr>
<td style="text-align:center">N</td>
<td style="text-align:center">kafka-network-thread_%d</td>
<td style="text-align:center">Processor线程，负责对Socket进行读写</td>
</tr>
<tr>
<td style="text-align:center">M</td>
<td style="text-align:center">kafka-request-handler-_%d</td>
<td style="text-align:center">Worker线程，处理具体的业务逻辑并生成Response返回</td>
</tr>
</tbody>
</table>
<p>Kafka网络通信层的完整框架图如下图所示：<br><img src="/2018/11/24/Kafka-源码解析之-Server-1-N-M-网络处理模型（一）/kafka-network.png" alt="Kafka Server 网络通信框架图"></p>
<p>刚开始看到上面的这个框架图可能会有一些不太理解，并不要紧，这里可以先对Kafka的网络通信层框架结构有一个大致了解。本文后面会结合Kafka的部分重要源码来详细阐述上面的过程。这里可以简单总结一下其网络通信模型中的几个重要概念：</p>
<ol>
<li><code>Acceptor</code>：1个接收线程，负责监听 Socket 新的连接请求，注册了 <code>OP_ACCEPT</code> 事件，将新的连接按照 round robin 方式交给对应的 Processor 线程处理；</li>
<li><code>Processor</code>：N个处理器线程，其中每个 Processor 都有自己的 selector，它会向 Acceptor 分配的 SocketChannel 注册相应的 OP_READ 事件，N 的大小由<code>num.networker.threads</code>决定；</li>
<li><code>KafkaRequestHandler</code>：M个请求处理线程，包含在线程池—KafkaRequestHandlerPool内部，从RequestChannel的全局请求队列—requestQueue中获取请求数据并交给KafkaApis处理，M的大小由<code>num.io.threads</code>决定；</li>
<li><code>RequestChannel</code>：其为Kafka服务端的请求通道，该数据结构中包含了一个全局的请求队列 requestQueue和多个与Processor处理器相对应的响应队列responseQueue，提供给Processor与请求处理线程KafkaRequestHandler和KafkaApis交换数据的地方。</li>
<li><code>NetworkClient</code>：其底层是对 Java NIO 进行相应的封装，位于Kafka的网络接口层。Kafka消息生产者对象—KafkaProducer的send方法主要调用NetworkClient完成消息发送；</li>
<li><code>SocketServer</code>：其是一个NIO的服务，它同时启动一个Acceptor接收线程和多个Processor处理器线程。提供了一种典型的Reactor多线程模式，将接收客户端请求和处理请求相分离；</li>
<li><code>KafkaServer</code>：代表了一个Kafka Broker的实例；其startup方法为实例启动的入口；</li>
<li><code>KafkaApis</code>：Kafka的业务逻辑处理Api，负责处理不同类型的请求；比如“发送消息”、“获取消息偏移量—offset”和“处理心跳请求”等；</li>
</ol>
<p> 上图展示的整体的处理流程如下所示：</p>
<ol>
<li>Acceptor 监听到来自请求者（请求者可以是来自 client，也可以来自 server）的新的连接，Acceptor 将这个请求者按照 round robin 的方式交给对对应的 Processor 进行处理；</li>
<li>Processor 注册这个 SocketChannel 的 OP_READ 的事件，如果有请求发送过来就可以被 Processor 的 Selector 选中；</li>
<li>Processor 将请求者发送的请求放入到一个 Request Queue 中，这是所有 Processor 共有的一个队列；</li>
<li>KafkaRequestHandler 从 Request Queue 中取出请求；</li>
<li>调用 KafkaApis 进行相应的处理；</li>
<li>处理的结果放入到该 Processor 对应的 Response Queue 中（每个 request 都标识它们来自哪个 Processor），Request Queue 的数量与 Processor 的数量保持一致；</li>
<li>Processor 从对应的 Response Queue 中取出 response；</li>
<li>Processor 将处理的结果返回给对应的请求者。</li>
</ol>
<h1 id="Kafka网络通信层的设计与具体实现"><a href="#Kafka网络通信层的设计与具体实现" class="headerlink" title="Kafka网络通信层的设计与具体实现"></a>Kafka网络通信层的设计与具体实现</h1><p> 这一节将结合Kafka网络通信层的源码来分析其设计与实现，这里主要详细介绍网络通信层的几个重要元素—SocketServer、Acceptor、Processor、RequestChannel和KafkaRequestHandler。本文分析的源码部分均基于Kafka的0.10.0.1版本。</p>
<h2 id="Server-网络模型整体流程"><a href="#Server-网络模型整体流程" class="headerlink" title="Server 网络模型整体流程"></a>Server 网络模型整体流程</h2><p>Kafka Server 启动后，会通过 KafkaServer 的 <code>startup()</code> 方法初始化涉及到网络模型的相关对象，如下所示：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">startup</span></span>() &#123;</span><br><span class="line">   <span class="keyword">try</span> &#123;</span><br><span class="line">     info(<span class="string">"starting"</span>)</span><br><span class="line"></span><br><span class="line">     <span class="keyword">if</span>(isShuttingDown.get)</span><br><span class="line">       <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(<span class="string">"Kafka server is still shutting down, cannot re-start!"</span>)</span><br><span class="line"></span><br><span class="line">     <span class="keyword">if</span>(startupComplete.get)</span><br><span class="line">       <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">     <span class="keyword">val</span> canStartup = isStartingUp.compareAndSet(<span class="literal">false</span>, <span class="literal">true</span>)</span><br><span class="line">     <span class="keyword">if</span> (canStartup) &#123;</span><br><span class="line">       metrics = <span class="keyword">new</span> <span class="type">Metrics</span>(metricConfig, reporters, kafkaMetricsTime, <span class="literal">true</span>)</span><br><span class="line"></span><br><span class="line">       brokerState.newState(<span class="type">Starting</span>)</span><br><span class="line"></span><br><span class="line">       <span class="comment">/* start scheduler */</span></span><br><span class="line">       kafkaScheduler.startup()</span><br><span class="line"></span><br><span class="line">       <span class="comment">/* setup zookeeper */</span></span><br><span class="line">       zkUtils = initZk()</span><br><span class="line"></span><br><span class="line">       <span class="comment">/* start log manager */</span></span><br><span class="line">       logManager = createLogManager(zkUtils.zkClient, brokerState)</span><br><span class="line">       logManager.startup()</span><br><span class="line"></span><br><span class="line">       <span class="comment">/* generate brokerId */</span></span><br><span class="line">       config.brokerId =  getBrokerId</span><br><span class="line">       <span class="keyword">this</span>.logIdent = <span class="string">"[Kafka Server "</span> + config.brokerId + <span class="string">"], "</span></span><br><span class="line">	<span class="comment">//note: socketServer</span></span><br><span class="line">       socketServer = <span class="keyword">new</span> <span class="type">SocketServer</span>(config, metrics, kafkaMetricsTime)</span><br><span class="line">       socketServer.startup()</span><br><span class="line"></span><br><span class="line">       <span class="comment">/* start replica manager */</span></span><br><span class="line">       replicaManager = <span class="keyword">new</span> <span class="type">ReplicaManager</span>(config, metrics, time, kafkaMetricsTime, zkUtils, kafkaScheduler, logManager,</span><br><span class="line">         isShuttingDown)</span><br><span class="line">       replicaManager.startup()</span><br><span class="line"></span><br><span class="line">       <span class="comment">/* start kafka controller */</span></span><br><span class="line">       kafkaController = <span class="keyword">new</span> <span class="type">KafkaController</span>(config, zkUtils, brokerState, kafkaMetricsTime, metrics, threadNamePrefix)</span><br><span class="line">       kafkaController.startup()</span><br><span class="line"></span><br><span class="line">       <span class="comment">/* start group coordinator */</span></span><br><span class="line">       groupCoordinator = <span class="type">GroupCoordinator</span>(config, zkUtils, replicaManager, kafkaMetricsTime)</span><br><span class="line">       groupCoordinator.startup()</span><br><span class="line"></span><br><span class="line">       <span class="comment">/* Get the authorizer and initialize it if one is specified.*/</span></span><br><span class="line">       authorizer = <span class="type">Option</span>(config.authorizerClassName).filter(_.nonEmpty).map &#123; authorizerClassName =&gt;</span><br><span class="line">         <span class="keyword">val</span> authZ = <span class="type">CoreUtils</span>.createObject[<span class="type">Authorizer</span>](authorizerClassName)</span><br><span class="line">         authZ.configure(config.originals())</span><br><span class="line">         authZ</span><br><span class="line">       &#125;</span><br><span class="line"></span><br><span class="line">       <span class="comment">/* start processing requests //<span class="doctag">NOTE:</span> 初始化 KafkaApis 实例,每个 Server 只会启动一个线程*/</span></span><br><span class="line">       apis = <span class="keyword">new</span> <span class="type">KafkaApis</span>(socketServer.requestChannel, replicaManager, groupCoordinator,</span><br><span class="line">         kafkaController, zkUtils, config.brokerId, config, metadataCache, metrics, authorizer)</span><br><span class="line">       requestHandlerPool = <span class="keyword">new</span> <span class="type">KafkaRequestHandlerPool</span>(config.brokerId, socketServer.requestChannel, apis, config.numIoThreads)</span><br><span class="line">       brokerState.newState(<span class="type">RunningAsBroker</span>)</span><br><span class="line"></span><br><span class="line">       <span class="type">Mx4jLoader</span>.maybeLoad()</span><br><span class="line"></span><br><span class="line">       <span class="comment">/* start dynamic config manager */</span></span><br><span class="line">       dynamicConfigHandlers = <span class="type">Map</span>[<span class="type">String</span>, <span class="type">ConfigHandler</span>](<span class="type">ConfigType</span>.<span class="type">Topic</span> -&gt; <span class="keyword">new</span> <span class="type">TopicConfigHandler</span>(logManager, config),</span><br><span class="line">                                                          <span class="type">ConfigType</span>.<span class="type">Client</span> -&gt; <span class="keyword">new</span> <span class="type">ClientIdConfigHandler</span>(apis.quotaManagers))</span><br><span class="line"></span><br><span class="line">       <span class="comment">// Apply all existing client configs to the ClientIdConfigHandler to bootstrap the overrides</span></span><br><span class="line">       <span class="comment">// <span class="doctag">TODO:</span> Move this logic to DynamicConfigManager</span></span><br><span class="line">       <span class="type">AdminUtils</span>.fetchAllEntityConfigs(zkUtils, <span class="type">ConfigType</span>.<span class="type">Client</span>).foreach &#123;</span><br><span class="line">         <span class="keyword">case</span> (clientId, properties) =&gt; dynamicConfigHandlers(<span class="type">ConfigType</span>.<span class="type">Client</span>).processConfigChanges(clientId, properties)</span><br><span class="line">       &#125;</span><br><span class="line"></span><br><span class="line">       <span class="comment">// Create the config manager. start listening to notifications</span></span><br><span class="line">       dynamicConfigManager = <span class="keyword">new</span> <span class="type">DynamicConfigManager</span>(zkUtils, dynamicConfigHandlers)</span><br><span class="line">       dynamicConfigManager.startup()</span><br><span class="line"></span><br><span class="line">       <span class="comment">/* tell everyone we are alive */</span></span><br><span class="line">       <span class="keyword">val</span> listeners = config.advertisedListeners.map &#123;<span class="keyword">case</span>(protocol, endpoint) =&gt;</span><br><span class="line">         <span class="keyword">if</span> (endpoint.port == <span class="number">0</span>)</span><br><span class="line">           (protocol, <span class="type">EndPoint</span>(endpoint.host, socketServer.boundPort(protocol), endpoint.protocolType))</span><br><span class="line">         <span class="keyword">else</span></span><br><span class="line">           (protocol, endpoint)</span><br><span class="line">       &#125;</span><br><span class="line">       kafkaHealthcheck = <span class="keyword">new</span> <span class="type">KafkaHealthcheck</span>(config.brokerId, listeners, zkUtils, config.rack,</span><br><span class="line">         config.interBrokerProtocolVersion)</span><br><span class="line">       kafkaHealthcheck.startup()</span><br><span class="line"></span><br><span class="line">       <span class="comment">// Now that the broker id is successfully registered via KafkaHealthcheck, checkpoint it</span></span><br><span class="line">       checkpointBrokerId(config.brokerId)</span><br><span class="line"></span><br><span class="line">       <span class="comment">/* register broker metrics */</span></span><br><span class="line">       registerStats()</span><br><span class="line"></span><br><span class="line">       shutdownLatch = <span class="keyword">new</span> <span class="type">CountDownLatch</span>(<span class="number">1</span>)</span><br><span class="line">       startupComplete.set(<span class="literal">true</span>)</span><br><span class="line">       isStartingUp.set(<span class="literal">false</span>)</span><br><span class="line">       <span class="type">AppInfoParser</span>.registerAppInfo(jmxPrefix, config.brokerId.toString)</span><br><span class="line">       info(<span class="string">"started"</span>)</span><br><span class="line">     &#125;</span><br><span class="line">   &#125;</span><br><span class="line">...</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure></p>
<p>Kafka Server 在启动时会初始化 <code>SocketServer</code>、<code>KafkaApis</code> 和 <code>KafkaRequestHandlerPool</code> 对象，这也是 Server 网络处理模型的主要组成部分。Kafka Server 的网络处理模型也是基于 Java NIO 机制实现的，实现模式与 Reactor 模式类似</p>
<p>上面是 Server 端网络处理的整体流程，下面我们开始详细讲述上面内容在 Kafka 中实现。</p>
<h2 id="SocketServer"><a href="#SocketServer" class="headerlink" title="SocketServer"></a>SocketServer</h2><p>SocketServer 是接收 Socket 连接、处理请求并返回处理结果的地方，Acceptor 及 Processor 的初始化、处理逻辑都是在这里实现的。在SocketServer 内有几个比较重要的变量，这里先来看下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SocketServer</span>(<span class="params">val config: <span class="type">KafkaConfig</span>, val metrics: <span class="type">Metrics</span>, val time: <span class="type">Time</span>, val credentialProvider: <span class="type">CredentialProvider</span></span>) <span class="keyword">extends</span> <span class="title">Logging</span> <span class="keyword">with</span> <span class="title">KafkaMetricsGroup</span> </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> endpoints = config.listeners.map(l =&gt; l.listenerName -&gt; l).toMap <span class="comment">//note: broker 开放的端口数</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> numProcessorThreads = config.numNetworkThreads <span class="comment">//note: num.network.threads 默认为 3个，即 processor</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> maxQueuedRequests = config.queuedMaxRequests <span class="comment">//note:  queued.max.requests，request 队列中允许的最多请求数，默认是500</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> totalProcessorThreads = numProcessorThreads * endpoints.size <span class="comment">//note: 每个端口会对应 N 个 processor</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> maxConnectionsPerIp = config.maxConnectionsPerIp <span class="comment">//note: 默认 2147483647</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> maxConnectionsPerIpOverrides = config.maxConnectionsPerIpOverrides</span><br><span class="line">  <span class="keyword">this</span>.logIdent = <span class="string">"[Socket Server on Broker "</span> + config.brokerId + <span class="string">"], "</span></span><br><span class="line">  <span class="comment">//note: 请求队列</span></span><br><span class="line">  <span class="keyword">val</span> requestChannel = <span class="keyword">new</span> <span class="type">RequestChannel</span>(totalProcessorThreads, maxQueuedRequests)</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> processors = <span class="keyword">new</span> <span class="type">Array</span>[<span class="type">Processor</span>](totalProcessorThreads)</span><br><span class="line">  <span class="keyword">private</span>[network] <span class="keyword">val</span> acceptors = mutable.<span class="type">Map</span>[<span class="type">EndPoint</span>, <span class="type">Acceptor</span>]()</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RequestChannel</span>(<span class="params">val numProcessors: <span class="type">Int</span>, val queueSize: <span class="type">Int</span></span>) <span class="keyword">extends</span> <span class="title">KafkaMetricsGroup</span> </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> responseListeners: <span class="type">List</span>[(<span class="type">Int</span>) =&gt; <span class="type">Unit</span>] = <span class="type">Nil</span></span><br><span class="line">  <span class="comment">//note: 一个 requestQueue 队列,N 个 responseQueues 队列</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> requestQueue = <span class="keyword">new</span> <span class="type">ArrayBlockingQueue</span>[<span class="type">RequestChannel</span>.<span class="type">Request</span>](queueSize)</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> responseQueues = <span class="keyword">new</span> <span class="type">Array</span>[<span class="type">BlockingQueue</span>[<span class="type">RequestChannel</span>.<span class="type">Response</span>]](numProcessors)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>其中</p>
<ol>
<li><code>numProcessorThreads</code>：决定了 Processor 的个数，默认是3个，也就是 1+N+M 的 N 的数值；</li>
<li><code>maxQueuedRequests</code>：决定了 request queue 中最多允许放入多少个请求（等待处理的请求），默认是 500；</li>
<li>在 <code>RequestChannel</code> 中初始化了一个 requestQueue 和 N 个 responseQueue。<h3 id="SocketServer-初始化"><a href="#SocketServer-初始化" class="headerlink" title="SocketServer 初始化"></a>SocketServer 初始化</h3>Boker在启动的时候会调用SocketServer的<code>startup</code>方法，会初始化 1 个 Acceptor 和 N 个 Processor 线程，并启动，其实现如下：<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">startup</span></span>() &#123;</span><br><span class="line">  <span class="keyword">this</span>.synchronized &#123;</span><br><span class="line">    <span class="comment">//note: 一台 broker 一般只设置一个端口，当然这里也可以设置两个</span></span><br><span class="line">    config.listeners.foreach &#123; endpoint =&gt;</span><br><span class="line">      <span class="keyword">val</span> listenerName = endpoint.listenerName</span><br><span class="line">      <span class="keyword">val</span> securityProtocol = endpoint.securityProtocol</span><br><span class="line">      <span class="keyword">val</span> processorEndIndex = processorBeginIndex + numProcessorThreads</span><br><span class="line">      <span class="comment">//note: N 个 processor</span></span><br><span class="line">      <span class="keyword">for</span> (i &lt;- processorBeginIndex until processorEndIndex)</span><br><span class="line">        processors(i) = newProcessor(i, connectionQuotas, listenerName, securityProtocol)</span><br><span class="line">      <span class="comment">//note: 1个 Acceptor</span></span><br><span class="line">      <span class="keyword">val</span> acceptor = <span class="keyword">new</span> <span class="type">Acceptor</span>(endpoint, sendBufferSize, recvBufferSize, brokerId,</span><br><span class="line">        processors.slice(processorBeginIndex, processorEndIndex), connectionQuotas)</span><br><span class="line">      acceptors.put(endpoint, acceptor)</span><br><span class="line">      <span class="type">Utils</span>.newThread(<span class="string">s"kafka-socket-acceptor-<span class="subst">$listenerName</span>-<span class="subst">$securityProtocol</span>-<span class="subst">$&#123;endpoint.port&#125;</span>"</span>, acceptor, <span class="literal">false</span>).start()</span><br><span class="line">      acceptor.awaitStartup()</span><br><span class="line">      processorBeginIndex = processorEndIndex</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="Acceptor"><a href="#Acceptor" class="headerlink" title="Acceptor"></a>Acceptor</h2><p>Acceptor是一个继承自抽象类AbstractServerThread的线程类。Acceptor的主要任务是监听并且接收客户端的请求，同时建立数据传输通道—SocketChannel，然后以轮询的方式交给一个后端的Processor线程处理（具体的方式是添加socketChannel至并发队列并唤醒Processor线程处理）。</p>
<p> 在该线程类中主要可以关注以下两个重要的变量：</p>
<ol>
<li>nioSelector：通过NSelector.open()方法创建的变量，封装了JAVA NIO Selector的相关操作；</li>
<li>serverChannel：用于监听端口的服务端Socket套接字对象；</li>
</ol>
<p>实现如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run</span></span>() &#123;</span><br><span class="line">  serverChannel.register(nioSelector, <span class="type">SelectionKey</span>.<span class="type">OP_ACCEPT</span>)<span class="comment">//note: 注册 accept 事件</span></span><br><span class="line">  startupComplete()</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">var</span> currentProcessor = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> (isRunning) &#123;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">val</span> ready = nioSelector.select(<span class="number">500</span>)</span><br><span class="line">        <span class="keyword">if</span> (ready &gt; <span class="number">0</span>) &#123;</span><br><span class="line">          <span class="keyword">val</span> keys = nioSelector.selectedKeys()</span><br><span class="line">          <span class="keyword">val</span> iter = keys.iterator()</span><br><span class="line">          <span class="keyword">while</span> (iter.hasNext &amp;&amp; isRunning) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">              <span class="keyword">val</span> key = iter.next</span><br><span class="line">              iter.remove()</span><br><span class="line">              <span class="keyword">if</span> (key.isAcceptable)</span><br><span class="line">                accept(key, processors(currentProcessor))<span class="comment">//note: 拿到一个socket 连接，轮询选择一个processor进行处理</span></span><br><span class="line">              <span class="keyword">else</span></span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(<span class="string">"Unrecognized key state for acceptor thread."</span>)</span><br><span class="line">              <span class="comment">//note: 轮询算法,使用 round robin</span></span><br><span class="line">              <span class="comment">// round robin to the next processor thread</span></span><br><span class="line">              currentProcessor = (currentProcessor + <span class="number">1</span>) % processors.length</span><br><span class="line">            &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">              <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt; error(<span class="string">"Error while accepting connection"</span>, e)</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">catch</span> &#123;</span><br><span class="line">        <span class="comment">// We catch all the throwables to prevent the acceptor thread from exiting on exceptions due</span></span><br><span class="line">        <span class="comment">// to a select operation on a specific channel or a bad request. We don't want</span></span><br><span class="line">        <span class="comment">// the broker to stop responding to requests from other clients in these scenarios.</span></span><br><span class="line">        <span class="keyword">case</span> e: <span class="type">ControlThrowable</span> =&gt; <span class="keyword">throw</span> e</span><br><span class="line">        <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt; error(<span class="string">"Error occurred"</span>, e)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    debug(<span class="string">"Closing server socket and selector."</span>)</span><br><span class="line">    swallowError(serverChannel.close())</span><br><span class="line">    swallowError(nioSelector.close())</span><br><span class="line">    shutdownComplete()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>Acceptor 通过 <code>accept()</code> 将该新连接交给对应的 Processor，其实现如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//note: 处理一个新的连接</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">accept</span></span>(key: <span class="type">SelectionKey</span>, processor: <span class="type">Processor</span>) &#123;</span><br><span class="line">  <span class="comment">//note: accept 事件发生时，获取注册到 selector 上的 ServerSocketChannel</span></span><br><span class="line">  <span class="keyword">val</span> serverSocketChannel = key.channel().asInstanceOf[<span class="type">ServerSocketChannel</span>]</span><br><span class="line">  <span class="keyword">val</span> socketChannel = serverSocketChannel.accept()</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    connectionQuotas.inc(socketChannel.socket().getInetAddress)</span><br><span class="line">    socketChannel.configureBlocking(<span class="literal">false</span>)</span><br><span class="line">    socketChannel.socket().setTcpNoDelay(<span class="literal">true</span>)</span><br><span class="line">    socketChannel.socket().setKeepAlive(<span class="literal">true</span>)</span><br><span class="line">    <span class="keyword">if</span> (sendBufferSize != <span class="type">Selectable</span>.<span class="type">USE_DEFAULT_BUFFER_SIZE</span>)</span><br><span class="line">      socketChannel.socket().setSendBufferSize(sendBufferSize)</span><br><span class="line">    debug(<span class="string">"Accepted connection from %s on %s and assigned it to processor %d, sendBufferSize [actual|requested]: [%d|%d] recvBufferSize [actual|requested]: [%d|%d]"</span></span><br><span class="line">          .format(socketChannel.socket.getRemoteSocketAddress, socketChannel.socket.getLocalSocketAddress, processor.id,</span><br><span class="line">                socketChannel.socket.getSendBufferSize, sendBufferSize,</span><br><span class="line">                socketChannel.socket.getReceiveBufferSize, recvBufferSize))</span><br><span class="line">    <span class="comment">//note: 轮询选择不同的 processor 进行处理</span></span><br><span class="line">    processor.accept(socketChannel)</span><br><span class="line">  &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> e: <span class="type">TooManyConnectionsException</span> =&gt;</span><br><span class="line">      info(<span class="string">"Rejected connection from %s, address already has the configured maximum of %d connections."</span>.format(e.ip, e.count))</span><br><span class="line">      close(socketChannel)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>在上面源码中可以看到，Acceptor线程启动后，首先会向用于监听端口的服务端套接字对象—ServerSocketChannel上注册OP_ACCEPT 事件。然后以轮询的方式等待所关注的事件发生。如果该事件发生，则调用accept()方法对OP_ACCEPT事件进行处理。这里，Processor是通过round robin方法选择的，这样可以保证后面多个Processor线程的负载基本均匀。<br> Acceptor的accept()方法的作用主要如下：</p>
<ol>
<li>通过SelectionKey取得与之对应的serverSocketChannel实例，并调用它的accept()方法与客户端建立连接；</li>
<li>调用connectionQuotas.inc()方法增加连接统计计数；并同时设置第（1）步中创建返回的socketChannel属性（如sendBufferSize、KeepAlive、TcpNoDelay、configureBlocking等）</li>
<li>将socketChannel交给processor.accept()方法进行处理。这里主要是将socketChannel加入Processor处理器的并发队列newConnections队列中，然后唤醒Processor线程从队列中获取socketChannel并处理。其中，newConnections会被Acceptor线程和Processor线程并发访问操作，所以newConnections是ConcurrentLinkedQueue队列（一个基于链接节点的无界线程安全队列）</li>
</ol>
<h2 id="Processor"><a href="#Processor" class="headerlink" title="Processor"></a>Processor</h2><p>Processor同Acceptor一样，也是一个线程类，继承了抽象类AbstractServerThread。其主要是从客户端的请求中读取数据和将KafkaRequestHandler处理完响应结果返回给客户端。在该线程类中主要关注以下几个重要的变量：</p>
<ol>
<li><code>newConnections</code>：在上面的Acceptor一节中已经提到过，它是一种ConcurrentLinkedQueue[SocketChannel]类型的队列，用于保存新连接交由Processor处理的socketChannel；</li>
<li><code>inflightResponses</code>：是一个Map[String, RequestChannel.Response]类型的集合，用于记录尚未发送的响应；</li>
<li><code>selector</code>：是一个类型为KSelector变量，用于管理网络连接；<br>下面先给出Processor处理器线程run方法执行的流程图：<br><img src="/2018/11/24/Kafka-源码解析之-Server-1-N-M-网络处理模型（一）/kafka-processor.png" alt="Kafk_Processor线程的处理流程图"></li>
</ol>
<p>在前面，Acceptor 通过 <code>accept()</code> 将新的连接交给 Processor，Processor 实际上是将该 SocketChannel 添加到该 Processor 的 <code>newConnections</code> 队列中，实现如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">accept</span></span>(socketChannel: <span class="type">SocketChannel</span>) &#123;</span><br><span class="line">  newConnections.add(socketChannel)<span class="comment">//note: 添加到队列中</span></span><br><span class="line">  wakeup()<span class="comment">//note: 唤醒 Processor 的 selector（如果此时在阻塞的话）</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>这里详细看下 Processor 线程做了什么事情，其 <code>run()</code> 方法的实现如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>() &#123;</span><br><span class="line">  startupComplete()</span><br><span class="line">  <span class="keyword">while</span> (isRunning) &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// setup any new connections that have been queued up</span></span><br><span class="line">      configureNewConnections()<span class="comment">//note: 对新的 socket 连接,并注册 READ 事件</span></span><br><span class="line">      <span class="comment">// register any new responses for writing</span></span><br><span class="line">      processNewResponses()<span class="comment">//note: 处理 response 队列中 response</span></span><br><span class="line">      poll() <span class="comment">//note: 监听所有的 socket channel，是否有新的请求发送过来</span></span><br><span class="line">      processCompletedReceives() <span class="comment">//note: 处理接收到请求，将其放入到 request queue 中</span></span><br><span class="line">      processCompletedSends() <span class="comment">//note: 处理已经完成的发送</span></span><br><span class="line">      processDisconnected() <span class="comment">//note: 处理断开的连接</span></span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="comment">// We catch all the throwables here to prevent the processor thread from exiting. We do this because</span></span><br><span class="line">      <span class="comment">// letting a processor exit might cause a bigger impact on the broker. Usually the exceptions thrown would</span></span><br><span class="line">      <span class="comment">// be either associated with a specific socket channel or a bad request. We just ignore the bad socket channel</span></span><br><span class="line">      <span class="comment">// or request. This behavior might need to be reviewed if we see an exception that need the entire broker to stop.</span></span><br><span class="line">      <span class="keyword">case</span> e: <span class="type">ControlThrowable</span> =&gt; <span class="keyword">throw</span> e</span><br><span class="line">      <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt;</span><br><span class="line">        error(<span class="string">"Processor got uncaught exception."</span>, e)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  debug(<span class="string">"Closing selector - processor "</span> + id)</span><br><span class="line">  swallowError(closeAll())</span><br><span class="line">  shutdownComplete()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>Processor 在一次循环中，主要做的事情如下：</p>
<ol>
<li><code>configureNewConnections()</code>：对新添加到 newConnections 队列中的 SocketChannel 进行处理，这里主要是遍历取出队列中的每个socketChannel并将其在selector上注册<code>OP_READ</code>事件；</li>
<li><code>processNewResponses()</code>：从该 Processor 对应的 response queue 中取出一个 response，进行发送,在这一步中会根据responseAction的类型（NoOpAction/SendAction/CloseConnectionAction）进行判断，若为“NoOpAction”，表示该连接对应的请求无需响应；若为“SendAction”，表示该Response需要发送给客户端，则会通过“selector.send”注册OP_WRITE事件，并且将该Response从responseQueue响应队列中移至inflightResponses集合中；“CloseConnectionAction”，表示该连接是要关闭的；；</li>
<li><code>poll()</code>：调用 selector 的 poll() 方法，遍历注册的 SocketChannel，查看是否有事件准备就绪；</li>
<li><code>processCompletedReceives()</code>：将接收到请求添加到的 request queue 中,在processCompletedReceives方法中调用“requestChannel.sendRequest”方法将请求Request添加至requestChannel的全局请求队列—requestQueue中，等待KafkaRequestHandler来处理。同时，调用“selector.mute”方法取消与该请求对应的连接通道上的OP_READ事件；</li>
<li><code>processCompletedSends()</code>：处理已经完成的响应发送,当已经完成将response发送给客户端，则将其从inflightResponses移除，同时通过调用“selector.unmute”方法为对应的连接通道重新注册OP_READ事件；</li>
<li><code>processDisconnected()</code>：处理断开的 SocketChannel, 将该response从inflightResponses集合中移除，同时将connectionQuotas统计计数减1。</li>
</ol>
<p>上面就是 Processor 线程处理的主要逻辑，先是向新的 SocketChannel 注册相应的事件，监控是否有请求发送过来，接着从 response queue 中取出处理完成的请求发送给对应的请求者，然后调用一下 selector 的 <code>poll()</code>，遍历一下注册的所有 SocketChannel，判断是否有事件就绪，然后做相应的处理。这里需要注意的是，request queue 是所有 Processor 公用的一个队列，而 response queue 则是与 Processor 一一对应的，因为每个 Processor 监听的 SocketChannel 并不是同一批的，如果公有一个 response queue，那么这个 N 个 Processor 的 selector 要去监听所有的 SocketChannel，而不是现在这种，只需要去关注分配给自己的 SocketChannel。</p>
<p>下面分别看下上面的这些方法的具体实现。</p>
<h3 id="configureNewConnections"><a href="#configureNewConnections" class="headerlink" title="configureNewConnections"></a>configureNewConnections</h3><p>configureNewConnections() 对新添加到 <code>newConnections</code> 队列中的 SocketChannel 进行处理，主要是 selector 注册相应的 <code>OP_READ</code> 事件，其实现如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//note: 如果有新的连接过来，将该 Channel 的 OP_READ 事件注册到 selector 上</span></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">configureNewConnections</span></span>() &#123;</span><br><span class="line">  <span class="keyword">while</span> (!newConnections.isEmpty) &#123;</span><br><span class="line">    <span class="keyword">val</span> channel = newConnections.poll()</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      debug(<span class="string">s"Processor <span class="subst">$id</span> listening to new connection from <span class="subst">$&#123;channel.socket.getRemoteSocketAddress&#125;</span>"</span>)</span><br><span class="line">      <span class="keyword">val</span> localHost = channel.socket().getLocalAddress.getHostAddress</span><br><span class="line">      <span class="keyword">val</span> localPort = channel.socket().getLocalPort</span><br><span class="line">      <span class="keyword">val</span> remoteHost = channel.socket().getInetAddress.getHostAddress</span><br><span class="line">      <span class="keyword">val</span> remotePort = channel.socket().getPort</span><br><span class="line">      <span class="keyword">val</span> connectionId = <span class="type">ConnectionId</span>(localHost, localPort, remoteHost, remotePort).toString</span><br><span class="line">      selector.register(connectionId, channel)</span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="comment">// We explicitly catch all non fatal exceptions and close the socket to avoid a socket leak. The other</span></span><br><span class="line">      <span class="comment">// throwables will be caught in processor and logged as uncaught exceptions.</span></span><br><span class="line">      <span class="keyword">case</span> <span class="type">NonFatal</span>(e) =&gt;</span><br><span class="line">        <span class="keyword">val</span> remoteAddress = channel.getRemoteAddress</span><br><span class="line">        <span class="comment">// need to close the channel here to avoid a socket leak.</span></span><br><span class="line">        close(channel)</span><br><span class="line">        error(<span class="string">s"Processor <span class="subst">$id</span> closed connection from <span class="subst">$remoteAddress</span>"</span>, e)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="processNewResponses"><a href="#processNewResponses" class="headerlink" title="processNewResponses"></a>processNewResponses</h3><p><code>processNewResponses()</code> 方法是从该 Processor 对应的 response queue 中取出一个 response，Processor 是通过 RequestChannel 的 <code>receiveResponse()</code> 从该 Processor 对应的 response queue 中取出 response，如下所示：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//note: 获取 response</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">receiveResponse</span></span>(processor: <span class="type">Int</span>): <span class="type">RequestChannel</span>.<span class="type">Response</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> response = responseQueues(processor).poll()</span><br><span class="line">  <span class="keyword">if</span> (response != <span class="literal">null</span>)</span><br><span class="line">    response.request.responseDequeueTimeMs = <span class="type">Time</span>.<span class="type">SYSTEM</span>.milliseconds</span><br><span class="line">  response</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>取到相应的 response 之后，会判断该 response 的类型，进行相应的操作，如果需要返回，那么会调用 <code>sendResponse()</code> 发送该 response，如下所示：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//note: 处理一个新的 response 响应</span></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">processNewResponses</span></span>() &#123;</span><br><span class="line">  <span class="keyword">var</span> curr = requestChannel.receiveResponse(id)</span><br><span class="line">  <span class="keyword">while</span> (curr != <span class="literal">null</span>) &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      curr.responseAction <span class="keyword">match</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> <span class="type">RequestChannel</span>.<span class="type">NoOpAction</span> =&gt; <span class="comment">//note: 如果这个请求不需要返回 response，再次注册该监听事件</span></span><br><span class="line">          <span class="comment">// There is no response to send to the client, we need to read more pipelined requests</span></span><br><span class="line">          <span class="comment">// that are sitting in the server's socket buffer</span></span><br><span class="line">          curr.request.updateRequestMetrics</span><br><span class="line">          trace(<span class="string">"Socket server received empty response to send, registering for read: "</span> + curr)</span><br><span class="line">          <span class="keyword">val</span> channelId = curr.request.connectionId</span><br><span class="line">          <span class="keyword">if</span> (selector.channel(channelId) != <span class="literal">null</span> || selector.closingChannel(channelId) != <span class="literal">null</span>)</span><br><span class="line">              selector.unmute(channelId)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">RequestChannel</span>.<span class="type">SendAction</span> =&gt; <span class="comment">//note: 需要发送的 response，那么进行发送</span></span><br><span class="line">          sendResponse(curr)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">RequestChannel</span>.<span class="type">CloseConnectionAction</span> =&gt; <span class="comment">//note: 要关闭的 response</span></span><br><span class="line">          curr.request.updateRequestMetrics</span><br><span class="line">          trace(<span class="string">"Closing socket connection actively according to the response code."</span>)</span><br><span class="line">          close(selector, curr.request.connectionId)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      curr = requestChannel.receiveResponse(id)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/* `protected` for test usage */</span></span><br><span class="line"><span class="comment">//note: 发送的对应的 response</span></span><br><span class="line"><span class="keyword">protected</span>[network] <span class="function"><span class="keyword">def</span> <span class="title">sendResponse</span></span>(response: <span class="type">RequestChannel</span>.<span class="type">Response</span>) &#123;</span><br><span class="line">  trace(<span class="string">s"Socket server received response to send, registering for write and sending data: <span class="subst">$response</span>"</span>)</span><br><span class="line">  <span class="keyword">val</span> channel = selector.channel(response.responseSend.destination)</span><br><span class="line">  <span class="comment">// `channel` can be null if the selector closed the connection because it was idle for too long</span></span><br><span class="line">  <span class="keyword">if</span> (channel == <span class="literal">null</span>) &#123;</span><br><span class="line">    warn(<span class="string">s"Attempting to send response via channel for which there is no open connection, connection id <span class="subst">$id</span>"</span>)</span><br><span class="line">    response.request.updateRequestMetrics()</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">else</span> &#123;</span><br><span class="line">    selector.send(response.responseSend) <span class="comment">//note: 发送该 response</span></span><br><span class="line">    inflightResponses += (response.request.connectionId -&gt; response) <span class="comment">//note: 添加到 inflinght 中</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="processCompletedReceives"><a href="#processCompletedReceives" class="headerlink" title="processCompletedReceives"></a>processCompletedReceives</h3><p><code>processCompletedReceives()</code>方法的主要作用是处理接收到请求，并将其放入到 request queue 中，其实现如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//note: 处理接收到的所有请求</span></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">processCompletedReceives</span></span>() &#123;</span><br><span class="line">  selector.completedReceives.asScala.foreach &#123; receive =&gt;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">val</span> openChannel = selector.channel(receive.source)</span><br><span class="line">      <span class="keyword">val</span> session = &#123;</span><br><span class="line">        <span class="comment">// Only methods that are safe to call on a disconnected channel should be invoked on 'channel'.</span></span><br><span class="line">        <span class="keyword">val</span> channel = <span class="keyword">if</span> (openChannel != <span class="literal">null</span>) openChannel <span class="keyword">else</span> selector.closingChannel(receive.source)</span><br><span class="line">        <span class="type">RequestChannel</span>.<span class="type">Session</span>(<span class="keyword">new</span> <span class="type">KafkaPrincipal</span>(<span class="type">KafkaPrincipal</span>.<span class="type">USER_TYPE</span>, channel.principal.getName), channel.socketAddress)</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">val</span> req = <span class="type">RequestChannel</span>.<span class="type">Request</span>(processor = id, connectionId = receive.source, session = session,</span><br><span class="line">        buffer = receive.payload, startTimeMs = time.milliseconds, listenerName = listenerName,</span><br><span class="line">        securityProtocol = securityProtocol)</span><br><span class="line">      requestChannel.sendRequest(req) <span class="comment">//note: 添加到请求队列，如果队列满了，将会阻塞</span></span><br><span class="line">      selector.mute(receive.source) <span class="comment">//note: 移除该连接的 OP_READ 监听</span></span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> e @ (_: <span class="type">InvalidRequestException</span> | _: <span class="type">SchemaException</span>) =&gt;</span><br><span class="line">        <span class="comment">// note that even though we got an exception, we can assume that receive.source is valid. Issues with constructing a valid receive object were handled earlier</span></span><br><span class="line">        error(<span class="string">s"Closing socket for <span class="subst">$&#123;receive.source&#125;</span> because of error"</span>, e)</span><br><span class="line">        close(selector, receive.source)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="processCompletedSends"><a href="#processCompletedSends" class="headerlink" title="processCompletedSends"></a>processCompletedSends</h3><p><code>processCompletedSends()</code> 方法是处理已经完成的发送，其实现如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">processCompletedSends</span></span>() &#123;</span><br><span class="line">  selector.completedSends.asScala.foreach &#123; send =&gt;</span><br><span class="line">    <span class="comment">//note: response 发送完成，从正在发送的集合中移除</span></span><br><span class="line">    <span class="keyword">val</span> resp = inflightResponses.remove(send.destination).getOrElse &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(<span class="string">s"Send for <span class="subst">$&#123;send.destination&#125;</span> completed, but not in `inflightResponses`"</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    resp.request.updateRequestMetrics()</span><br><span class="line">    selector.unmute(send.destination) <span class="comment">//note: 完成这个请求之后再次监听 OP_READ 事件</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="KafkaRequestHandlerPool"><a href="#KafkaRequestHandlerPool" class="headerlink" title="KafkaRequestHandlerPool"></a>KafkaRequestHandlerPool</h2><p>上面主要是讲述 SocketServer 中 Acceptor 与 Processor 的处理内容，也就是 1+N+M 模型中 1+N 部分，下面开始讲述 M 部分，也就是 KafkaRequestHandler 的内容，其初始化实现如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">KafkaRequestHandlerPool</span>(<span class="params">val brokerId: <span class="type">Int</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                              val requestChannel: <span class="type">RequestChannel</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                              val apis: <span class="type">KafkaApis</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                              time: <span class="type">Time</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                              numThreads: <span class="type">Int</span></span>) <span class="keyword">extends</span> <span class="title">Logging</span> <span class="keyword">with</span> <span class="title">KafkaMetricsGroup</span> </span>&#123;</span><br><span class="line">  <span class="comment">/* a meter to track the average free capacity of the request handlers */</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> aggregateIdleMeter = newMeter(<span class="string">"RequestHandlerAvgIdlePercent"</span>, <span class="string">"percent"</span>, <span class="type">TimeUnit</span>.<span class="type">NANOSECONDS</span>)</span><br><span class="line">  <span class="keyword">this</span>.logIdent = <span class="string">"[Kafka Request Handler on Broker "</span> + brokerId + <span class="string">"], "</span></span><br><span class="line">  <span class="keyword">val</span> threads = <span class="keyword">new</span> <span class="type">Array</span>[<span class="type">Thread</span>](numThreads)</span><br><span class="line">  <span class="keyword">val</span> runnables = <span class="keyword">new</span> <span class="type">Array</span>[<span class="type">KafkaRequestHandler</span>](numThreads)</span><br><span class="line">  <span class="comment">//note: 建立 M 个（numThreads）KafkaRequestHandler</span></span><br><span class="line">  <span class="keyword">for</span>(i &lt;- <span class="number">0</span> until numThreads) &#123;</span><br><span class="line">    <span class="comment">//note: requestChannel 是 Processor 存放 request 请求的地方,也是 Handler 处理完请求存放 response 的地方</span></span><br><span class="line">    runnables(i) = <span class="keyword">new</span> <span class="type">KafkaRequestHandler</span>(i, brokerId, aggregateIdleMeter, numThreads, requestChannel, apis, time)</span><br><span class="line">    threads(i) = <span class="type">Utils</span>.daemonThread(<span class="string">"kafka-request-handler-"</span> + i, runnables(i))</span><br><span class="line">    threads(i).start()</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">shutdown</span></span>() &#123;</span><br><span class="line">    info(<span class="string">"shutting down"</span>)</span><br><span class="line">    <span class="keyword">for</span>(handler &lt;- runnables)</span><br><span class="line">      handler.shutdown</span><br><span class="line">    <span class="keyword">for</span>(thread &lt;- threads)</span><br><span class="line">      thread.join</span><br><span class="line">    info(<span class="string">"shut down completely"</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>如上面实现所示：</p>
<ol>
<li>KafkaRequestHandlerPool 会初始化 M 个 KafkaRequestHandler 线程，并启动该线程；</li>
<li>在初始化 KafkaRequestHandler 时，传入一个 requestChannel 变量，这个是 Processor 存放 request 的地方，KafkaRequestHandler 在处理请求时，会从这个 queue 中取出相应的 request。<h3 id="KafkaRequestHandler"><a href="#KafkaRequestHandler" class="headerlink" title="KafkaRequestHandler"></a>KafkaRequestHandler</h3>KafkaRequestHandler 线程的处理实现如下：<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run</span></span>() &#123;</span><br><span class="line">  <span class="keyword">while</span>(<span class="literal">true</span>) &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">var</span> req : <span class="type">RequestChannel</span>.<span class="type">Request</span> = <span class="literal">null</span></span><br><span class="line">      <span class="keyword">while</span> (req == <span class="literal">null</span>) &#123;</span><br><span class="line">        <span class="comment">// We use a single meter for aggregate idle percentage for the thread pool.</span></span><br><span class="line">        <span class="comment">// Since meter is calculated as total_recorded_value / time_window and</span></span><br><span class="line">        <span class="comment">// time_window is independent of the number of threads, each recorded idle</span></span><br><span class="line">        <span class="comment">// time should be discounted by # threads.</span></span><br><span class="line">        <span class="keyword">val</span> startSelectTime = time.nanoseconds</span><br><span class="line">        req = requestChannel.receiveRequest(<span class="number">300</span>) <span class="comment">//note: 从 request queue 中拿去 request</span></span><br><span class="line">        <span class="keyword">val</span> idleTime = time.nanoseconds - startSelectTime</span><br><span class="line">        aggregateIdleMeter.mark(idleTime / totalHandlerThreads)</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span>(req eq <span class="type">RequestChannel</span>.<span class="type">AllDone</span>) &#123;</span><br><span class="line">        debug(<span class="string">"Kafka request handler %d on broker %d received shut down command"</span>.format(</span><br><span class="line">          id, brokerId))</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">      &#125;</span><br><span class="line">      req.requestDequeueTimeMs = time.milliseconds</span><br><span class="line">      trace(<span class="string">"Kafka request handler %d on broker %d handling request %s"</span>.format(id, brokerId, req))</span><br><span class="line">      apis.handle(req) <span class="comment">//note: 处理请求,并将处理的结果通过 sendResponse 放入 response queue 中</span></span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt; error(<span class="string">"Exception when handling request"</span>, e)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>上述方法的实现逻辑：</p>
<ol>
<li>KafkaRequestHandler不断的从requestChannel队列里面取出request交给apis处理；</li>
<li>KafkaApis 处理这个 request，并通过 <code>requestChannel.sendResponse()</code> 将处理的结果放入 requestChannel 的 response queue 中，如下所示：<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//note: 将 response 添加到对应的队列中</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sendResponse</span></span>(response: <span class="type">RequestChannel</span>.<span class="type">Response</span>) &#123;</span><br><span class="line">  responseQueues(response.processor).put(response)</span><br><span class="line">  <span class="keyword">for</span>(onResponse &lt;- responseListeners)</span><br><span class="line">    onResponse(response.processor) <span class="comment">//note: 调用对应 processor 的 wakeup 方法</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>KafkaRequestHandler也是一种线程类，在KafkaServer实例启动时候会实例化一个线程池—KafkaRequestHandlerPool对象（包含了若干个KafkaRequestHandler线程），这些线程以守护线程的方式在后台运行。在KafkaRequestHandler的run方法中会循环地从RequestChannel中阻塞式读取request，读取后再交由KafkaApis来具体处理。</p>
<h2 id="KafkaApis"><a href="#KafkaApis" class="headerlink" title="KafkaApis"></a>KafkaApis</h2><p>KafkaApis是用于处理对通信网络传输过来的业务消息请求的中心转发组件。该组件反映出Kafka Broker Server可以提供哪些服务。<br>apis根据不同的请求类型调用不同的方法进行处理， 代码如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Top-level method that handles all requests and multiplexes to the right api</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">handle</span></span>(request: <span class="type">RequestChannel</span>.<span class="type">Request</span>) &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="type">ApiKeys</span>.forId(request.requestId) <span class="keyword">match</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">PRODUCE</span> =&gt; handleProducerRequest(request)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">FETCH</span> =&gt; handleFetchRequest(request)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">LIST_OFFSETS</span> =&gt; handleOffsetRequest(request)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">METADATA</span> =&gt; handleTopicMetadataRequest(request)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">LEADER_AND_ISR</span> =&gt; handleLeaderAndIsrRequest(request)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">STOP_REPLICA</span> =&gt; handleStopReplicaRequest(request)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">UPDATE_METADATA_KEY</span> =&gt; handleUpdateMetadataRequest(request)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">CONTROLLED_SHUTDOWN_KEY</span> =&gt; handleControlledShutdownRequest(request)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">OFFSET_COMMIT</span> =&gt; handleOffsetCommitRequest(request)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">OFFSET_FETCH</span> =&gt; handleOffsetFetchRequest(request)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">GROUP_COORDINATOR</span> =&gt; handleGroupCoordinatorRequest(request)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">JOIN_GROUP</span> =&gt; handleJoinGroupRequest(request)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">HEARTBEAT</span> =&gt; handleHeartbeatRequest(request)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">LEAVE_GROUP</span> =&gt; handleLeaveGroupRequest(request)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">SYNC_GROUP</span> =&gt; handleSyncGroupRequest(request)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">DESCRIBE_GROUPS</span> =&gt; handleDescribeGroupRequest(request)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">LIST_GROUPS</span> =&gt; handleListGroupsRequest(request)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">SASL_HANDSHAKE</span> =&gt; handleSaslHandshakeRequest(request)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">API_VERSIONS</span> =&gt; handleApiVersionsRequest(request)</span><br><span class="line">        <span class="keyword">case</span> requestId =&gt; <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">KafkaException</span>(<span class="string">"Unknown api code "</span> + requestId)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;<span class="keyword">catch</span> &#123;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">finally</span></span><br><span class="line">      request.apiLocalCompleteTimeMs = <span class="type">SystemTime</span>.milliseconds</span><br></pre></td></tr></table></figure></p>
<p>显然，此处处理的速度影响Kafka整体的消息处理的速度。<br>这里我们分析一个处理方法handleProducerRequest。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Handle a produce request</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">handleProducerRequest</span></span>(request: <span class="type">RequestChannel</span>.<span class="type">Request</span>) &#123;</span><br><span class="line">    <span class="keyword">val</span> produceRequest = request.body.asInstanceOf[<span class="type">ProduceRequest</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment">// the callback for sending a produce response</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sendResponseCallback</span></span>(responseStatus: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">PartitionResponse</span>]) &#123;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">var</span> errorInResponse = <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">      mergedResponseStatus.foreach &#123; <span class="keyword">case</span> (topicPartition, status) =&gt;</span><br><span class="line">        <span class="keyword">if</span> (status.errorCode != <span class="type">Errors</span>.<span class="type">NONE</span>.code) &#123;</span><br><span class="line">          errorInResponse = <span class="literal">true</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="function"><span class="keyword">def</span> <span class="title">produceResponseCallback</span></span>(delayTimeMs: <span class="type">Int</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (produceRequest.acks == <span class="number">0</span>) &#123;</span><br><span class="line">          <span class="comment">// no operation needed if producer request.required.acks = 0; however, if there is any error in handling</span></span><br><span class="line">          <span class="comment">// the request, since no response is expected by the producer, the server will close socket server so that</span></span><br><span class="line">          <span class="comment">// the producer client will know that some error has happened and will refresh its metadata</span></span><br><span class="line">          <span class="keyword">if</span> (errorInResponse) &#123;</span><br><span class="line">            <span class="keyword">val</span> exceptionsSummary = mergedResponseStatus.map &#123; <span class="keyword">case</span> (topicPartition, status) =&gt;</span><br><span class="line">              topicPartition -&gt; <span class="type">Errors</span>.forCode(status.errorCode).exceptionName</span><br><span class="line">            &#125;.mkString(<span class="string">", "</span>)</span><br><span class="line">            requestChannel.closeConnection(request.processor, request)</span><br><span class="line">          &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            requestChannel.noOperation(request.processor, request)</span><br><span class="line">          &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="keyword">val</span> respHeader = <span class="keyword">new</span> <span class="type">ResponseHeader</span>(request.header.correlationId)</span><br><span class="line">          <span class="keyword">val</span> respBody = request.header.apiVersion <span class="keyword">match</span> &#123;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">0</span> =&gt; <span class="keyword">new</span> <span class="type">ProduceResponse</span>(mergedResponseStatus.asJava)</span><br><span class="line">            <span class="keyword">case</span> version@(<span class="number">1</span> | <span class="number">2</span>) =&gt; <span class="keyword">new</span> <span class="type">ProduceResponse</span>(mergedResponseStatus.asJava, delayTimeMs, version)</span><br><span class="line">            <span class="comment">// This case shouldn't happen unless a new version of ProducerRequest is added without</span></span><br><span class="line">            <span class="comment">// updating this part of the code to handle it properly.</span></span><br><span class="line">            <span class="keyword">case</span> version =&gt; <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalArgumentException</span>(<span class="string">s"Version `<span class="subst">$version</span>` of ProduceRequest is not handled. Code must be updated."</span>)</span><br><span class="line">          &#125;</span><br><span class="line"></span><br><span class="line">          requestChannel.sendResponse(<span class="keyword">new</span> <span class="type">RequestChannel</span>.<span class="type">Response</span>(request, <span class="keyword">new</span> <span class="type">ResponseSend</span>(request.connectionId, respHeader, respBody)))</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// When this callback is triggered, the remote API call has completed</span></span><br><span class="line">      request.apiRemoteCompleteTimeMs = <span class="type">SystemTime</span>.milliseconds</span><br><span class="line"></span><br><span class="line">      quotaManagers(<span class="type">ApiKeys</span>.<span class="type">PRODUCE</span>.id).recordAndMaybeThrottle(</span><br><span class="line">        request.header.clientId,</span><br><span class="line">        numBytesAppended,</span><br><span class="line">        produceResponseCallback)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (authorizedRequestInfo.isEmpty)</span><br><span class="line">      sendResponseCallback(<span class="type">Map</span>.empty)</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">val</span> internalTopicsAllowed = request.header.clientId == <span class="type">AdminUtils</span>.<span class="type">AdminClientId</span></span><br><span class="line"></span><br><span class="line">      <span class="comment">// Convert ByteBuffer to ByteBufferMessageSet</span></span><br><span class="line">      <span class="keyword">val</span> authorizedMessagesPerPartition = authorizedRequestInfo.map &#123;</span><br><span class="line">        <span class="keyword">case</span> (topicPartition, buffer) =&gt; (topicPartition, <span class="keyword">new</span> <span class="type">ByteBufferMessageSet</span>(buffer))</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// call the replica manager to append messages to the replicas</span></span><br><span class="line">      replicaManager.appendMessages(</span><br><span class="line">        produceRequest.timeout.toLong,</span><br><span class="line">        produceRequest.acks,</span><br><span class="line">        internalTopicsAllowed,</span><br><span class="line">        authorizedMessagesPerPartition,</span><br><span class="line">        sendResponseCallback)</span><br><span class="line"></span><br><span class="line">      <span class="comment">// if the request is put into the purgatory, it will have a held reference</span></span><br><span class="line">      <span class="comment">// and hence cannot be garbage collected; hence we clear its data here in</span></span><br><span class="line">      <span class="comment">// order to let GC re-claim its memory since it is already appended to log</span></span><br><span class="line">      produceRequest.clearPartitionRecords()</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></p>
<p>这里会调用replicaManager.appendMessages处理Kafka message的保存和备份,也就是leader和备份节点上。</p>
<h3 id="Replication-Subsystem"><a href="#Replication-Subsystem" class="headerlink" title="Replication Subsystem"></a>Replication Subsystem</h3><p>顺藤摸瓜，我们进入replicaManager.appendMessages的代码。<br>这个方法会将消息放到leader分区上，并复制到备份分区上。在超时或者根据required acks的值及时返回response。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Append messages to leader replicas of the partition, and wait for them to be replicated to other replicas;</span></span><br><span class="line"><span class="comment">   * the callback function will be triggered either when timeout or the required acks are satisfied</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">appendMessages</span></span>(timeout: <span class="type">Long</span>,</span><br><span class="line">                     requiredAcks: <span class="type">Short</span>,</span><br><span class="line">                     internalTopicsAllowed: <span class="type">Boolean</span>,</span><br><span class="line">                     messagesPerPartition: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">MessageSet</span>],</span><br><span class="line">                     responseCallback: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">PartitionResponse</span>] =&gt; <span class="type">Unit</span>) &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (isValidRequiredAcks(requiredAcks)) &#123;</span><br><span class="line">      <span class="keyword">val</span> sTime = <span class="type">SystemTime</span>.milliseconds</span><br><span class="line">      <span class="keyword">val</span> localProduceResults = appendToLocalLog(internalTopicsAllowed, messagesPerPartition, requiredAcks)</span><br><span class="line">      debug(<span class="string">"Produce to local log in %d ms"</span>.format(<span class="type">SystemTime</span>.milliseconds - sTime))</span><br><span class="line"></span><br><span class="line">      <span class="keyword">val</span> produceStatus = localProduceResults.map &#123; <span class="keyword">case</span> (topicPartition, result) =&gt;</span><br><span class="line">        topicPartition -&gt;</span><br><span class="line">                <span class="type">ProducePartitionStatus</span>(</span><br><span class="line">                  result.info.lastOffset + <span class="number">1</span>, <span class="comment">// required offset</span></span><br><span class="line">                  <span class="keyword">new</span> <span class="type">PartitionResponse</span>(result.errorCode, result.info.firstOffset, result.info.timestamp)) <span class="comment">// response status</span></span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (delayedRequestRequired(requiredAcks, messagesPerPartition, localProduceResults)) &#123;</span><br><span class="line">        <span class="comment">// create delayed produce operation</span></span><br><span class="line">        <span class="keyword">val</span> produceMetadata = <span class="type">ProduceMetadata</span>(requiredAcks, produceStatus)</span><br><span class="line">        <span class="keyword">val</span> delayedProduce = <span class="keyword">new</span> <span class="type">DelayedProduce</span>(timeout, produceMetadata, <span class="keyword">this</span>, responseCallback)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// create a list of (topic, partition) pairs to use as keys for this delayed produce operation</span></span><br><span class="line">        <span class="keyword">val</span> producerRequestKeys = messagesPerPartition.keys.map(<span class="keyword">new</span> <span class="type">TopicPartitionOperationKey</span>(_)).toSeq</span><br><span class="line"></span><br><span class="line">        <span class="comment">// try to complete the request immediately, otherwise put it into the purgatory</span></span><br><span class="line">        <span class="comment">// this is because while the delayed produce operation is being created, new</span></span><br><span class="line">        <span class="comment">// requests may arrive and hence make this operation completable.</span></span><br><span class="line">        delayedProducePurgatory.tryCompleteElseWatch(delayedProduce, producerRequestKeys)</span><br><span class="line"></span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// we can respond immediately</span></span><br><span class="line">        <span class="keyword">val</span> produceResponseStatus = produceStatus.mapValues(status =&gt; status.responseStatus)</span><br><span class="line">        responseCallback(produceResponseStatus)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// If required.acks is outside accepted range, something is wrong with the client</span></span><br><span class="line">      <span class="comment">// Just return an error and don't handle the request at all</span></span><br><span class="line">      <span class="keyword">val</span> responseStatus = messagesPerPartition.map &#123;</span><br><span class="line">        <span class="keyword">case</span> (topicAndPartition, messageSet) =&gt;</span><br><span class="line">          (topicAndPartition -&gt; <span class="keyword">new</span> <span class="type">PartitionResponse</span>(<span class="type">Errors</span>.<span class="type">INVALID_REQUIRED_ACKS</span>.code,</span><br><span class="line">                                                      <span class="type">LogAppendInfo</span>.<span class="type">UnknownLogAppendInfo</span>.firstOffset,</span><br><span class="line">                                                      <span class="type">Message</span>.<span class="type">NoTimestamp</span>))</span><br><span class="line">      &#125;</span><br><span class="line">      responseCallback(responseStatus)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="Log-Subsystem"><a href="#Log-Subsystem" class="headerlink" title="Log Subsystem"></a>Log Subsystem</h3><p>LogManager负责管理Kafka的Log(Kafka消息)， 包括log/Log文件夹的创建，获取和清理。它也会通过定时器检查内存中的log是否要缓存到磁盘中。重要的类包括LogManager和Log。</p>
<h3 id="OffsetManager"><a href="#OffsetManager" class="headerlink" title="OffsetManager"></a>OffsetManager</h3><p>负责管理offset，提供offset的读写。</p>
<h3 id="TopicConfigManager"><a href="#TopicConfigManager" class="headerlink" title="TopicConfigManager"></a>TopicConfigManager</h3><p>它负责动态改变Topic的配置属性。<br>如果某个topic的配置属性改变了，Kafka会在ZooKeeper上创建一个类似/brokers/config_changes/config_change_13321的节点， topicConfigManager会监控这些节点， 获得属性改变的topics并处理,实际上以新的LogConfig替换老的</p>
<h2 id="RequestChannel"><a href="#RequestChannel" class="headerlink" title="RequestChannel"></a>RequestChannel</h2><p>在Kafka的网络通信层中，RequestChannel为Processor处理器线程与KafkaRequestHandler线程之间的数据交换提供了一个数据缓冲区，是通信过程中Request和Response缓存的地方。因此，其作用就是在通信中起到了一个数据缓冲队列的作用。Processor线程将读取到的请求添加至RequestChannel的全局请求队列—requestQueue中；KafkaRequestHandler线程从请求队列中获取并处理，处理完以后将Response添加至RequestChannel的响应队列—responseQueue中，并通过responseListeners唤醒对应的Processor线程，最后Processor线程从响应队列中取出后发送至客户端。</p>
<p>到这里为止，一个请求从 Processor 接收，到 KafkaRequestHandler 通过 KafkaApis 处理并放回该 Processor 对应的 response queue 这整个过程就完成了（建议阅读本文的时候结合最前面的流程图一起看）。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://cloud.tencent.com/developer/article/1329040" title="消息中间件—简谈Kafka中的NIO网络通信模型" target="_blank" rel="noopener">消息中间件—简谈Kafka中的NIO网络通信模型</a></p>
<p><a href="https://bbs.huaweicloud.com/blogs/4d192a25ea1311e79fc57ca23e93a89f" title="kafka源码解析之八：Broker分析" target="_blank" rel="noopener">kafka源码解析之八：Broker分析</a></p>
</div><div class="tags"><a href="/tags/kafka/">kafka</a></div><div class="post-nav"><a class="pre" href="/2018/11/26/Kafka-源码解析之-Producer-NIO网络模型（二）/">Kafka-源码解析之-Producer NIO网络模型（二）</a><a class="next" href="/2018/11/24/hello-world/">Hello World</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.baidu.com/baidu" method="get" accept-charset="utf-8" target="_blank"><input type="search" name="word" maxlength="20" placeholder="Search"><input type="hidden" name="si" value="http://yoursite.com"><input name="tn" type="hidden" value="bds"><input name="cl" type="hidden" value="3"><input name="ct" type="hidden" value="2097152"><input name="s" type="hidden" value="on"></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/大数据/">大数据</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/kafka/" style="font-size: 15px;">kafka</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/11/26/Kafka-最佳实践之-Producer-性能调优（二）/">Kafka-最佳实践之-Producer-性能调优（二）</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/26/Kafka-最佳实践之-Broker-性能调优（一）/">Kafka-最佳实践之-Broker-性能调优（一）</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/26/Kafka-源码解析之-Producer-NIO网络模型（二）/">Kafka-源码解析之-Producer NIO网络模型（二）</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/24/Kafka-源码解析之-Server-1-N-M-网络处理模型（一）/">Kafka 源码解析之 Server 1+N+M 网络处理模型（一）</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/24/hello-world/">Hello World</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://tech.meituan.com/" title="美团技术博客" target="_blank">美团技术博客</a><ul></ul><a href="http://jm.taobao.org/categories/" title="阿里中间件团队博客" target="_blank">阿里中间件团队博客</a><ul></ul><a href="http://lxw1234.com/" title="lxw的技术天地" target="_blank">lxw的技术天地</a><ul></ul><a href="http://hbasefly.com/" title="范欣欣~有态度的HBase" target="_blank">范欣欣~有态度的HBase</a><ul></ul><a href="http://orchome.com" title="Kafka技术博客~OrcHome" target="_blank">Kafka技术博客~OrcHome</a><ul></ul><a href="http://cwiki.apachecn.org/pages/viewpage.action?pageId=4260364" title="Elasticsearch 5.4 中文文档" target="_blank">Elasticsearch 5.4 中文文档</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/." rel="nofollow">Steffen's Blog.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>