<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Steffen&#39;s Blog</title>
  
  <subtitle>唐良运</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-11-26T12:57:48.615Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>唐良运</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Kafka-最佳实践之-Producer-性能调优（二）</title>
    <link href="http://yoursite.com/2018/11/26/Kafka-%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5%E4%B9%8B-Producer-%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%EF%BC%88%E4%BA%8C%EF%BC%89/"/>
    <id>http://yoursite.com/2018/11/26/Kafka-最佳实践之-Producer-性能调优（二）/</id>
    <published>2018-11-26T12:57:48.000Z</published>
    <updated>2018-11-26T12:57:48.615Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Kafka-最佳实践之-Broker-性能调优（一）</title>
    <link href="http://yoursite.com/2018/11/26/Kafka-%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5%E4%B9%8B-Broker-%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%EF%BC%88%E4%B8%80%EF%BC%89/"/>
    <id>http://yoursite.com/2018/11/26/Kafka-最佳实践之-Broker-性能调优（一）/</id>
    <published>2018-11-26T12:57:12.000Z</published>
    <updated>2018-11-27T02:49:36.144Z</updated>
    
    <content type="html"><![CDATA[<p>通过扩展节点资源，来达到千万TPS等海量吞吐诉求，实际上，我们大部分业务可能不需要那么大规模，对于集群资源有限，如何最大可能调优kafka集群性能，下面我们从broker、producer、consumer 3个方面性能相关参数详细解析，实测解密集群如何最大性能化</p><h1 id="Broker篇"><a href="#Broker篇" class="headerlink" title="Broker篇"></a>Broker篇</h1><h2 id="网络模型相关参数"><a href="#网络模型相关参数" class="headerlink" title="网络模型相关参数"></a>网络模型相关参数</h2><p>关于kafka网络模型的原理请查看上一篇博客：<a href="https://itcrazy0918.github.io/2018/11/24/Kafka-%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E4%B9%8B-Server-1-N-M-%E7%BD%91%E7%BB%9C%E5%A4%84%E7%90%86%E6%A8%A1%E5%9E%8B%EF%BC%88%E4%B8%80%EF%BC%89/" title="Kafka 源码解析之 Server 1+N+M 网络处理模型（一）" target="_blank" rel="noopener">Kafka 源码解析之 Server 1+N+M 网络处理模型（一）</a></p><h3 id="参数描述"><a href="#参数描述" class="headerlink" title="参数描述"></a>参数描述</h3><table><thead><tr><th style="text-align:center">参数</th><th style="text-align:center">默认值</th><th style="text-align:center">说明</th></tr></thead><tbody><tr><td style="text-align:center">num.network.threads</td><td style="text-align:center">3</td><td style="text-align:center">Broker用来处理网络请求的网络线程数目；主要处理网络io，读写缓冲区数据，基本没有io等待，配置线程数量为cpu核数加1.</td></tr><tr><td style="text-align:center">num.io.threads</td><td style="text-align:center">8</td><td style="text-align:center">broker用来处理请求的I/O线程的数目；主要进行磁盘io操作，高峰期可能有些io等待，因此配置需要大些。配置线程数量为cpu核数2倍，最大不超过3倍</td></tr><tr><td style="text-align:center">queued.max.requests</td><td style="text-align:center">500</td><td style="text-align:center">在网络线程停止读取新请求之前，可以排队等待I/O线程处理的最大请求个数;超过该值，network thread阻塞</td></tr></tbody></table><p>Kafka网络通信层的完整框架图如下图所示：<br><img src="/2018/11/26/Kafka-最佳实践之-Broker-性能调优（一）/kafka-broker-inter.png" alt="Kafka Server 网络通信框架图"></p><p>Kafka使用NIO自己实现了网络层的代码， 而不是采用netty, mina等第三方的网络框架。从性能上来讲，这一块的代码不是性能的瓶颈。</p><p>它采用IO多路复用和多线程下的Reactor模式,主要实现类包括SocketServer, Acceptor, Processor和RequestChannel。</p><p>Kafka的服务器由SocketServer实现,它是一个NIO的服务器，线程模型如下：</p><ul><li><code>1个Acceptor</code>线程负责处理新连接</li><li><code>N个Processor</code>线程， 每个processor都有自己的selector，负责从socket中读取请求和发送response</li><li><code>M个Handler</code>线程处理请求，并产生response给processor线程</li></ul><p>可以从上面的图形中看到Acceptor, Processor和Handler的功能<br>其中num.network.threads是控制上图中的Processor Thread的个数， num.io.threads是控制API Thread的个数，queued.max_requests是控制Request Channel队列的容量</p><h2 id="日志保存策略"><a href="#日志保存策略" class="headerlink" title="日志保存策略"></a>日志保存策略</h2><table><thead><tr><th style="text-align:center">参数</th><th style="text-align:center">默认值</th><th style="text-align:center">说明</th></tr></thead><tbody><tr><td style="text-align:center">log.retention.hours</td><td style="text-align:center">168</td><td style="text-align:center">当kafka broker的被写入海量消息后，会生成很多数据文件，占用大量磁盘空间，kafka默认是保留7天，建议根据磁盘情况配置，避免磁盘撑爆</td></tr><tr><td style="text-align:center">log.segment.bytes</td><td style="text-align:center">1GB</td><td style="text-align:center">段文件配置1GB，有利于快速回收磁盘空间，重启kafka加载也会加快(如果文件过小，则文件数量比较多，kafka启动时是单线程扫描目录(log.dir)下所有数据文件)</td></tr></tbody></table><h2 id="Replica-副本配置"><a href="#Replica-副本配置" class="headerlink" title="Replica 副本配置"></a>Replica 副本配置</h2><table><thead><tr><th style="text-align:center">参数</th><th style="text-align:center">默认值</th><th style="text-align:center">推荐值</th><th style="text-align:center">说明</th></tr></thead><tbody><tr><td style="text-align:center">replica.socket.receive.buffer.bytes</td><td style="text-align:center">64*1024</td><td style="text-align:center">256k~2M</td><td style="text-align:center">备份时向leader发送网络请求时的socket receive buffer</td></tr><tr><td style="text-align:center">replica.fetch.max.bytes</td><td style="text-align:center">1024*1024</td><td style="text-align:center">根据业务实际配置</td><td style="text-align:center">备份时每次fetch的最大值</td></tr><tr><td style="text-align:center">num.replica.fetchers</td><td style="text-align:center">1</td><td style="text-align:center">默认值</td><td style="text-align:center">从leader备份数据的线程数</td></tr></tbody></table><ol><li>replica.socket.receive.buffer.bytes： 同TCP buffer的分析，不少于BDP 窗口大小，时延高的可以设大一点</li><li><p>replica.fetch.max.bytes:  不得少于发往broker消息的最大长度（message.max.bytes），需要根据业务实际消息的大小，然后设大一点即可。</p></li><li><p>num.replica.fetchers： 复制fetch线程设置大一点可以提升获取性能，同时增加备机的IO并行性，但设置太大也没用反而导致空闲，这个同Consumer的fetch thread一样。</p></li></ol><p>在ACK=1的情况下，Produce/Consumer的性能与复制关系不是很大，除非受到网络的瓶颈</p><p>参考</p><ol><li><a href="https://bbs.huaweicloud.com/blogs/eca0c026873311e7b8317ca23e93a891" title="kafka性能调优解密（一）-- Broker端" target="_blank" rel="noopener">kafka性能调优解密（一）– Broker端</a></li><li><a href="http://orchome.com/472" title="Kafka Broker配置（0.10版）" target="_blank" rel="noopener">Kafka Broker配置（0.10版）</a></li><li><a href="https://blog.csdn.net/airfish20000/article/details/77430542" title="Kafka测试及性能调优详细总结" target="_blank" rel="noopener">Kafka测试及性能调优详细总结</a></li><li><a href="https://blog.csdn.net/stark_summer/article/details/50203133" title="kafka性能参数和压力测试揭秘" target="_blank" rel="noopener">kafka性能参数和压力测试揭秘</a></li><li><a href="https://blog.csdn.net/bluetjs/article/details/80485359" title="kafka性能调优" target="_blank" rel="noopener">kafka性能调优</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;通过扩展节点资源，来达到千万TPS等海量吞吐诉求，实际上，我们大部分业务可能不需要那么大规模，对于集群资源有限，如何最大可能调优kafka集群性能，下面我们从broker、producer、consumer 3个方面性能相关参数详细解析，实测解密集群如何最大性能化&lt;/p&gt;

      
    
    </summary>
    
      <category term="大数据" scheme="http://yoursite.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="kafka" scheme="http://yoursite.com/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka-源码解析之-Producer NIO网络模型（二）</title>
    <link href="http://yoursite.com/2018/11/26/Kafka-%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E4%B9%8B-Producer-NIO%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%EF%BC%88%E4%BA%8C%EF%BC%89/"/>
    <id>http://yoursite.com/2018/11/26/Kafka-源码解析之-Producer-NIO网络模型（二）/</id>
    <published>2018-11-26T12:53:59.000Z</published>
    <updated>2018-12-01T15:56:47.217Z</updated>
    
    <content type="html"><![CDATA[<p>在写这篇文章之前，专门看了一下 Java NIO 相关的内容，只有理解了 Java NIO 模型才能更好地理解 NIO 在 Kafka 中是如何应用的以及 Producer 如何利用 Java NIO 构建其网络模型（不了解的，可以先看一下上一篇文章：<a href="http://matt33.com/2017/08/12/java-nio/" title="谈一谈 Java IO 模型" target="_blank" rel="noopener">谈一谈 Java IO 模型</a>），同时，本文也是对 Producer 整个流程的一个总结，主要讲述以下两个问题：</p><ol><li>Producer 的大概网络模型，与 Java NIO 模型之间关系；</li><li>Producer 整体流程及其整体流程详解。</li></ol><p>#Producer 的网络模型<br>KafkaProducer 通过 Sender 进行相应的 IO 操作，而 Sender 又调用 NetworkClient 来进行 IO 操作，NetworkClient 底层是对 Java NIO 进行相应的封装，其网络模型如下图所示（该图参考：<a href="http://blog.csdn.net/chunlongyu/article/details/52636762" title="Kafka源码深度解析－序列3 －Producer －Java NIO" target="_blank" rel="noopener">Kafka源码深度解析－序列3 －Producer －Java NIO</a>，在其基础上增加一个 KafkaProducer 成员变量的图形）。<br><img src="/2018/11/26/Kafka-源码解析之-Producer-NIO网络模型（二）/producer-network.png" alt="Prodcuer 网络模型"></p><p>从图中可以看出，Sender 为最上层的接口，即调用层，Sender 调用 NetworkClient，NetworkClient 调用 Selector，而 Selector 底层封装了 Java NIO 的相关接口，从右边的图也可以看出它们之间的关系。</p><p>#Producer 整体流程<br>有了对 Producer 网络模型的大概框架认识之后，下面再深入进去，看一下它们之间的调用关系以及 Producer 是如何调用 Java NIO 的相关接口，Producer 端的整体流程如下图所示。<br><img src="/2018/11/26/Kafka-源码解析之-Producer-NIO网络模型（二）/producer-nio-flow.png" alt="Producer 整体流程"></p><p>这里涉及到的主要方法是：</p><ul><li><strong>KafkaProducer.dosend()；</strong></li><li><strong>Sender.run()；</strong></li><li><strong>NetworkClient.poll()（NetworkClient.dosend()）；</strong></li><li><strong>Selector.poll()；</strong></li></ul><p>下面会结合上图，对这几个方法做详细的讲解，本文下面的内容都是结合上图进行讲解。</p><p>##KafkaProducer.dosend()<br>dosend() 方法是 Producer 的入口，dosend() 主要做了两个事情：</p><ul><li>waitOnMetadata()：请求更新 tp（topic-partition） meta，中间会调用 sender.wakeup()；</li><li>accumulator.append()：将 msg 写入到其 tp 对应的 deque 中，如果该 tp 对应的 deque 新建了一个 Batch，最后也会调用 sender.wakeup()。<br>这里主要关注的是 sender.wakeup() 方法，它的作用是将 Sender 线程从阻塞中唤醒。</li></ul><p>###sender.wakeup() 方法<br>这里来看一下 sender.wakeup() 具体实现：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// org.apache.kafka.clients.producer.internals.Sender</span></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* Wake up the selector associated with this send thread</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line">public void wakeup() &#123;</span><br><span class="line">    <span class="keyword">this</span>.client.wakeup();</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// org.apache.kafka.clients.NetworkClient</span></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* Interrupt the client if it is blocked waiting on I/O.</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line">public void wakeup() &#123;</span><br><span class="line">    <span class="keyword">this</span>.selector.wakeup();</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// org.apache.kafka.common.network.Selector</span></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* Interrupt the nioSelector if it is blocked waiting to do I/O.</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="comment">//note: 如果 selector 是阻塞的话,就唤醒</span></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line">public void wakeup() &#123;</span><br><span class="line">    <span class="keyword">this</span>.nioSelector.wakeup();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>这个方法很简单，但也很有意思，其调用过程是下面这个样子：</p><ul><li>Sender -&gt; NetworkClient -&gt; Selector(Kafka 封装的) -&gt; Selector(Java NIO)</li></ul><p>跟上面两张图中 KafkaProducer 的总体调用过程大概一致，它的作用就是将 Sender 线程从 select() 方法的阻塞中唤醒，select() 方法的作用是轮询注册在多路复用器上的 Channel，它会一直阻塞在这个方法上，除非满足下面条件中的一个：</p><ul><li>at least one channel is selected;</li><li>this selector’s {@link #wakeup wakeup} method is invoked;</li><li>the current thread is interrupted;</li><li>the given timeout period expires.</li></ul><p>否则 select() 将会一直轮询，阻塞在这个地方，直到条件满足。</p><p>分析到这里，KafkaProducer 中 dosend() 方法调用 sender.wakeup() 方法作用就很明显的，作用就是：当有新的 RecordBatch 创建后，旧的 RecordBatch 就可以发送了（或者此时有 Metadata 请求需要发送），如果线程阻塞在 select() 方法中，就将其唤醒，Sender 重新开始运行 run() 方法，在这个方法中，旧的 RecordBatch （或相应的 Metadata 请求）将会被选中，进而可以及时将这些请求发送出去。</p><p>###Sender.run()<br>每次循环都是从 Sender 的 run() 方法开始，具体代码如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//note: Sender 线程每次循环具体执行的地方</span></span><br><span class="line">    void run(long now) &#123;</span><br><span class="line">        <span class="type">Cluster</span> cluster = metadata.fetch();</span><br><span class="line">        <span class="comment">//note: Step1 获取那些已经可以发送的 RecordBatch 对应的 nodes</span></span><br><span class="line">        <span class="type">RecordAccumulator</span>.<span class="type">ReadyCheckResult</span> result = <span class="keyword">this</span>.accumulator.ready(cluster, now);</span><br><span class="line">        <span class="comment">//note: Step2  如果有 topic-partition 的 leader 是未知的,就强制 metadata 更新</span></span><br><span class="line">        <span class="keyword">if</span> (!result.unknownLeaderTopics.isEmpty()) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">String</span> topic : result.unknownLeaderTopics)</span><br><span class="line">                <span class="keyword">this</span>.metadata.add(topic);</span><br><span class="line">            <span class="keyword">this</span>.metadata.requestUpdate();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//note: 如果与node 没有连接（如果可以连接,会初始化该连接）,暂时先移除该 node</span></span><br><span class="line">        <span class="type">Iterator</span>&lt;<span class="type">Node</span>&gt; iter = result.readyNodes.iterator();</span><br><span class="line">        long notReadyTimeout = <span class="type">Long</span>.<span class="type">MAX_VALUE</span>;</span><br><span class="line">        <span class="keyword">while</span> (iter.hasNext()) &#123;</span><br><span class="line">            <span class="type">Node</span> node = iter.next();</span><br><span class="line">            <span class="keyword">if</span> (!<span class="keyword">this</span>.client.ready(node, now)) &#123;<span class="comment">//note: 没有建立连接的 broker,这里会与其建立连接</span></span><br><span class="line">                iter.remove();</span><br><span class="line">                notReadyTimeout = <span class="type">Math</span>.min(notReadyTimeout, <span class="keyword">this</span>.client.connectionDelay(node, now));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//note: Step3  返回该 node 对应的所有可以发送的 RecordBatch 组成的 batches（key 是 node.id,这些 batches 将会在一个 request 中发送）</span></span><br><span class="line">        <span class="type">Map</span>&lt;<span class="type">Integer</span>, <span class="type">List</span>&lt;<span class="type">RecordBatch</span>&gt;&gt; batches = <span class="keyword">this</span>.accumulator.drain(cluster,</span><br><span class="line">                                                                         result.readyNodes,</span><br><span class="line">                                                                         <span class="keyword">this</span>.maxRequestSize,</span><br><span class="line">                                                                         now);</span><br><span class="line">        <span class="comment">//note: 保证一个 tp 只有一个 RecordBatch 在发送,保证有序性</span></span><br><span class="line">        <span class="comment">//note: max.in.flight.requests.per.connection 设置为1时会保证</span></span><br><span class="line">        <span class="keyword">if</span> (guaranteeMessageOrder) &#123;</span><br><span class="line">            <span class="comment">// Mute all the partitions draine</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="type">List</span>&lt;<span class="type">RecordBatch</span>&gt; batchList : batches.values()) &#123;</span><br><span class="line">                <span class="keyword">for</span> (<span class="type">RecordBatch</span> batch : batchList)</span><br><span class="line">                    <span class="keyword">this</span>.accumulator.mutePartition(batch.topicPartition);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//note: 将由于元数据不可用而导致发送超时的 RecordBatch 移除</span></span><br><span class="line">        <span class="type">List</span>&lt;<span class="type">RecordBatch</span>&gt; expiredBatches = <span class="keyword">this</span>.accumulator.abortExpiredBatches(<span class="keyword">this</span>.requestTimeout, now);</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">RecordBatch</span> expiredBatch : expiredBatches)</span><br><span class="line">            <span class="keyword">this</span>.sensors.recordErrors(expiredBatch.topicPartition.topic(), expiredBatch.recordCount);</span><br><span class="line">        sensors.updateProduceRequestMetrics(batches);</span><br><span class="line">        long pollTimeout = <span class="type">Math</span>.min(result.nextReadyCheckDelayMs, notReadyTimeout);</span><br><span class="line">        <span class="keyword">if</span> (!result.readyNodes.isEmpty()) &#123;</span><br><span class="line">            log.trace(<span class="string">"Nodes with data ready to send: &#123;&#125;"</span>, result.readyNodes);</span><br><span class="line">            pollTimeout = <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//note: Step4 发送 RecordBatch</span></span><br><span class="line">        sendProduceRequests(batches, now);</span><br><span class="line">        <span class="comment">//note: 如果有 partition 可以立马发送数据,那么 pollTimeout 为0.</span></span><br><span class="line">        <span class="comment">//note: Step5 关于 socket 的一些实际的读写操作</span></span><br><span class="line">        <span class="keyword">this</span>.client.poll(pollTimeout, now);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p><p><code>Sender.run()</code> 的大概流程总共有以下五步：</p><ol><li><p>accumulator.ready()：遍历所有的 tp（topic-partition），如果其对应的 RecordBatch 可以发送（大小达到 <code>batch.size</code> 大小或时间达到 <code>linger.ms</code>），就将其对应的 leader 选出来，最后会返回一个可以发送 Produce request 的 <code>Set&lt;Node&gt;</code>（实际返回的是 ReadyCheckResult 实例，不过 <code>Set&lt;Node&gt;</code> 是最主要的成员变量）；</p></li><li><p>如果发现有 tp 没有 leader，那么这里就调用 <code>requestUpdate()</code> 方法更新 metadata，实际上还是在第一步对 tp 的遍历中，遇到没有 leader 的 tp 就将其加入到一个叫做 unknownLeaderTopics 的 set 中，然后会请求这个 tp 的 meta（meta 的更新策略可以参考之前的一篇博客 <a href="http://matt33.com/2017/07/08/kafka-producer-metadata/#Producer-Metadata-%E7%9A%84%E6%9B%B4%E6%96%B0%E7%AD%96%E7%95%A5" title="Producer Metadata 的更新策略" target="_blank" rel="noopener">Producer Metadata 的更新策略</a>）；</p></li><li><p>accumulator.drain()：遍历每个 leader （第一步中选出）上的所有 tp，如果该 tp 对应的 RecordBatch 不在 backoff 期间（没有重试过，或者重试了但是间隔已经达到了 retryBackoffMs ），并且加上这个 RecordBatch 其大小不超过 maxSize（一个 request 的最大限制，默认为 1MB），那么就把这个 RecordBatch 添加 list 中，最终返回的类型为 <code>Map&lt;Integer, List&lt;RecordBatch&gt;&gt;</code>，key 为 leader.id，value 为要发送的 RecordBatch 的列表；</p></li><li><p>sendProduceRequests()：发送 Produce 请求，从图中，可以看出，这个方法会调用 NetworkClient.send() 来发送 clientRequest；</p></li><li><p>NetworkClient.poll()：关于 socket 的 IO 操作都是在这个方法进行的，它还是调用 Selector 进行的相应操作，而 Selector 底层则是封装的 Java NIO 的相关接口，这个下面会详细讲述。</p></li></ol><p>在第三步中，可以看到，如果要向一个 leader 发送 Produce 请求，那么这 leader 对应 tp，如果其 RecordBatch 没有达到要求（batch.size 或 linger.ms 都没达到）还是可能会发送，这样做的好处是：可以减少 request 的频率，有利于提供发送效率。</p><p>###NetworkClient.poll()<br>这个方法也是一个非常重要的方法，其作用简单来说有三点：</p><ul><li>如果需要更新 Metadata，那么就发送 Metadata 请求；</li><li>调用 Selector 进行相应的 IO 操作；</li><li>处理 Server 端的 response 及一些其他的操作。</li></ul><p>具体代码如下所示：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">public <span class="type">List</span>&lt;<span class="type">ClientResponse</span>&gt; poll(long timeout, long now) &#123;</span><br><span class="line">        <span class="comment">//note: Step1 判断是否需要更新 meta,如果需要就更新（请求更新 metadata 的地方）</span></span><br><span class="line">        long metadataTimeout = metadataUpdater.maybeUpdate(now);</span><br><span class="line">        <span class="comment">//note: Step2 调用 Selector.poll() 进行 socket 相关的 IO 操作</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">this</span>.selector.poll(<span class="type">Utils</span>.min(timeout, metadataTimeout, requestTimeoutMs));</span><br><span class="line">        &#125; <span class="keyword">catch</span> (<span class="type">IOException</span> e) &#123;</span><br><span class="line">            log.error(<span class="string">"Unexpected error during I/O"</span>, e);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//note: Step3 处理完成后的操作</span></span><br><span class="line">        long updatedNow = <span class="keyword">this</span>.time.milliseconds();</span><br><span class="line">        <span class="type">List</span>&lt;<span class="type">ClientResponse</span>&gt; responses = <span class="keyword">new</span> <span class="type">ArrayList</span>&lt;&gt;();</span><br><span class="line">        handleAbortedSends(responses);</span><br><span class="line">        <span class="comment">//note: 处理已经完成的 send（不需要 response 的 request,如 send）</span></span><br><span class="line">        handleCompletedSends(responses, updatedNow);<span class="comment">//note: 通过 selector 中获取 Server 端的 response</span></span><br><span class="line">        <span class="comment">//note: 处理从 server 端接收到 Receive（如 Metadata 请求）</span></span><br><span class="line">        handleCompletedReceives(responses, updatedNow);<span class="comment">//note: 在返回的 handler 中，会处理 metadata 的更新</span></span><br><span class="line">        <span class="comment">//note: 处理连接失败那些连接,重新请求 meta</span></span><br><span class="line">        handleDisconnections(responses, updatedNow);</span><br><span class="line">        <span class="comment">//note: 处理新建立的那些连接（还不能发送请求,比如:还未认证）</span></span><br><span class="line">        handleConnections();</span><br><span class="line">        handleInitiateApiVersionRequests(updatedNow);</span><br><span class="line">        handleTimedOutRequests(responses, updatedNow);</span><br><span class="line">        <span class="comment">// invoke callbacks</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">ClientResponse</span> response : responses) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                response.onComplete();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (<span class="type">Exception</span> e) &#123;</span><br><span class="line">                log.error(<span class="string">"Uncaught error in request completion:"</span>, e);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> responses;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p><p>这个方法大致分为三步，这里详述讲述一下：</p><ol><li>metadataUpdater.maybeUpdate()：如果 Metadata 需要更新，那么就选择连接数最小的 node，发送 Metadata 请求，详细流程可以参考之前那篇博客<a href="http://matt33.com/2017/07/08/kafka-producer-metadata/#Producer-%E7%9A%84-Metadata-%E6%9B%B4%E6%96%B0%E6%B5%81%E7%A8%8B" title="Producer 的 Metadata 更新流程" target="_blank" rel="noopener">Producer 的 Metadata 更新流程</a>；</li><li>selector.poll()：进行 socket IO 相关的操作，下面会详细讲述；</li><li><p>process completed actions：在一个 select() 过程之后的相关处理。</p><ul><li>handleAbortedSends(responses)：处理那么在发送过程出现 UnsupportedVersionException 异常的 request；</li><li>handleCompletedSends(responses, updatedNow)：处理那些已经完成的 request，如果是那些不需要 response 的 request 的话，这里直接调用 request.completed()，标志着这个 request 发送处理完成；</li><li>handleCompletedReceives(responses, updatedNow)：处理那些从 Server 端接收的 Receive，metadata 更新就是在这里处理的（以及 ApiVersionsResponse）；</li><li>handleDisconnections(responses, updatedNow)：处理连接失败那些连接,重新请求 metadata；</li><li>handleConnections()：处理新建立的那些连接（还不能发送请求,比如:还未认证）；</li><li>handleInitiateApiVersionRequests(updatedNow)：对那些新建立的连接，发送 apiVersionRequest（默认情况：第一次建立连接时，需要向 Broker 发送 ApiVersionRequest 请求）；</li><li>handleTimedOutRequests(responses, updatedNow)：处理 timeout 的连接，关闭该连接，并刷新 Metadata。</li></ul><p>###Selector.poll()<br>Selector 类是 Kafka 对 Java NIO 相关接口的封装，socket IO 相关的操作都是这个类中完成的，这里先看一下 poll() 方法，主要的操作都是这个方法中调用的，其代码实现如下：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">public void poll(long timeout) <span class="keyword">throws</span> <span class="type">IOException</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (timeout &lt; <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalArgumentException</span>(<span class="string">"timeout should be &gt;= 0"</span>);</span><br><span class="line">        <span class="comment">//note: Step1 清除相关记录</span></span><br><span class="line">        clear();</span><br><span class="line">        <span class="keyword">if</span> (hasStagedReceives() || !immediatelyConnectedKeys.isEmpty())</span><br><span class="line">            timeout = <span class="number">0</span>;</span><br><span class="line">        <span class="comment">/* check ready keys */</span></span><br><span class="line">        <span class="comment">//note: Step2 获取就绪事件的数</span></span><br><span class="line">        long startSelect = time.nanoseconds();</span><br><span class="line">        int readyKeys = select(timeout);</span><br><span class="line">        long endSelect = time.nanoseconds();</span><br><span class="line">        <span class="keyword">this</span>.sensors.selectTime.record(endSelect - startSelect, time.milliseconds());</span><br><span class="line">        <span class="comment">//note: Step3 处理 io 操作</span></span><br><span class="line">        <span class="keyword">if</span> (readyKeys &gt; <span class="number">0</span> || !immediatelyConnectedKeys.isEmpty()) &#123;</span><br><span class="line">            pollSelectionKeys(<span class="keyword">this</span>.nioSelector.selectedKeys(), <span class="literal">false</span>, endSelect);</span><br><span class="line">            pollSelectionKeys(immediatelyConnectedKeys, <span class="literal">true</span>, endSelect);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//note: Step4 将处理得到的 stagedReceives 添加到 completedReceives 中</span></span><br><span class="line">        addToCompletedReceives();</span><br><span class="line">        long endIo = time.nanoseconds();</span><br><span class="line">        <span class="keyword">this</span>.sensors.ioTime.record(endIo - endSelect, time.milliseconds());</span><br><span class="line">        <span class="comment">// we use the time at the end of select to ensure that we don't close any connections that</span></span><br><span class="line">        <span class="comment">// have just been processed in pollSelectionKeys</span></span><br><span class="line">        <span class="comment">//note: 每次 poll 之后会调用一次</span></span><br><span class="line">        <span class="comment">//<span class="doctag">TODO:</span> 连接虽然关闭了,但是 Client 端的缓存依然存在</span></span><br><span class="line">        maybeCloseOldestConnection(endSelect);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>Selector.poll() 方法会进行四步操作，这里分别来介绍一些。</p><p>####clear()<br>clear() 方法是在每次 poll() 执行的第一步，它作用的就是清理上一次 poll 过程产生的部分缓存。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//note: 每次 poll 调用前都会清除以下缓存</span></span><br><span class="line"><span class="keyword">private</span> void clear() &#123;</span><br><span class="line">    <span class="keyword">this</span>.completedSends.clear();</span><br><span class="line">    <span class="keyword">this</span>.completedReceives.clear();</span><br><span class="line">    <span class="keyword">this</span>.connected.clear();</span><br><span class="line">    <span class="keyword">this</span>.disconnected.clear();</span><br><span class="line">    <span class="comment">// Remove closed channels after all their staged receives have been processed or if a send was requested</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">Iterator</span>&lt;<span class="type">Map</span>.<span class="type">Entry</span>&lt;<span class="type">String</span>, <span class="type">KafkaChannel</span>&gt;&gt; it = closingChannels.entrySet().iterator(); it.hasNext(); ) &#123;</span><br><span class="line">        <span class="type">KafkaChannel</span> channel = it.next().getValue();</span><br><span class="line">        <span class="type">Deque</span>&lt;<span class="type">NetworkReceive</span>&gt; deque = <span class="keyword">this</span>.stagedReceives.get(channel);</span><br><span class="line">        boolean sendFailed = failedSends.remove(channel.id());</span><br><span class="line">        <span class="keyword">if</span> (deque == <span class="literal">null</span> || deque.isEmpty() || sendFailed) &#123;</span><br><span class="line">            doClose(channel, <span class="literal">true</span>);</span><br><span class="line">            it.remove();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">this</span>.disconnected.addAll(<span class="keyword">this</span>.failedSends);</span><br><span class="line">    <span class="keyword">this</span>.failedSends.clear();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>####select()<br>Selector 的 select() 方法在实现上底层还是调用 Java NIO 原生的接口，这里的 nioSelector 其实就是 java.nio.channels.Selector 的实例对象，这个方法最坏情况下，会阻塞 ms 的时间，如果在一次轮询，只要有一个 Channel 的事件就绪，它就会立马返回。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> int select(long ms) <span class="keyword">throws</span> <span class="type">IOException</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (ms &lt; <span class="number">0</span>L)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalArgumentException</span>(<span class="string">"timeout should be &gt;= 0"</span>);</span><br><span class="line">    <span class="keyword">if</span> (ms == <span class="number">0</span>L)</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.nioSelector.selectNow();</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.nioSelector.select(ms);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>####pollSelectionKeys()<br>这部分是 socket IO 的主要部分，发送 Send 及接收 Receive 都是在这里完成的，在 poll() 方法中，这个方法会调用两次：</p><ol><li>第一次调用的目的是：处理已经就绪的事件，进行相应的 IO 操作；</li><li>第二次调用的目的是：处理新建立的那些连接，添加缓存及传输层（Kafka 又封装了一次，这里后续文章会讲述）的握手与认证。</li></ol><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> void pollSelectionKeys(<span class="type">Iterable</span>&lt;<span class="type">SelectionKey</span>&gt; selectionKeys,</span><br><span class="line">                                   boolean isImmediatelyConnected,</span><br><span class="line">                                   long currentTimeNanos) &#123;</span><br><span class="line">        <span class="type">Iterator</span>&lt;<span class="type">SelectionKey</span>&gt; iterator = selectionKeys.iterator();</span><br><span class="line">        <span class="keyword">while</span> (iterator.hasNext()) &#123;</span><br><span class="line">            <span class="type">SelectionKey</span> key = iterator.next();</span><br><span class="line">            iterator.remove();</span><br><span class="line">            <span class="type">KafkaChannel</span> channel = channel(key);</span><br><span class="line">            <span class="comment">// register all per-connection metrics at once</span></span><br><span class="line">            sensors.maybeRegisterConnectionMetrics(channel.id());</span><br><span class="line">            <span class="keyword">if</span> (idleExpiryManager != <span class="literal">null</span>)</span><br><span class="line">                idleExpiryManager.update(channel.id(), currentTimeNanos);</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="comment">/* complete any connections that have finished their handshake (either normally or immediately) */</span></span><br><span class="line">                <span class="comment">//note: 处理一些刚建立 tcp 连接的 channel</span></span><br><span class="line">                <span class="keyword">if</span> (isImmediatelyConnected || key.isConnectable()) &#123;</span><br><span class="line">                    <span class="keyword">if</span> (channel.finishConnect()) &#123;<span class="comment">//note: 连接已经建立</span></span><br><span class="line">                        <span class="keyword">this</span>.connected.add(channel.id());</span><br><span class="line">                        <span class="keyword">this</span>.sensors.connectionCreated.record();</span><br><span class="line">                        <span class="type">SocketChannel</span> socketChannel = (<span class="type">SocketChannel</span>) key.channel();</span><br><span class="line">                        log.debug(<span class="string">"Created socket with SO_RCVBUF = &#123;&#125;, SO_SNDBUF = &#123;&#125;, SO_TIMEOUT = &#123;&#125; to node &#123;&#125;"</span>,</span><br><span class="line">                                socketChannel.socket().getReceiveBufferSize(),</span><br><span class="line">                                socketChannel.socket().getSendBufferSize(),</span><br><span class="line">                                socketChannel.socket().getSoTimeout(),</span><br><span class="line">                                channel.id());</span><br><span class="line">                    &#125; <span class="keyword">else</span></span><br><span class="line">                        <span class="keyword">continue</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">/* if channel is not ready finish prepare */</span></span><br><span class="line">                <span class="comment">//note: 处理 tcp 连接还未完成的连接,进行传输层的握手及认证</span></span><br><span class="line">                <span class="keyword">if</span> (channel.isConnected() &amp;&amp; !channel.ready())</span><br><span class="line">                    channel.prepare();</span><br><span class="line">                <span class="comment">/* if channel is ready read from any connections that have readable data */</span></span><br><span class="line">                <span class="keyword">if</span> (channel.ready() &amp;&amp; key.isReadable() &amp;&amp; !hasStagedReceive(channel)) &#123;</span><br><span class="line">                    <span class="type">NetworkReceive</span> networkReceive;</span><br><span class="line">                    <span class="keyword">while</span> ((networkReceive = channel.read()) != <span class="literal">null</span>)<span class="comment">//note: 知道读取一个完整的 Receive,才添加到集合中</span></span><br><span class="line">                        addToStagedReceives(channel, networkReceive);<span class="comment">//note: 读取数据</span></span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">/* if channel is ready write to any sockets that have space in their buffer and for which we have data */</span></span><br><span class="line">                <span class="keyword">if</span> (channel.ready() &amp;&amp; key.isWritable()) &#123;</span><br><span class="line">                    <span class="type">Send</span> send = channel.write();</span><br><span class="line">                    <span class="keyword">if</span> (send != <span class="literal">null</span>) &#123;</span><br><span class="line">                        <span class="keyword">this</span>.completedSends.add(send);<span class="comment">//note: 将完成的 send 添加到 list 中</span></span><br><span class="line">                        <span class="keyword">this</span>.sensors.recordBytesSent(channel.id(), send.size());</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">/* cancel any defunct sockets */</span></span><br><span class="line">                <span class="comment">//note: 关闭断开的连接</span></span><br><span class="line">                <span class="keyword">if</span> (!key.isValid())</span><br><span class="line">                    close(channel, <span class="literal">true</span>);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (<span class="type">Exception</span> e) &#123;</span><br><span class="line">                <span class="type">String</span> desc = channel.socketDescription();</span><br><span class="line">                <span class="keyword">if</span> (e instanceof <span class="type">IOException</span>)</span><br><span class="line">                    log.debug(<span class="string">"Connection with &#123;&#125; disconnected"</span>, desc, e);</span><br><span class="line">                <span class="keyword">else</span></span><br><span class="line">                    log.warn(<span class="string">"Unexpected error from &#123;&#125;; closing connection"</span>, desc, e);</span><br><span class="line">                close(channel, <span class="literal">true</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>####addToCompletedReceives()<br>这个方法的目的是处理接收到的 Receive，由于 Selector 这个类在 Client 和 Server 端都会调用，这里分两种情况讲述一下：</p><ol><li>应用在 Server 端时，后续文章会详细介绍，这里简单说一下，Server 为了保证消息的时序性，在 Selector 中提供了两个方法：mute(String id) 和 unmute(String id)，对该 KafkaChannel 做标记来保证同时只能处理这个 Channel 的一个 request（可以理解为排它锁）。当 Server 端接收到 request 后，先将其放入 stagedReceives 集合中，此时该 Channel 还未 mute，这个 Receive 会被放入 completedReceives 集合中。Server 在对 completedReceives 集合中的 request 进行处理时，会先对该 Channel mute，处理后的 response 发送完成后再对该 Channel unmute，然后才能处理该 Channel 其他的请求；</li><li>应用在 Client 端时，Client 并不会调用 Selector 的 mute() 和 unmute() 方法，client 的时序性而是通过 InFlightRequests 和 RecordAccumulator 的 mutePartition 来保证的（下篇文章会讲述），因此对于 Client 端而言，这里接收到的所有 Receive 都会被放入到 completedReceives 的集合中等待后续处理。</li></ol><p>这个方法只有配合 Server 端的调用才能看明白其作用，它统一 Client 和 Server 调用的 api，使得都可以使用 Selector 这个类。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * checks if there are any staged receives and adds to completedReceives</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> void addToCompletedReceives() &#123;</span><br><span class="line">    <span class="keyword">if</span> (!<span class="keyword">this</span>.stagedReceives.isEmpty()) &#123;<span class="comment">//note: 处理 stagedReceives</span></span><br><span class="line">        <span class="type">Iterator</span>&lt;<span class="type">Map</span>.<span class="type">Entry</span>&lt;<span class="type">KafkaChannel</span>, <span class="type">Deque</span>&lt;<span class="type">NetworkReceive</span>&gt;&gt;&gt; iter = <span class="keyword">this</span>.stagedReceives.entrySet().iterator();</span><br><span class="line">        <span class="keyword">while</span> (iter.hasNext()) &#123;</span><br><span class="line">            <span class="type">Map</span>.<span class="type">Entry</span>&lt;<span class="type">KafkaChannel</span>, <span class="type">Deque</span>&lt;<span class="type">NetworkReceive</span>&gt;&gt; entry = iter.next();</span><br><span class="line">            <span class="type">KafkaChannel</span> channel = entry.getKey();</span><br><span class="line">            <span class="keyword">if</span> (!channel.isMute()) &#123;</span><br><span class="line">                <span class="type">Deque</span>&lt;<span class="type">NetworkReceive</span>&gt; deque = entry.getValue();</span><br><span class="line">                addToCompletedReceives(channel, deque);</span><br><span class="line">                <span class="keyword">if</span> (deque.isEmpty())</span><br><span class="line">                    iter.remove();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">private</span> void addToCompletedReceives(<span class="type">KafkaChannel</span> channel, <span class="type">Deque</span>&lt;<span class="type">NetworkReceive</span>&gt; stagedDeque) &#123;</span><br><span class="line">    <span class="type">NetworkReceive</span> networkReceive = stagedDeque.poll();</span><br><span class="line">    <span class="keyword">this</span>.completedReceives.add(networkReceive); <span class="comment">//note: 添加到 completedReceives 中</span></span><br><span class="line">    <span class="keyword">this</span>.sensors.recordBytesReceived(channel.id(), networkReceive.payload().limit());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>##Network.send() 方法<br>至此，文章的主要内容已经讲述得差不多了，第二张图中最上面的那个调用关系已经讲述完，下面讲述一下另外一个小分支，也就是从 Sender.run() 调用 NetworkClient.send() 开始的那部分，其调用过程如下：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Sender</span>.run()</span><br><span class="line"><span class="type">Sender</span>.sendProduceRequests()</span><br><span class="line"><span class="type">NetworkClient</span>.send()</span><br><span class="line"><span class="type">NetworkClient</span>.dosend()</span><br><span class="line"><span class="type">Selector</span>.send()</span><br><span class="line"><span class="type">KafkaChannel</span>.setSend()</span><br></pre></td></tr></table></figure></li></ol><p>####NetworkClient.dosend()<br>Producer 端的请求都是通过 NetworkClient.dosend() 来发送的，其作用就是：</p><ol><li>检查版本信息，并根据 apiKey() 构建 Request；</li><li>创建 NetworkSend 实例；</li><li>调用 Selector.send 发送该 Send。</li></ol><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//note: 发送请求</span></span><br><span class="line">    <span class="keyword">private</span> void doSend(<span class="type">ClientRequest</span> clientRequest, boolean isInternalRequest, long now) &#123;</span><br><span class="line">        <span class="type">String</span> nodeId = clientRequest.destination();</span><br><span class="line">        <span class="keyword">if</span> (!isInternalRequest) &#123;</span><br><span class="line">            <span class="comment">// If this request came from outside the NetworkClient, validate</span></span><br><span class="line">            <span class="comment">// that we can send data.  If the request is internal, we trust</span></span><br><span class="line">            <span class="comment">// that that internal code has done this validation.  Validation</span></span><br><span class="line">            <span class="comment">// will be slightly different for some internal requests (for</span></span><br><span class="line">            <span class="comment">// example, ApiVersionsRequests can be sent prior to being in</span></span><br><span class="line">            <span class="comment">// READY state.)</span></span><br><span class="line">            <span class="keyword">if</span> (!canSendRequest(nodeId))</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(<span class="string">"Attempt to send a request to node "</span> + nodeId + <span class="string">" which is not ready."</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="type">AbstractRequest</span> request = <span class="literal">null</span>;</span><br><span class="line">        <span class="type">AbstractRequest</span>.<span class="type">Builder</span>&lt;?&gt; builder = clientRequest.requestBuilder();</span><br><span class="line">        <span class="comment">//note: 构建 AbstractRequest, 检查其版本信息</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="type">NodeApiVersions</span> versionInfo = nodeApiVersions.get(nodeId);</span><br><span class="line">            <span class="comment">// Note: if versionInfo is null, we have no server version information. This would be</span></span><br><span class="line">            <span class="comment">// the case when sending the initial ApiVersionRequest which fetches the version</span></span><br><span class="line">            <span class="comment">// information itself.  It is also the case when discoverBrokerVersions is set to false.</span></span><br><span class="line">            <span class="keyword">if</span> (versionInfo == <span class="literal">null</span>) &#123;</span><br><span class="line">                <span class="keyword">if</span> (discoverBrokerVersions &amp;&amp; log.isTraceEnabled())</span><br><span class="line">                    log.trace(<span class="string">"No version information found when sending message of type &#123;&#125; to node &#123;&#125;. "</span> +</span><br><span class="line">                            <span class="string">"Assuming version &#123;&#125;."</span>, clientRequest.apiKey(), nodeId, builder.version());</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                short version = versionInfo.usableVersion(clientRequest.apiKey());</span><br><span class="line">                builder.setVersion(version);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// The call to build may also throw UnsupportedVersionException, if there are essential</span></span><br><span class="line">            <span class="comment">// fields that cannot be represented in the chosen version.</span></span><br><span class="line">            request = builder.build();<span class="comment">//note: 当为 Produce 请求时,转化为 ProduceRequest,Metadata 请求时,转化为 Metadata 请求</span></span><br><span class="line">        &#125; <span class="keyword">catch</span> (<span class="type">UnsupportedVersionException</span> e) &#123;</span><br><span class="line">            <span class="comment">// If the version is not supported, skip sending the request over the wire.</span></span><br><span class="line">            <span class="comment">// Instead, simply add it to the local queue of aborted requests.</span></span><br><span class="line">            log.debug(<span class="string">"Version mismatch when attempting to send &#123;&#125; to &#123;&#125;"</span>,</span><br><span class="line">                    clientRequest.toString(), clientRequest.destination(), e);</span><br><span class="line">            <span class="type">ClientResponse</span> clientResponse = <span class="keyword">new</span> <span class="type">ClientResponse</span>(clientRequest.makeHeader(),</span><br><span class="line">                    clientRequest.callback(), clientRequest.destination(), now, now,</span><br><span class="line">                    <span class="literal">false</span>, e, <span class="literal">null</span>);</span><br><span class="line">            abortedSends.add(clientResponse);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="type">RequestHeader</span> header = clientRequest.makeHeader();</span><br><span class="line">        <span class="keyword">if</span> (log.isDebugEnabled()) &#123;</span><br><span class="line">            int latestClientVersion = <span class="type">ProtoUtils</span>.latestVersion(clientRequest.apiKey().id);</span><br><span class="line">            <span class="keyword">if</span> (header.apiVersion() == latestClientVersion) &#123;</span><br><span class="line">                log.trace(<span class="string">"Sending &#123;&#125; to node &#123;&#125;."</span>, request, nodeId);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                log.debug(<span class="string">"Using older server API v&#123;&#125; to send &#123;&#125; to node &#123;&#125;."</span>,</span><br><span class="line">                    header.apiVersion(), request, nodeId);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//note: Send是一个接口，这里返回的是 NetworkSend，而 NetworkSend 继承 ByteBufferSend</span></span><br><span class="line">        <span class="type">Send</span> send = request.toSend(nodeId, header);</span><br><span class="line">        <span class="type">InFlightRequest</span> inFlightRequest = <span class="keyword">new</span> <span class="type">InFlightRequest</span>(</span><br><span class="line">                header,</span><br><span class="line">                clientRequest.createdTimeMs(),</span><br><span class="line">                clientRequest.destination(),</span><br><span class="line">                clientRequest.callback(),</span><br><span class="line">                clientRequest.expectResponse(),</span><br><span class="line">                isInternalRequest,</span><br><span class="line">                send,</span><br><span class="line">                now);</span><br><span class="line">        <span class="keyword">this</span>.inFlightRequests.add(inFlightRequest);</span><br><span class="line">        <span class="comment">//note: 将 send 和对应 kafkaChannel 绑定起来，并开启该 kafkaChannel 底层 socket 的写事件</span></span><br><span class="line">        selector.send(inFlightRequest.send);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>####Selector.send()<br>这个方法就比较容易理解了，它的作用就是获取该 Send 对应的 KafkaChannel，调用 setSend() 向 KafkaChannel 注册一个 Write 事件。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//note: 发送请求</span></span><br><span class="line">public void send(<span class="type">Send</span> send) &#123;</span><br><span class="line">    <span class="type">String</span> connectionId = send.destination();</span><br><span class="line">    <span class="keyword">if</span> (closingChannels.containsKey(connectionId))</span><br><span class="line">        <span class="keyword">this</span>.failedSends.add(connectionId);</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="type">KafkaChannel</span> channel = channelOrFail(connectionId, <span class="literal">false</span>);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            channel.setSend(send);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (<span class="type">CancelledKeyException</span> e) &#123;</span><br><span class="line">            <span class="keyword">this</span>.failedSends.add(connectionId);</span><br><span class="line">            close(channel, <span class="literal">false</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>###KafkaChannel.setSend()<br>setSend() 方法需要配合 write()（该方法是在 Selector.poll() 中调用的） 方法一起来看</p><ul><li>setSend()：将当前 KafkaChannel 的 Send 赋值为要发送的 Send，并注册一个 OP_WRITE 事件；</li><li>write()：发送当前的 Send，发送完后删除注册的 OP_WRITE 事件。</li></ul><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//note: 每次调用时都会注册一个 OP_WRITE 事件</span></span><br><span class="line">public void setSend(<span class="type">Send</span> send) &#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">this</span>.send != <span class="literal">null</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(<span class="string">"Attempt to begin a send operation with prior send operation still in progress."</span>);</span><br><span class="line">    <span class="keyword">this</span>.send = send;</span><br><span class="line">    <span class="keyword">this</span>.transportLayer.addInterestOps(<span class="type">SelectionKey</span>.<span class="type">OP_WRITE</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//note: 调用 send() 发送 Send</span></span><br><span class="line">public <span class="type">Send</span> write() <span class="keyword">throws</span> <span class="type">IOException</span> &#123;</span><br><span class="line">    <span class="type">Send</span> result = <span class="literal">null</span>;</span><br><span class="line">    <span class="keyword">if</span> (send != <span class="literal">null</span> &amp;&amp; send(send)) &#123;</span><br><span class="line">        result = send;</span><br><span class="line">        send = <span class="literal">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//note: 发送完成后,就删除这个 WRITE 事件</span></span><br><span class="line"><span class="keyword">private</span> boolean send(<span class="type">Send</span> send) <span class="keyword">throws</span> <span class="type">IOException</span> &#123;</span><br><span class="line">    send.writeTo(transportLayer);</span><br><span class="line">    <span class="keyword">if</span> (send.completed())</span><br><span class="line">        transportLayer.removeInterestOps(<span class="type">SelectionKey</span>.<span class="type">OP_WRITE</span>);</span><br><span class="line">    <span class="keyword">return</span> send.completed();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>最后，简单总结一下，可以回过头再看一下第一张图，对于 KafkaProducer 而言，其直接调用是 Sender，而 Sender 底层调用的是 NetworkClient，NetworkClient 则是通过 Selector 实现，Selector 则是对 Java NIO 原生接口的封装。</p><p>参考文献：</p><ul><li><a href="http://blog.csdn.net/chunlongyu/article/details/52636762" title="Kafka源码深度解析－序列3 －Producer －Java NIO" target="_blank" rel="noopener">Kafka源码深度解析－序列3 －Producer －Java NIO</a></li><li><a href="http://blog.csdn.net/chunlongyu/article/details/52651960" title="Kafka源码深度解析－序列4 －Producer －network层核心原理" target="_blank" rel="noopener">Kafka源码深度解析－序列4 －Producer －network层核心原理</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在写这篇文章之前，专门看了一下 Java NIO 相关的内容，只有理解了 Java NIO 模型才能更好地理解 NIO 在 Kafka 中是如何应用的以及 Producer 如何利用 Java NIO 构建其网络模型（不了解的，可以先看一下上一篇文章：&lt;a href=&quot;ht
      
    
    </summary>
    
      <category term="大数据" scheme="http://yoursite.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="kafka" scheme="http://yoursite.com/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka 源码解析之 Server 1+N+M 网络处理模型（一）</title>
    <link href="http://yoursite.com/2018/11/24/Kafka-%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E4%B9%8B-Server-1-N-M-%E7%BD%91%E7%BB%9C%E5%A4%84%E7%90%86%E6%A8%A1%E5%9E%8B%EF%BC%88%E4%B8%80%EF%BC%89/"/>
    <id>http://yoursite.com/2018/11/24/Kafka-源码解析之-Server-1-N-M-网络处理模型（一）/</id>
    <published>2018-11-24T15:46:54.000Z</published>
    <updated>2018-11-26T13:57:03.094Z</updated>
    
    <content type="html"><![CDATA[<p>开源分布式消息队列—Kafka，具备高吞吐量和高并发的特性，其网络通信层是如何做到消息的高效传输的呢？为了解开自己心中的疑虑，就查阅了Kafka的Network通信模块的源码，乘机会写本篇文章。<br> 本文主要通过对Kafka源码的分析来简述其Reactor的多线程网络通信模型和总体框架结构，同时简要介绍Kafka网络通信层的设计与具体实现。</p><h1 id="Kafka网络通信模型概述"><a href="#Kafka网络通信模型概述" class="headerlink" title="Kafka网络通信模型概述"></a>Kafka网络通信模型概述</h1><p>Kafka的网络通信模型是基于NIO的Reactor多线程模型来设计的。这里先引用Kafka源码中注释的一段话：</p><blockquote><p>An NIO socket server. The threading model is<br> <code>1 Acceptor thread</code> that handles new connections.<br> Acceptor has <code>N Processor threads</code> that each have their own selector and read requests from sockets.<br> <code>M Handler threads</code> that handle requests and produce responses back to the processor threads for writing.</p></blockquote><p>相信大家看了上面的这段引文注释后，大致可以了解到Kafka的网络通信层模型，主要采用了1（<code>1个Acceptor线程</code>）+N（<code>N个Processor线程</code>）+M（<code>M个业务处理线程</code>）。下面的表格简要的列举了下（这里先简单的看下后面还会详细说明）：</p><table><thead><tr><th style="text-align:center">线程数</th><th style="text-align:center">线程名</th><th style="text-align:center">线程具体说明</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:center">kafka-socket-acceptor_%x</td><td style="text-align:center">Acceptor线程，负责监听Client端发起的请求</td></tr><tr><td style="text-align:center">N</td><td style="text-align:center">kafka-network-thread_%d</td><td style="text-align:center">Processor线程，负责对Socket进行读写</td></tr><tr><td style="text-align:center">M</td><td style="text-align:center">kafka-request-handler-_%d</td><td style="text-align:center">Worker线程，处理具体的业务逻辑并生成Response返回</td></tr></tbody></table><p>Kafka网络通信层的完整框架图如下图所示：<br><img src="/2018/11/24/Kafka-源码解析之-Server-1-N-M-网络处理模型（一）/kafka-network.png" alt="Kafka Server 网络通信框架图"></p><p>刚开始看到上面的这个框架图可能会有一些不太理解，并不要紧，这里可以先对Kafka的网络通信层框架结构有一个大致了解。本文后面会结合Kafka的部分重要源码来详细阐述上面的过程。这里可以简单总结一下其网络通信模型中的几个重要概念：</p><ol><li><code>Acceptor</code>：1个接收线程，负责监听 Socket 新的连接请求，注册了 <code>OP_ACCEPT</code> 事件，将新的连接按照 round robin 方式交给对应的 Processor 线程处理；</li><li><code>Processor</code>：N个处理器线程，其中每个 Processor 都有自己的 selector，它会向 Acceptor 分配的 SocketChannel 注册相应的 OP_READ 事件，N 的大小由<code>num.networker.threads</code>决定；</li><li><code>KafkaRequestHandler</code>：M个请求处理线程，包含在线程池—KafkaRequestHandlerPool内部，从RequestChannel的全局请求队列—requestQueue中获取请求数据并交给KafkaApis处理，M的大小由<code>num.io.threads</code>决定；</li><li><code>RequestChannel</code>：其为Kafka服务端的请求通道，该数据结构中包含了一个全局的请求队列 requestQueue和多个与Processor处理器相对应的响应队列responseQueue，提供给Processor与请求处理线程KafkaRequestHandler和KafkaApis交换数据的地方。</li><li><code>NetworkClient</code>：其底层是对 Java NIO 进行相应的封装，位于Kafka的网络接口层。Kafka消息生产者对象—KafkaProducer的send方法主要调用NetworkClient完成消息发送；</li><li><code>SocketServer</code>：其是一个NIO的服务，它同时启动一个Acceptor接收线程和多个Processor处理器线程。提供了一种典型的Reactor多线程模式，将接收客户端请求和处理请求相分离；</li><li><code>KafkaServer</code>：代表了一个Kafka Broker的实例；其startup方法为实例启动的入口；</li><li><code>KafkaApis</code>：Kafka的业务逻辑处理Api，负责处理不同类型的请求；比如“发送消息”、“获取消息偏移量—offset”和“处理心跳请求”等；</li></ol><p> 上图展示的整体的处理流程如下所示：</p><ol><li>Acceptor 监听到来自请求者（请求者可以是来自 client，也可以来自 server）的新的连接，Acceptor 将这个请求者按照 round robin 的方式交给对对应的 Processor 进行处理；</li><li>Processor 注册这个 SocketChannel 的 OP_READ 的事件，如果有请求发送过来就可以被 Processor 的 Selector 选中；</li><li>Processor 将请求者发送的请求放入到一个 Request Queue 中，这是所有 Processor 共有的一个队列；</li><li>KafkaRequestHandler 从 Request Queue 中取出请求；</li><li>调用 KafkaApis 进行相应的处理；</li><li>处理的结果放入到该 Processor 对应的 Response Queue 中（每个 request 都标识它们来自哪个 Processor），Request Queue 的数量与 Processor 的数量保持一致；</li><li>Processor 从对应的 Response Queue 中取出 response；</li><li>Processor 将处理的结果返回给对应的请求者。</li></ol><h1 id="Kafka网络通信层的设计与具体实现"><a href="#Kafka网络通信层的设计与具体实现" class="headerlink" title="Kafka网络通信层的设计与具体实现"></a>Kafka网络通信层的设计与具体实现</h1><p> 这一节将结合Kafka网络通信层的源码来分析其设计与实现，这里主要详细介绍网络通信层的几个重要元素—SocketServer、Acceptor、Processor、RequestChannel和KafkaRequestHandler。本文分析的源码部分均基于Kafka的0.10.0.1版本。</p><h2 id="Server-网络模型整体流程"><a href="#Server-网络模型整体流程" class="headerlink" title="Server 网络模型整体流程"></a>Server 网络模型整体流程</h2><p>Kafka Server 启动后，会通过 KafkaServer 的 <code>startup()</code> 方法初始化涉及到网络模型的相关对象，如下所示：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">startup</span></span>() &#123;</span><br><span class="line">   <span class="keyword">try</span> &#123;</span><br><span class="line">     info(<span class="string">"starting"</span>)</span><br><span class="line"></span><br><span class="line">     <span class="keyword">if</span>(isShuttingDown.get)</span><br><span class="line">       <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(<span class="string">"Kafka server is still shutting down, cannot re-start!"</span>)</span><br><span class="line"></span><br><span class="line">     <span class="keyword">if</span>(startupComplete.get)</span><br><span class="line">       <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">     <span class="keyword">val</span> canStartup = isStartingUp.compareAndSet(<span class="literal">false</span>, <span class="literal">true</span>)</span><br><span class="line">     <span class="keyword">if</span> (canStartup) &#123;</span><br><span class="line">       metrics = <span class="keyword">new</span> <span class="type">Metrics</span>(metricConfig, reporters, kafkaMetricsTime, <span class="literal">true</span>)</span><br><span class="line"></span><br><span class="line">       brokerState.newState(<span class="type">Starting</span>)</span><br><span class="line"></span><br><span class="line">       <span class="comment">/* start scheduler */</span></span><br><span class="line">       kafkaScheduler.startup()</span><br><span class="line"></span><br><span class="line">       <span class="comment">/* setup zookeeper */</span></span><br><span class="line">       zkUtils = initZk()</span><br><span class="line"></span><br><span class="line">       <span class="comment">/* start log manager */</span></span><br><span class="line">       logManager = createLogManager(zkUtils.zkClient, brokerState)</span><br><span class="line">       logManager.startup()</span><br><span class="line"></span><br><span class="line">       <span class="comment">/* generate brokerId */</span></span><br><span class="line">       config.brokerId =  getBrokerId</span><br><span class="line">       <span class="keyword">this</span>.logIdent = <span class="string">"[Kafka Server "</span> + config.brokerId + <span class="string">"], "</span></span><br><span class="line"><span class="comment">//note: socketServer</span></span><br><span class="line">       socketServer = <span class="keyword">new</span> <span class="type">SocketServer</span>(config, metrics, kafkaMetricsTime)</span><br><span class="line">       socketServer.startup()</span><br><span class="line"></span><br><span class="line">       <span class="comment">/* start replica manager */</span></span><br><span class="line">       replicaManager = <span class="keyword">new</span> <span class="type">ReplicaManager</span>(config, metrics, time, kafkaMetricsTime, zkUtils, kafkaScheduler, logManager,</span><br><span class="line">         isShuttingDown)</span><br><span class="line">       replicaManager.startup()</span><br><span class="line"></span><br><span class="line">       <span class="comment">/* start kafka controller */</span></span><br><span class="line">       kafkaController = <span class="keyword">new</span> <span class="type">KafkaController</span>(config, zkUtils, brokerState, kafkaMetricsTime, metrics, threadNamePrefix)</span><br><span class="line">       kafkaController.startup()</span><br><span class="line"></span><br><span class="line">       <span class="comment">/* start group coordinator */</span></span><br><span class="line">       groupCoordinator = <span class="type">GroupCoordinator</span>(config, zkUtils, replicaManager, kafkaMetricsTime)</span><br><span class="line">       groupCoordinator.startup()</span><br><span class="line"></span><br><span class="line">       <span class="comment">/* Get the authorizer and initialize it if one is specified.*/</span></span><br><span class="line">       authorizer = <span class="type">Option</span>(config.authorizerClassName).filter(_.nonEmpty).map &#123; authorizerClassName =&gt;</span><br><span class="line">         <span class="keyword">val</span> authZ = <span class="type">CoreUtils</span>.createObject[<span class="type">Authorizer</span>](authorizerClassName)</span><br><span class="line">         authZ.configure(config.originals())</span><br><span class="line">         authZ</span><br><span class="line">       &#125;</span><br><span class="line"></span><br><span class="line">       <span class="comment">/* start processing requests //<span class="doctag">NOTE:</span> 初始化 KafkaApis 实例,每个 Server 只会启动一个线程*/</span></span><br><span class="line">       apis = <span class="keyword">new</span> <span class="type">KafkaApis</span>(socketServer.requestChannel, replicaManager, groupCoordinator,</span><br><span class="line">         kafkaController, zkUtils, config.brokerId, config, metadataCache, metrics, authorizer)</span><br><span class="line">       requestHandlerPool = <span class="keyword">new</span> <span class="type">KafkaRequestHandlerPool</span>(config.brokerId, socketServer.requestChannel, apis, config.numIoThreads)</span><br><span class="line">       brokerState.newState(<span class="type">RunningAsBroker</span>)</span><br><span class="line"></span><br><span class="line">       <span class="type">Mx4jLoader</span>.maybeLoad()</span><br><span class="line"></span><br><span class="line">       <span class="comment">/* start dynamic config manager */</span></span><br><span class="line">       dynamicConfigHandlers = <span class="type">Map</span>[<span class="type">String</span>, <span class="type">ConfigHandler</span>](<span class="type">ConfigType</span>.<span class="type">Topic</span> -&gt; <span class="keyword">new</span> <span class="type">TopicConfigHandler</span>(logManager, config),</span><br><span class="line">                                                          <span class="type">ConfigType</span>.<span class="type">Client</span> -&gt; <span class="keyword">new</span> <span class="type">ClientIdConfigHandler</span>(apis.quotaManagers))</span><br><span class="line"></span><br><span class="line">       <span class="comment">// Apply all existing client configs to the ClientIdConfigHandler to bootstrap the overrides</span></span><br><span class="line">       <span class="comment">// <span class="doctag">TODO:</span> Move this logic to DynamicConfigManager</span></span><br><span class="line">       <span class="type">AdminUtils</span>.fetchAllEntityConfigs(zkUtils, <span class="type">ConfigType</span>.<span class="type">Client</span>).foreach &#123;</span><br><span class="line">         <span class="keyword">case</span> (clientId, properties) =&gt; dynamicConfigHandlers(<span class="type">ConfigType</span>.<span class="type">Client</span>).processConfigChanges(clientId, properties)</span><br><span class="line">       &#125;</span><br><span class="line"></span><br><span class="line">       <span class="comment">// Create the config manager. start listening to notifications</span></span><br><span class="line">       dynamicConfigManager = <span class="keyword">new</span> <span class="type">DynamicConfigManager</span>(zkUtils, dynamicConfigHandlers)</span><br><span class="line">       dynamicConfigManager.startup()</span><br><span class="line"></span><br><span class="line">       <span class="comment">/* tell everyone we are alive */</span></span><br><span class="line">       <span class="keyword">val</span> listeners = config.advertisedListeners.map &#123;<span class="keyword">case</span>(protocol, endpoint) =&gt;</span><br><span class="line">         <span class="keyword">if</span> (endpoint.port == <span class="number">0</span>)</span><br><span class="line">           (protocol, <span class="type">EndPoint</span>(endpoint.host, socketServer.boundPort(protocol), endpoint.protocolType))</span><br><span class="line">         <span class="keyword">else</span></span><br><span class="line">           (protocol, endpoint)</span><br><span class="line">       &#125;</span><br><span class="line">       kafkaHealthcheck = <span class="keyword">new</span> <span class="type">KafkaHealthcheck</span>(config.brokerId, listeners, zkUtils, config.rack,</span><br><span class="line">         config.interBrokerProtocolVersion)</span><br><span class="line">       kafkaHealthcheck.startup()</span><br><span class="line"></span><br><span class="line">       <span class="comment">// Now that the broker id is successfully registered via KafkaHealthcheck, checkpoint it</span></span><br><span class="line">       checkpointBrokerId(config.brokerId)</span><br><span class="line"></span><br><span class="line">       <span class="comment">/* register broker metrics */</span></span><br><span class="line">       registerStats()</span><br><span class="line"></span><br><span class="line">       shutdownLatch = <span class="keyword">new</span> <span class="type">CountDownLatch</span>(<span class="number">1</span>)</span><br><span class="line">       startupComplete.set(<span class="literal">true</span>)</span><br><span class="line">       isStartingUp.set(<span class="literal">false</span>)</span><br><span class="line">       <span class="type">AppInfoParser</span>.registerAppInfo(jmxPrefix, config.brokerId.toString)</span><br><span class="line">       info(<span class="string">"started"</span>)</span><br><span class="line">     &#125;</span><br><span class="line">   &#125;</span><br><span class="line">...</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure></p><p>Kafka Server 在启动时会初始化 <code>SocketServer</code>、<code>KafkaApis</code> 和 <code>KafkaRequestHandlerPool</code> 对象，这也是 Server 网络处理模型的主要组成部分。Kafka Server 的网络处理模型也是基于 Java NIO 机制实现的，实现模式与 Reactor 模式类似</p><p>上面是 Server 端网络处理的整体流程，下面我们开始详细讲述上面内容在 Kafka 中实现。</p><h2 id="SocketServer"><a href="#SocketServer" class="headerlink" title="SocketServer"></a>SocketServer</h2><p>SocketServer 是接收 Socket 连接、处理请求并返回处理结果的地方，Acceptor 及 Processor 的初始化、处理逻辑都是在这里实现的。在SocketServer 内有几个比较重要的变量，这里先来看下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SocketServer</span>(<span class="params">val config: <span class="type">KafkaConfig</span>, val metrics: <span class="type">Metrics</span>, val time: <span class="type">Time</span>, val credentialProvider: <span class="type">CredentialProvider</span></span>) <span class="keyword">extends</span> <span class="title">Logging</span> <span class="keyword">with</span> <span class="title">KafkaMetricsGroup</span> </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> endpoints = config.listeners.map(l =&gt; l.listenerName -&gt; l).toMap <span class="comment">//note: broker 开放的端口数</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> numProcessorThreads = config.numNetworkThreads <span class="comment">//note: num.network.threads 默认为 3个，即 processor</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> maxQueuedRequests = config.queuedMaxRequests <span class="comment">//note:  queued.max.requests，request 队列中允许的最多请求数，默认是500</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> totalProcessorThreads = numProcessorThreads * endpoints.size <span class="comment">//note: 每个端口会对应 N 个 processor</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> maxConnectionsPerIp = config.maxConnectionsPerIp <span class="comment">//note: 默认 2147483647</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> maxConnectionsPerIpOverrides = config.maxConnectionsPerIpOverrides</span><br><span class="line">  <span class="keyword">this</span>.logIdent = <span class="string">"[Socket Server on Broker "</span> + config.brokerId + <span class="string">"], "</span></span><br><span class="line">  <span class="comment">//note: 请求队列</span></span><br><span class="line">  <span class="keyword">val</span> requestChannel = <span class="keyword">new</span> <span class="type">RequestChannel</span>(totalProcessorThreads, maxQueuedRequests)</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> processors = <span class="keyword">new</span> <span class="type">Array</span>[<span class="type">Processor</span>](totalProcessorThreads)</span><br><span class="line">  <span class="keyword">private</span>[network] <span class="keyword">val</span> acceptors = mutable.<span class="type">Map</span>[<span class="type">EndPoint</span>, <span class="type">Acceptor</span>]()</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RequestChannel</span>(<span class="params">val numProcessors: <span class="type">Int</span>, val queueSize: <span class="type">Int</span></span>) <span class="keyword">extends</span> <span class="title">KafkaMetricsGroup</span> </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> responseListeners: <span class="type">List</span>[(<span class="type">Int</span>) =&gt; <span class="type">Unit</span>] = <span class="type">Nil</span></span><br><span class="line">  <span class="comment">//note: 一个 requestQueue 队列,N 个 responseQueues 队列</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> requestQueue = <span class="keyword">new</span> <span class="type">ArrayBlockingQueue</span>[<span class="type">RequestChannel</span>.<span class="type">Request</span>](queueSize)</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> responseQueues = <span class="keyword">new</span> <span class="type">Array</span>[<span class="type">BlockingQueue</span>[<span class="type">RequestChannel</span>.<span class="type">Response</span>]](numProcessors)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>其中</p><ol><li><code>numProcessorThreads</code>：决定了 Processor 的个数，默认是3个，也就是 1+N+M 的 N 的数值；</li><li><code>maxQueuedRequests</code>：决定了 request queue 中最多允许放入多少个请求（等待处理的请求），默认是 500；</li><li>在 <code>RequestChannel</code> 中初始化了一个 requestQueue 和 N 个 responseQueue。<h3 id="SocketServer-初始化"><a href="#SocketServer-初始化" class="headerlink" title="SocketServer 初始化"></a>SocketServer 初始化</h3>Boker在启动的时候会调用SocketServer的<code>startup</code>方法，会初始化 1 个 Acceptor 和 N 个 Processor 线程，并启动，其实现如下：<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">startup</span></span>() &#123;</span><br><span class="line">  <span class="keyword">this</span>.synchronized &#123;</span><br><span class="line">    <span class="comment">//note: 一台 broker 一般只设置一个端口，当然这里也可以设置两个</span></span><br><span class="line">    config.listeners.foreach &#123; endpoint =&gt;</span><br><span class="line">      <span class="keyword">val</span> listenerName = endpoint.listenerName</span><br><span class="line">      <span class="keyword">val</span> securityProtocol = endpoint.securityProtocol</span><br><span class="line">      <span class="keyword">val</span> processorEndIndex = processorBeginIndex + numProcessorThreads</span><br><span class="line">      <span class="comment">//note: N 个 processor</span></span><br><span class="line">      <span class="keyword">for</span> (i &lt;- processorBeginIndex until processorEndIndex)</span><br><span class="line">        processors(i) = newProcessor(i, connectionQuotas, listenerName, securityProtocol)</span><br><span class="line">      <span class="comment">//note: 1个 Acceptor</span></span><br><span class="line">      <span class="keyword">val</span> acceptor = <span class="keyword">new</span> <span class="type">Acceptor</span>(endpoint, sendBufferSize, recvBufferSize, brokerId,</span><br><span class="line">        processors.slice(processorBeginIndex, processorEndIndex), connectionQuotas)</span><br><span class="line">      acceptors.put(endpoint, acceptor)</span><br><span class="line">      <span class="type">Utils</span>.newThread(<span class="string">s"kafka-socket-acceptor-<span class="subst">$listenerName</span>-<span class="subst">$securityProtocol</span>-<span class="subst">$&#123;endpoint.port&#125;</span>"</span>, acceptor, <span class="literal">false</span>).start()</span><br><span class="line">      acceptor.awaitStartup()</span><br><span class="line">      processorBeginIndex = processorEndIndex</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h2 id="Acceptor"><a href="#Acceptor" class="headerlink" title="Acceptor"></a>Acceptor</h2><p>Acceptor是一个继承自抽象类AbstractServerThread的线程类。Acceptor的主要任务是监听并且接收客户端的请求，同时建立数据传输通道—SocketChannel，然后以轮询的方式交给一个后端的Processor线程处理（具体的方式是添加socketChannel至并发队列并唤醒Processor线程处理）。</p><p> 在该线程类中主要可以关注以下两个重要的变量：</p><ol><li>nioSelector：通过NSelector.open()方法创建的变量，封装了JAVA NIO Selector的相关操作；</li><li>serverChannel：用于监听端口的服务端Socket套接字对象；</li></ol><p>实现如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run</span></span>() &#123;</span><br><span class="line">  serverChannel.register(nioSelector, <span class="type">SelectionKey</span>.<span class="type">OP_ACCEPT</span>)<span class="comment">//note: 注册 accept 事件</span></span><br><span class="line">  startupComplete()</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">var</span> currentProcessor = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> (isRunning) &#123;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">val</span> ready = nioSelector.select(<span class="number">500</span>)</span><br><span class="line">        <span class="keyword">if</span> (ready &gt; <span class="number">0</span>) &#123;</span><br><span class="line">          <span class="keyword">val</span> keys = nioSelector.selectedKeys()</span><br><span class="line">          <span class="keyword">val</span> iter = keys.iterator()</span><br><span class="line">          <span class="keyword">while</span> (iter.hasNext &amp;&amp; isRunning) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">              <span class="keyword">val</span> key = iter.next</span><br><span class="line">              iter.remove()</span><br><span class="line">              <span class="keyword">if</span> (key.isAcceptable)</span><br><span class="line">                accept(key, processors(currentProcessor))<span class="comment">//note: 拿到一个socket 连接，轮询选择一个processor进行处理</span></span><br><span class="line">              <span class="keyword">else</span></span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(<span class="string">"Unrecognized key state for acceptor thread."</span>)</span><br><span class="line">              <span class="comment">//note: 轮询算法,使用 round robin</span></span><br><span class="line">              <span class="comment">// round robin to the next processor thread</span></span><br><span class="line">              currentProcessor = (currentProcessor + <span class="number">1</span>) % processors.length</span><br><span class="line">            &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">              <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt; error(<span class="string">"Error while accepting connection"</span>, e)</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">catch</span> &#123;</span><br><span class="line">        <span class="comment">// We catch all the throwables to prevent the acceptor thread from exiting on exceptions due</span></span><br><span class="line">        <span class="comment">// to a select operation on a specific channel or a bad request. We don't want</span></span><br><span class="line">        <span class="comment">// the broker to stop responding to requests from other clients in these scenarios.</span></span><br><span class="line">        <span class="keyword">case</span> e: <span class="type">ControlThrowable</span> =&gt; <span class="keyword">throw</span> e</span><br><span class="line">        <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt; error(<span class="string">"Error occurred"</span>, e)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    debug(<span class="string">"Closing server socket and selector."</span>)</span><br><span class="line">    swallowError(serverChannel.close())</span><br><span class="line">    swallowError(nioSelector.close())</span><br><span class="line">    shutdownComplete()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>Acceptor 通过 <code>accept()</code> 将该新连接交给对应的 Processor，其实现如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//note: 处理一个新的连接</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">accept</span></span>(key: <span class="type">SelectionKey</span>, processor: <span class="type">Processor</span>) &#123;</span><br><span class="line">  <span class="comment">//note: accept 事件发生时，获取注册到 selector 上的 ServerSocketChannel</span></span><br><span class="line">  <span class="keyword">val</span> serverSocketChannel = key.channel().asInstanceOf[<span class="type">ServerSocketChannel</span>]</span><br><span class="line">  <span class="keyword">val</span> socketChannel = serverSocketChannel.accept()</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    connectionQuotas.inc(socketChannel.socket().getInetAddress)</span><br><span class="line">    socketChannel.configureBlocking(<span class="literal">false</span>)</span><br><span class="line">    socketChannel.socket().setTcpNoDelay(<span class="literal">true</span>)</span><br><span class="line">    socketChannel.socket().setKeepAlive(<span class="literal">true</span>)</span><br><span class="line">    <span class="keyword">if</span> (sendBufferSize != <span class="type">Selectable</span>.<span class="type">USE_DEFAULT_BUFFER_SIZE</span>)</span><br><span class="line">      socketChannel.socket().setSendBufferSize(sendBufferSize)</span><br><span class="line">    debug(<span class="string">"Accepted connection from %s on %s and assigned it to processor %d, sendBufferSize [actual|requested]: [%d|%d] recvBufferSize [actual|requested]: [%d|%d]"</span></span><br><span class="line">          .format(socketChannel.socket.getRemoteSocketAddress, socketChannel.socket.getLocalSocketAddress, processor.id,</span><br><span class="line">                socketChannel.socket.getSendBufferSize, sendBufferSize,</span><br><span class="line">                socketChannel.socket.getReceiveBufferSize, recvBufferSize))</span><br><span class="line">    <span class="comment">//note: 轮询选择不同的 processor 进行处理</span></span><br><span class="line">    processor.accept(socketChannel)</span><br><span class="line">  &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> e: <span class="type">TooManyConnectionsException</span> =&gt;</span><br><span class="line">      info(<span class="string">"Rejected connection from %s, address already has the configured maximum of %d connections."</span>.format(e.ip, e.count))</span><br><span class="line">      close(socketChannel)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>在上面源码中可以看到，Acceptor线程启动后，首先会向用于监听端口的服务端套接字对象—ServerSocketChannel上注册OP_ACCEPT 事件。然后以轮询的方式等待所关注的事件发生。如果该事件发生，则调用accept()方法对OP_ACCEPT事件进行处理。这里，Processor是通过round robin方法选择的，这样可以保证后面多个Processor线程的负载基本均匀。<br> Acceptor的accept()方法的作用主要如下：</p><ol><li>通过SelectionKey取得与之对应的serverSocketChannel实例，并调用它的accept()方法与客户端建立连接；</li><li>调用connectionQuotas.inc()方法增加连接统计计数；并同时设置第（1）步中创建返回的socketChannel属性（如sendBufferSize、KeepAlive、TcpNoDelay、configureBlocking等）</li><li>将socketChannel交给processor.accept()方法进行处理。这里主要是将socketChannel加入Processor处理器的并发队列newConnections队列中，然后唤醒Processor线程从队列中获取socketChannel并处理。其中，newConnections会被Acceptor线程和Processor线程并发访问操作，所以newConnections是ConcurrentLinkedQueue队列（一个基于链接节点的无界线程安全队列）</li></ol><h2 id="Processor"><a href="#Processor" class="headerlink" title="Processor"></a>Processor</h2><p>Processor同Acceptor一样，也是一个线程类，继承了抽象类AbstractServerThread。其主要是从客户端的请求中读取数据和将KafkaRequestHandler处理完响应结果返回给客户端。在该线程类中主要关注以下几个重要的变量：</p><ol><li><code>newConnections</code>：在上面的Acceptor一节中已经提到过，它是一种ConcurrentLinkedQueue[SocketChannel]类型的队列，用于保存新连接交由Processor处理的socketChannel；</li><li><code>inflightResponses</code>：是一个Map[String, RequestChannel.Response]类型的集合，用于记录尚未发送的响应；</li><li><code>selector</code>：是一个类型为KSelector变量，用于管理网络连接；<br>下面先给出Processor处理器线程run方法执行的流程图：<br><img src="/2018/11/24/Kafka-源码解析之-Server-1-N-M-网络处理模型（一）/kafka-processor.png" alt="Kafk_Processor线程的处理流程图"></li></ol><p>在前面，Acceptor 通过 <code>accept()</code> 将新的连接交给 Processor，Processor 实际上是将该 SocketChannel 添加到该 Processor 的 <code>newConnections</code> 队列中，实现如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">accept</span></span>(socketChannel: <span class="type">SocketChannel</span>) &#123;</span><br><span class="line">  newConnections.add(socketChannel)<span class="comment">//note: 添加到队列中</span></span><br><span class="line">  wakeup()<span class="comment">//note: 唤醒 Processor 的 selector（如果此时在阻塞的话）</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>这里详细看下 Processor 线程做了什么事情，其 <code>run()</code> 方法的实现如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>() &#123;</span><br><span class="line">  startupComplete()</span><br><span class="line">  <span class="keyword">while</span> (isRunning) &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// setup any new connections that have been queued up</span></span><br><span class="line">      configureNewConnections()<span class="comment">//note: 对新的 socket 连接,并注册 READ 事件</span></span><br><span class="line">      <span class="comment">// register any new responses for writing</span></span><br><span class="line">      processNewResponses()<span class="comment">//note: 处理 response 队列中 response</span></span><br><span class="line">      poll() <span class="comment">//note: 监听所有的 socket channel，是否有新的请求发送过来</span></span><br><span class="line">      processCompletedReceives() <span class="comment">//note: 处理接收到请求，将其放入到 request queue 中</span></span><br><span class="line">      processCompletedSends() <span class="comment">//note: 处理已经完成的发送</span></span><br><span class="line">      processDisconnected() <span class="comment">//note: 处理断开的连接</span></span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="comment">// We catch all the throwables here to prevent the processor thread from exiting. We do this because</span></span><br><span class="line">      <span class="comment">// letting a processor exit might cause a bigger impact on the broker. Usually the exceptions thrown would</span></span><br><span class="line">      <span class="comment">// be either associated with a specific socket channel or a bad request. We just ignore the bad socket channel</span></span><br><span class="line">      <span class="comment">// or request. This behavior might need to be reviewed if we see an exception that need the entire broker to stop.</span></span><br><span class="line">      <span class="keyword">case</span> e: <span class="type">ControlThrowable</span> =&gt; <span class="keyword">throw</span> e</span><br><span class="line">      <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt;</span><br><span class="line">        error(<span class="string">"Processor got uncaught exception."</span>, e)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  debug(<span class="string">"Closing selector - processor "</span> + id)</span><br><span class="line">  swallowError(closeAll())</span><br><span class="line">  shutdownComplete()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>Processor 在一次循环中，主要做的事情如下：</p><ol><li><code>configureNewConnections()</code>：对新添加到 newConnections 队列中的 SocketChannel 进行处理，这里主要是遍历取出队列中的每个socketChannel并将其在selector上注册<code>OP_READ</code>事件；</li><li><code>processNewResponses()</code>：从该 Processor 对应的 response queue 中取出一个 response，进行发送,在这一步中会根据responseAction的类型（NoOpAction/SendAction/CloseConnectionAction）进行判断，若为“NoOpAction”，表示该连接对应的请求无需响应；若为“SendAction”，表示该Response需要发送给客户端，则会通过“selector.send”注册OP_WRITE事件，并且将该Response从responseQueue响应队列中移至inflightResponses集合中；“CloseConnectionAction”，表示该连接是要关闭的；；</li><li><code>poll()</code>：调用 selector 的 poll() 方法，遍历注册的 SocketChannel，查看是否有事件准备就绪；</li><li><code>processCompletedReceives()</code>：将接收到请求添加到的 request queue 中,在processCompletedReceives方法中调用“requestChannel.sendRequest”方法将请求Request添加至requestChannel的全局请求队列—requestQueue中，等待KafkaRequestHandler来处理。同时，调用“selector.mute”方法取消与该请求对应的连接通道上的OP_READ事件；</li><li><code>processCompletedSends()</code>：处理已经完成的响应发送,当已经完成将response发送给客户端，则将其从inflightResponses移除，同时通过调用“selector.unmute”方法为对应的连接通道重新注册OP_READ事件；</li><li><code>processDisconnected()</code>：处理断开的 SocketChannel, 将该response从inflightResponses集合中移除，同时将connectionQuotas统计计数减1。</li></ol><p>上面就是 Processor 线程处理的主要逻辑，先是向新的 SocketChannel 注册相应的事件，监控是否有请求发送过来，接着从 response queue 中取出处理完成的请求发送给对应的请求者，然后调用一下 selector 的 <code>poll()</code>，遍历一下注册的所有 SocketChannel，判断是否有事件就绪，然后做相应的处理。这里需要注意的是，request queue 是所有 Processor 公用的一个队列，而 response queue 则是与 Processor 一一对应的，因为每个 Processor 监听的 SocketChannel 并不是同一批的，如果公有一个 response queue，那么这个 N 个 Processor 的 selector 要去监听所有的 SocketChannel，而不是现在这种，只需要去关注分配给自己的 SocketChannel。</p><p>下面分别看下上面的这些方法的具体实现。</p><h3 id="configureNewConnections"><a href="#configureNewConnections" class="headerlink" title="configureNewConnections"></a>configureNewConnections</h3><p>configureNewConnections() 对新添加到 <code>newConnections</code> 队列中的 SocketChannel 进行处理，主要是 selector 注册相应的 <code>OP_READ</code> 事件，其实现如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//note: 如果有新的连接过来，将该 Channel 的 OP_READ 事件注册到 selector 上</span></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">configureNewConnections</span></span>() &#123;</span><br><span class="line">  <span class="keyword">while</span> (!newConnections.isEmpty) &#123;</span><br><span class="line">    <span class="keyword">val</span> channel = newConnections.poll()</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      debug(<span class="string">s"Processor <span class="subst">$id</span> listening to new connection from <span class="subst">$&#123;channel.socket.getRemoteSocketAddress&#125;</span>"</span>)</span><br><span class="line">      <span class="keyword">val</span> localHost = channel.socket().getLocalAddress.getHostAddress</span><br><span class="line">      <span class="keyword">val</span> localPort = channel.socket().getLocalPort</span><br><span class="line">      <span class="keyword">val</span> remoteHost = channel.socket().getInetAddress.getHostAddress</span><br><span class="line">      <span class="keyword">val</span> remotePort = channel.socket().getPort</span><br><span class="line">      <span class="keyword">val</span> connectionId = <span class="type">ConnectionId</span>(localHost, localPort, remoteHost, remotePort).toString</span><br><span class="line">      selector.register(connectionId, channel)</span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="comment">// We explicitly catch all non fatal exceptions and close the socket to avoid a socket leak. The other</span></span><br><span class="line">      <span class="comment">// throwables will be caught in processor and logged as uncaught exceptions.</span></span><br><span class="line">      <span class="keyword">case</span> <span class="type">NonFatal</span>(e) =&gt;</span><br><span class="line">        <span class="keyword">val</span> remoteAddress = channel.getRemoteAddress</span><br><span class="line">        <span class="comment">// need to close the channel here to avoid a socket leak.</span></span><br><span class="line">        close(channel)</span><br><span class="line">        error(<span class="string">s"Processor <span class="subst">$id</span> closed connection from <span class="subst">$remoteAddress</span>"</span>, e)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="processNewResponses"><a href="#processNewResponses" class="headerlink" title="processNewResponses"></a>processNewResponses</h3><p><code>processNewResponses()</code> 方法是从该 Processor 对应的 response queue 中取出一个 response，Processor 是通过 RequestChannel 的 <code>receiveResponse()</code> 从该 Processor 对应的 response queue 中取出 response，如下所示：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//note: 获取 response</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">receiveResponse</span></span>(processor: <span class="type">Int</span>): <span class="type">RequestChannel</span>.<span class="type">Response</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> response = responseQueues(processor).poll()</span><br><span class="line">  <span class="keyword">if</span> (response != <span class="literal">null</span>)</span><br><span class="line">    response.request.responseDequeueTimeMs = <span class="type">Time</span>.<span class="type">SYSTEM</span>.milliseconds</span><br><span class="line">  response</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>取到相应的 response 之后，会判断该 response 的类型，进行相应的操作，如果需要返回，那么会调用 <code>sendResponse()</code> 发送该 response，如下所示：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//note: 处理一个新的 response 响应</span></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">processNewResponses</span></span>() &#123;</span><br><span class="line">  <span class="keyword">var</span> curr = requestChannel.receiveResponse(id)</span><br><span class="line">  <span class="keyword">while</span> (curr != <span class="literal">null</span>) &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      curr.responseAction <span class="keyword">match</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> <span class="type">RequestChannel</span>.<span class="type">NoOpAction</span> =&gt; <span class="comment">//note: 如果这个请求不需要返回 response，再次注册该监听事件</span></span><br><span class="line">          <span class="comment">// There is no response to send to the client, we need to read more pipelined requests</span></span><br><span class="line">          <span class="comment">// that are sitting in the server's socket buffer</span></span><br><span class="line">          curr.request.updateRequestMetrics</span><br><span class="line">          trace(<span class="string">"Socket server received empty response to send, registering for read: "</span> + curr)</span><br><span class="line">          <span class="keyword">val</span> channelId = curr.request.connectionId</span><br><span class="line">          <span class="keyword">if</span> (selector.channel(channelId) != <span class="literal">null</span> || selector.closingChannel(channelId) != <span class="literal">null</span>)</span><br><span class="line">              selector.unmute(channelId)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">RequestChannel</span>.<span class="type">SendAction</span> =&gt; <span class="comment">//note: 需要发送的 response，那么进行发送</span></span><br><span class="line">          sendResponse(curr)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">RequestChannel</span>.<span class="type">CloseConnectionAction</span> =&gt; <span class="comment">//note: 要关闭的 response</span></span><br><span class="line">          curr.request.updateRequestMetrics</span><br><span class="line">          trace(<span class="string">"Closing socket connection actively according to the response code."</span>)</span><br><span class="line">          close(selector, curr.request.connectionId)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      curr = requestChannel.receiveResponse(id)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/* `protected` for test usage */</span></span><br><span class="line"><span class="comment">//note: 发送的对应的 response</span></span><br><span class="line"><span class="keyword">protected</span>[network] <span class="function"><span class="keyword">def</span> <span class="title">sendResponse</span></span>(response: <span class="type">RequestChannel</span>.<span class="type">Response</span>) &#123;</span><br><span class="line">  trace(<span class="string">s"Socket server received response to send, registering for write and sending data: <span class="subst">$response</span>"</span>)</span><br><span class="line">  <span class="keyword">val</span> channel = selector.channel(response.responseSend.destination)</span><br><span class="line">  <span class="comment">// `channel` can be null if the selector closed the connection because it was idle for too long</span></span><br><span class="line">  <span class="keyword">if</span> (channel == <span class="literal">null</span>) &#123;</span><br><span class="line">    warn(<span class="string">s"Attempting to send response via channel for which there is no open connection, connection id <span class="subst">$id</span>"</span>)</span><br><span class="line">    response.request.updateRequestMetrics()</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">else</span> &#123;</span><br><span class="line">    selector.send(response.responseSend) <span class="comment">//note: 发送该 response</span></span><br><span class="line">    inflightResponses += (response.request.connectionId -&gt; response) <span class="comment">//note: 添加到 inflinght 中</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="processCompletedReceives"><a href="#processCompletedReceives" class="headerlink" title="processCompletedReceives"></a>processCompletedReceives</h3><p><code>processCompletedReceives()</code>方法的主要作用是处理接收到请求，并将其放入到 request queue 中，其实现如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//note: 处理接收到的所有请求</span></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">processCompletedReceives</span></span>() &#123;</span><br><span class="line">  selector.completedReceives.asScala.foreach &#123; receive =&gt;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">val</span> openChannel = selector.channel(receive.source)</span><br><span class="line">      <span class="keyword">val</span> session = &#123;</span><br><span class="line">        <span class="comment">// Only methods that are safe to call on a disconnected channel should be invoked on 'channel'.</span></span><br><span class="line">        <span class="keyword">val</span> channel = <span class="keyword">if</span> (openChannel != <span class="literal">null</span>) openChannel <span class="keyword">else</span> selector.closingChannel(receive.source)</span><br><span class="line">        <span class="type">RequestChannel</span>.<span class="type">Session</span>(<span class="keyword">new</span> <span class="type">KafkaPrincipal</span>(<span class="type">KafkaPrincipal</span>.<span class="type">USER_TYPE</span>, channel.principal.getName), channel.socketAddress)</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">val</span> req = <span class="type">RequestChannel</span>.<span class="type">Request</span>(processor = id, connectionId = receive.source, session = session,</span><br><span class="line">        buffer = receive.payload, startTimeMs = time.milliseconds, listenerName = listenerName,</span><br><span class="line">        securityProtocol = securityProtocol)</span><br><span class="line">      requestChannel.sendRequest(req) <span class="comment">//note: 添加到请求队列，如果队列满了，将会阻塞</span></span><br><span class="line">      selector.mute(receive.source) <span class="comment">//note: 移除该连接的 OP_READ 监听</span></span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> e @ (_: <span class="type">InvalidRequestException</span> | _: <span class="type">SchemaException</span>) =&gt;</span><br><span class="line">        <span class="comment">// note that even though we got an exception, we can assume that receive.source is valid. Issues with constructing a valid receive object were handled earlier</span></span><br><span class="line">        error(<span class="string">s"Closing socket for <span class="subst">$&#123;receive.source&#125;</span> because of error"</span>, e)</span><br><span class="line">        close(selector, receive.source)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="processCompletedSends"><a href="#processCompletedSends" class="headerlink" title="processCompletedSends"></a>processCompletedSends</h3><p><code>processCompletedSends()</code> 方法是处理已经完成的发送，其实现如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">processCompletedSends</span></span>() &#123;</span><br><span class="line">  selector.completedSends.asScala.foreach &#123; send =&gt;</span><br><span class="line">    <span class="comment">//note: response 发送完成，从正在发送的集合中移除</span></span><br><span class="line">    <span class="keyword">val</span> resp = inflightResponses.remove(send.destination).getOrElse &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(<span class="string">s"Send for <span class="subst">$&#123;send.destination&#125;</span> completed, but not in `inflightResponses`"</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    resp.request.updateRequestMetrics()</span><br><span class="line">    selector.unmute(send.destination) <span class="comment">//note: 完成这个请求之后再次监听 OP_READ 事件</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="KafkaRequestHandlerPool"><a href="#KafkaRequestHandlerPool" class="headerlink" title="KafkaRequestHandlerPool"></a>KafkaRequestHandlerPool</h2><p>上面主要是讲述 SocketServer 中 Acceptor 与 Processor 的处理内容，也就是 1+N+M 模型中 1+N 部分，下面开始讲述 M 部分，也就是 KafkaRequestHandler 的内容，其初始化实现如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">KafkaRequestHandlerPool</span>(<span class="params">val brokerId: <span class="type">Int</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                              val requestChannel: <span class="type">RequestChannel</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                              val apis: <span class="type">KafkaApis</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                              time: <span class="type">Time</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                              numThreads: <span class="type">Int</span></span>) <span class="keyword">extends</span> <span class="title">Logging</span> <span class="keyword">with</span> <span class="title">KafkaMetricsGroup</span> </span>&#123;</span><br><span class="line">  <span class="comment">/* a meter to track the average free capacity of the request handlers */</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> aggregateIdleMeter = newMeter(<span class="string">"RequestHandlerAvgIdlePercent"</span>, <span class="string">"percent"</span>, <span class="type">TimeUnit</span>.<span class="type">NANOSECONDS</span>)</span><br><span class="line">  <span class="keyword">this</span>.logIdent = <span class="string">"[Kafka Request Handler on Broker "</span> + brokerId + <span class="string">"], "</span></span><br><span class="line">  <span class="keyword">val</span> threads = <span class="keyword">new</span> <span class="type">Array</span>[<span class="type">Thread</span>](numThreads)</span><br><span class="line">  <span class="keyword">val</span> runnables = <span class="keyword">new</span> <span class="type">Array</span>[<span class="type">KafkaRequestHandler</span>](numThreads)</span><br><span class="line">  <span class="comment">//note: 建立 M 个（numThreads）KafkaRequestHandler</span></span><br><span class="line">  <span class="keyword">for</span>(i &lt;- <span class="number">0</span> until numThreads) &#123;</span><br><span class="line">    <span class="comment">//note: requestChannel 是 Processor 存放 request 请求的地方,也是 Handler 处理完请求存放 response 的地方</span></span><br><span class="line">    runnables(i) = <span class="keyword">new</span> <span class="type">KafkaRequestHandler</span>(i, brokerId, aggregateIdleMeter, numThreads, requestChannel, apis, time)</span><br><span class="line">    threads(i) = <span class="type">Utils</span>.daemonThread(<span class="string">"kafka-request-handler-"</span> + i, runnables(i))</span><br><span class="line">    threads(i).start()</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">shutdown</span></span>() &#123;</span><br><span class="line">    info(<span class="string">"shutting down"</span>)</span><br><span class="line">    <span class="keyword">for</span>(handler &lt;- runnables)</span><br><span class="line">      handler.shutdown</span><br><span class="line">    <span class="keyword">for</span>(thread &lt;- threads)</span><br><span class="line">      thread.join</span><br><span class="line">    info(<span class="string">"shut down completely"</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>如上面实现所示：</p><ol><li>KafkaRequestHandlerPool 会初始化 M 个 KafkaRequestHandler 线程，并启动该线程；</li><li>在初始化 KafkaRequestHandler 时，传入一个 requestChannel 变量，这个是 Processor 存放 request 的地方，KafkaRequestHandler 在处理请求时，会从这个 queue 中取出相应的 request。<h3 id="KafkaRequestHandler"><a href="#KafkaRequestHandler" class="headerlink" title="KafkaRequestHandler"></a>KafkaRequestHandler</h3>KafkaRequestHandler 线程的处理实现如下：<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run</span></span>() &#123;</span><br><span class="line">  <span class="keyword">while</span>(<span class="literal">true</span>) &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">var</span> req : <span class="type">RequestChannel</span>.<span class="type">Request</span> = <span class="literal">null</span></span><br><span class="line">      <span class="keyword">while</span> (req == <span class="literal">null</span>) &#123;</span><br><span class="line">        <span class="comment">// We use a single meter for aggregate idle percentage for the thread pool.</span></span><br><span class="line">        <span class="comment">// Since meter is calculated as total_recorded_value / time_window and</span></span><br><span class="line">        <span class="comment">// time_window is independent of the number of threads, each recorded idle</span></span><br><span class="line">        <span class="comment">// time should be discounted by # threads.</span></span><br><span class="line">        <span class="keyword">val</span> startSelectTime = time.nanoseconds</span><br><span class="line">        req = requestChannel.receiveRequest(<span class="number">300</span>) <span class="comment">//note: 从 request queue 中拿去 request</span></span><br><span class="line">        <span class="keyword">val</span> idleTime = time.nanoseconds - startSelectTime</span><br><span class="line">        aggregateIdleMeter.mark(idleTime / totalHandlerThreads)</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span>(req eq <span class="type">RequestChannel</span>.<span class="type">AllDone</span>) &#123;</span><br><span class="line">        debug(<span class="string">"Kafka request handler %d on broker %d received shut down command"</span>.format(</span><br><span class="line">          id, brokerId))</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">      &#125;</span><br><span class="line">      req.requestDequeueTimeMs = time.milliseconds</span><br><span class="line">      trace(<span class="string">"Kafka request handler %d on broker %d handling request %s"</span>.format(id, brokerId, req))</span><br><span class="line">      apis.handle(req) <span class="comment">//note: 处理请求,并将处理的结果通过 sendResponse 放入 response queue 中</span></span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt; error(<span class="string">"Exception when handling request"</span>, e)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><p>上述方法的实现逻辑：</p><ol><li>KafkaRequestHandler不断的从requestChannel队列里面取出request交给apis处理；</li><li>KafkaApis 处理这个 request，并通过 <code>requestChannel.sendResponse()</code> 将处理的结果放入 requestChannel 的 response queue 中，如下所示：<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//note: 将 response 添加到对应的队列中</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sendResponse</span></span>(response: <span class="type">RequestChannel</span>.<span class="type">Response</span>) &#123;</span><br><span class="line">  responseQueues(response.processor).put(response)</span><br><span class="line">  <span class="keyword">for</span>(onResponse &lt;- responseListeners)</span><br><span class="line">    onResponse(response.processor) <span class="comment">//note: 调用对应 processor 的 wakeup 方法</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><p>KafkaRequestHandler也是一种线程类，在KafkaServer实例启动时候会实例化一个线程池—KafkaRequestHandlerPool对象（包含了若干个KafkaRequestHandler线程），这些线程以守护线程的方式在后台运行。在KafkaRequestHandler的run方法中会循环地从RequestChannel中阻塞式读取request，读取后再交由KafkaApis来具体处理。</p><h2 id="KafkaApis"><a href="#KafkaApis" class="headerlink" title="KafkaApis"></a>KafkaApis</h2><p>KafkaApis是用于处理对通信网络传输过来的业务消息请求的中心转发组件。该组件反映出Kafka Broker Server可以提供哪些服务。<br>apis根据不同的请求类型调用不同的方法进行处理， 代码如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Top-level method that handles all requests and multiplexes to the right api</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">handle</span></span>(request: <span class="type">RequestChannel</span>.<span class="type">Request</span>) &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="type">ApiKeys</span>.forId(request.requestId) <span class="keyword">match</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">PRODUCE</span> =&gt; handleProducerRequest(request)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">FETCH</span> =&gt; handleFetchRequest(request)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">LIST_OFFSETS</span> =&gt; handleOffsetRequest(request)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">METADATA</span> =&gt; handleTopicMetadataRequest(request)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">LEADER_AND_ISR</span> =&gt; handleLeaderAndIsrRequest(request)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">STOP_REPLICA</span> =&gt; handleStopReplicaRequest(request)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">UPDATE_METADATA_KEY</span> =&gt; handleUpdateMetadataRequest(request)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">CONTROLLED_SHUTDOWN_KEY</span> =&gt; handleControlledShutdownRequest(request)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">OFFSET_COMMIT</span> =&gt; handleOffsetCommitRequest(request)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">OFFSET_FETCH</span> =&gt; handleOffsetFetchRequest(request)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">GROUP_COORDINATOR</span> =&gt; handleGroupCoordinatorRequest(request)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">JOIN_GROUP</span> =&gt; handleJoinGroupRequest(request)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">HEARTBEAT</span> =&gt; handleHeartbeatRequest(request)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">LEAVE_GROUP</span> =&gt; handleLeaveGroupRequest(request)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">SYNC_GROUP</span> =&gt; handleSyncGroupRequest(request)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">DESCRIBE_GROUPS</span> =&gt; handleDescribeGroupRequest(request)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">LIST_GROUPS</span> =&gt; handleListGroupsRequest(request)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">SASL_HANDSHAKE</span> =&gt; handleSaslHandshakeRequest(request)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">API_VERSIONS</span> =&gt; handleApiVersionsRequest(request)</span><br><span class="line">        <span class="keyword">case</span> requestId =&gt; <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">KafkaException</span>(<span class="string">"Unknown api code "</span> + requestId)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;<span class="keyword">catch</span> &#123;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">finally</span></span><br><span class="line">      request.apiLocalCompleteTimeMs = <span class="type">SystemTime</span>.milliseconds</span><br></pre></td></tr></table></figure></p><p>显然，此处处理的速度影响Kafka整体的消息处理的速度。<br>这里我们分析一个处理方法handleProducerRequest。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Handle a produce request</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">handleProducerRequest</span></span>(request: <span class="type">RequestChannel</span>.<span class="type">Request</span>) &#123;</span><br><span class="line">    <span class="keyword">val</span> produceRequest = request.body.asInstanceOf[<span class="type">ProduceRequest</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment">// the callback for sending a produce response</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sendResponseCallback</span></span>(responseStatus: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">PartitionResponse</span>]) &#123;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">var</span> errorInResponse = <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">      mergedResponseStatus.foreach &#123; <span class="keyword">case</span> (topicPartition, status) =&gt;</span><br><span class="line">        <span class="keyword">if</span> (status.errorCode != <span class="type">Errors</span>.<span class="type">NONE</span>.code) &#123;</span><br><span class="line">          errorInResponse = <span class="literal">true</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="function"><span class="keyword">def</span> <span class="title">produceResponseCallback</span></span>(delayTimeMs: <span class="type">Int</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (produceRequest.acks == <span class="number">0</span>) &#123;</span><br><span class="line">          <span class="comment">// no operation needed if producer request.required.acks = 0; however, if there is any error in handling</span></span><br><span class="line">          <span class="comment">// the request, since no response is expected by the producer, the server will close socket server so that</span></span><br><span class="line">          <span class="comment">// the producer client will know that some error has happened and will refresh its metadata</span></span><br><span class="line">          <span class="keyword">if</span> (errorInResponse) &#123;</span><br><span class="line">            <span class="keyword">val</span> exceptionsSummary = mergedResponseStatus.map &#123; <span class="keyword">case</span> (topicPartition, status) =&gt;</span><br><span class="line">              topicPartition -&gt; <span class="type">Errors</span>.forCode(status.errorCode).exceptionName</span><br><span class="line">            &#125;.mkString(<span class="string">", "</span>)</span><br><span class="line">            requestChannel.closeConnection(request.processor, request)</span><br><span class="line">          &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            requestChannel.noOperation(request.processor, request)</span><br><span class="line">          &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="keyword">val</span> respHeader = <span class="keyword">new</span> <span class="type">ResponseHeader</span>(request.header.correlationId)</span><br><span class="line">          <span class="keyword">val</span> respBody = request.header.apiVersion <span class="keyword">match</span> &#123;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">0</span> =&gt; <span class="keyword">new</span> <span class="type">ProduceResponse</span>(mergedResponseStatus.asJava)</span><br><span class="line">            <span class="keyword">case</span> version@(<span class="number">1</span> | <span class="number">2</span>) =&gt; <span class="keyword">new</span> <span class="type">ProduceResponse</span>(mergedResponseStatus.asJava, delayTimeMs, version)</span><br><span class="line">            <span class="comment">// This case shouldn't happen unless a new version of ProducerRequest is added without</span></span><br><span class="line">            <span class="comment">// updating this part of the code to handle it properly.</span></span><br><span class="line">            <span class="keyword">case</span> version =&gt; <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalArgumentException</span>(<span class="string">s"Version `<span class="subst">$version</span>` of ProduceRequest is not handled. Code must be updated."</span>)</span><br><span class="line">          &#125;</span><br><span class="line"></span><br><span class="line">          requestChannel.sendResponse(<span class="keyword">new</span> <span class="type">RequestChannel</span>.<span class="type">Response</span>(request, <span class="keyword">new</span> <span class="type">ResponseSend</span>(request.connectionId, respHeader, respBody)))</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// When this callback is triggered, the remote API call has completed</span></span><br><span class="line">      request.apiRemoteCompleteTimeMs = <span class="type">SystemTime</span>.milliseconds</span><br><span class="line"></span><br><span class="line">      quotaManagers(<span class="type">ApiKeys</span>.<span class="type">PRODUCE</span>.id).recordAndMaybeThrottle(</span><br><span class="line">        request.header.clientId,</span><br><span class="line">        numBytesAppended,</span><br><span class="line">        produceResponseCallback)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (authorizedRequestInfo.isEmpty)</span><br><span class="line">      sendResponseCallback(<span class="type">Map</span>.empty)</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">val</span> internalTopicsAllowed = request.header.clientId == <span class="type">AdminUtils</span>.<span class="type">AdminClientId</span></span><br><span class="line"></span><br><span class="line">      <span class="comment">// Convert ByteBuffer to ByteBufferMessageSet</span></span><br><span class="line">      <span class="keyword">val</span> authorizedMessagesPerPartition = authorizedRequestInfo.map &#123;</span><br><span class="line">        <span class="keyword">case</span> (topicPartition, buffer) =&gt; (topicPartition, <span class="keyword">new</span> <span class="type">ByteBufferMessageSet</span>(buffer))</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// call the replica manager to append messages to the replicas</span></span><br><span class="line">      replicaManager.appendMessages(</span><br><span class="line">        produceRequest.timeout.toLong,</span><br><span class="line">        produceRequest.acks,</span><br><span class="line">        internalTopicsAllowed,</span><br><span class="line">        authorizedMessagesPerPartition,</span><br><span class="line">        sendResponseCallback)</span><br><span class="line"></span><br><span class="line">      <span class="comment">// if the request is put into the purgatory, it will have a held reference</span></span><br><span class="line">      <span class="comment">// and hence cannot be garbage collected; hence we clear its data here in</span></span><br><span class="line">      <span class="comment">// order to let GC re-claim its memory since it is already appended to log</span></span><br><span class="line">      produceRequest.clearPartitionRecords()</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></p><p>这里会调用replicaManager.appendMessages处理Kafka message的保存和备份,也就是leader和备份节点上。</p><h3 id="Replication-Subsystem"><a href="#Replication-Subsystem" class="headerlink" title="Replication Subsystem"></a>Replication Subsystem</h3><p>顺藤摸瓜，我们进入replicaManager.appendMessages的代码。<br>这个方法会将消息放到leader分区上，并复制到备份分区上。在超时或者根据required acks的值及时返回response。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Append messages to leader replicas of the partition, and wait for them to be replicated to other replicas;</span></span><br><span class="line"><span class="comment">   * the callback function will be triggered either when timeout or the required acks are satisfied</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">appendMessages</span></span>(timeout: <span class="type">Long</span>,</span><br><span class="line">                     requiredAcks: <span class="type">Short</span>,</span><br><span class="line">                     internalTopicsAllowed: <span class="type">Boolean</span>,</span><br><span class="line">                     messagesPerPartition: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">MessageSet</span>],</span><br><span class="line">                     responseCallback: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">PartitionResponse</span>] =&gt; <span class="type">Unit</span>) &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (isValidRequiredAcks(requiredAcks)) &#123;</span><br><span class="line">      <span class="keyword">val</span> sTime = <span class="type">SystemTime</span>.milliseconds</span><br><span class="line">      <span class="keyword">val</span> localProduceResults = appendToLocalLog(internalTopicsAllowed, messagesPerPartition, requiredAcks)</span><br><span class="line">      debug(<span class="string">"Produce to local log in %d ms"</span>.format(<span class="type">SystemTime</span>.milliseconds - sTime))</span><br><span class="line"></span><br><span class="line">      <span class="keyword">val</span> produceStatus = localProduceResults.map &#123; <span class="keyword">case</span> (topicPartition, result) =&gt;</span><br><span class="line">        topicPartition -&gt;</span><br><span class="line">                <span class="type">ProducePartitionStatus</span>(</span><br><span class="line">                  result.info.lastOffset + <span class="number">1</span>, <span class="comment">// required offset</span></span><br><span class="line">                  <span class="keyword">new</span> <span class="type">PartitionResponse</span>(result.errorCode, result.info.firstOffset, result.info.timestamp)) <span class="comment">// response status</span></span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (delayedRequestRequired(requiredAcks, messagesPerPartition, localProduceResults)) &#123;</span><br><span class="line">        <span class="comment">// create delayed produce operation</span></span><br><span class="line">        <span class="keyword">val</span> produceMetadata = <span class="type">ProduceMetadata</span>(requiredAcks, produceStatus)</span><br><span class="line">        <span class="keyword">val</span> delayedProduce = <span class="keyword">new</span> <span class="type">DelayedProduce</span>(timeout, produceMetadata, <span class="keyword">this</span>, responseCallback)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// create a list of (topic, partition) pairs to use as keys for this delayed produce operation</span></span><br><span class="line">        <span class="keyword">val</span> producerRequestKeys = messagesPerPartition.keys.map(<span class="keyword">new</span> <span class="type">TopicPartitionOperationKey</span>(_)).toSeq</span><br><span class="line"></span><br><span class="line">        <span class="comment">// try to complete the request immediately, otherwise put it into the purgatory</span></span><br><span class="line">        <span class="comment">// this is because while the delayed produce operation is being created, new</span></span><br><span class="line">        <span class="comment">// requests may arrive and hence make this operation completable.</span></span><br><span class="line">        delayedProducePurgatory.tryCompleteElseWatch(delayedProduce, producerRequestKeys)</span><br><span class="line"></span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// we can respond immediately</span></span><br><span class="line">        <span class="keyword">val</span> produceResponseStatus = produceStatus.mapValues(status =&gt; status.responseStatus)</span><br><span class="line">        responseCallback(produceResponseStatus)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// If required.acks is outside accepted range, something is wrong with the client</span></span><br><span class="line">      <span class="comment">// Just return an error and don't handle the request at all</span></span><br><span class="line">      <span class="keyword">val</span> responseStatus = messagesPerPartition.map &#123;</span><br><span class="line">        <span class="keyword">case</span> (topicAndPartition, messageSet) =&gt;</span><br><span class="line">          (topicAndPartition -&gt; <span class="keyword">new</span> <span class="type">PartitionResponse</span>(<span class="type">Errors</span>.<span class="type">INVALID_REQUIRED_ACKS</span>.code,</span><br><span class="line">                                                      <span class="type">LogAppendInfo</span>.<span class="type">UnknownLogAppendInfo</span>.firstOffset,</span><br><span class="line">                                                      <span class="type">Message</span>.<span class="type">NoTimestamp</span>))</span><br><span class="line">      &#125;</span><br><span class="line">      responseCallback(responseStatus)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></p><h3 id="Log-Subsystem"><a href="#Log-Subsystem" class="headerlink" title="Log Subsystem"></a>Log Subsystem</h3><p>LogManager负责管理Kafka的Log(Kafka消息)， 包括log/Log文件夹的创建，获取和清理。它也会通过定时器检查内存中的log是否要缓存到磁盘中。重要的类包括LogManager和Log。</p><h3 id="OffsetManager"><a href="#OffsetManager" class="headerlink" title="OffsetManager"></a>OffsetManager</h3><p>负责管理offset，提供offset的读写。</p><h3 id="TopicConfigManager"><a href="#TopicConfigManager" class="headerlink" title="TopicConfigManager"></a>TopicConfigManager</h3><p>它负责动态改变Topic的配置属性。<br>如果某个topic的配置属性改变了，Kafka会在ZooKeeper上创建一个类似/brokers/config_changes/config_change_13321的节点， topicConfigManager会监控这些节点， 获得属性改变的topics并处理,实际上以新的LogConfig替换老的</p><h2 id="RequestChannel"><a href="#RequestChannel" class="headerlink" title="RequestChannel"></a>RequestChannel</h2><p>在Kafka的网络通信层中，RequestChannel为Processor处理器线程与KafkaRequestHandler线程之间的数据交换提供了一个数据缓冲区，是通信过程中Request和Response缓存的地方。因此，其作用就是在通信中起到了一个数据缓冲队列的作用。Processor线程将读取到的请求添加至RequestChannel的全局请求队列—requestQueue中；KafkaRequestHandler线程从请求队列中获取并处理，处理完以后将Response添加至RequestChannel的响应队列—responseQueue中，并通过responseListeners唤醒对应的Processor线程，最后Processor线程从响应队列中取出后发送至客户端。</p><p>到这里为止，一个请求从 Processor 接收，到 KafkaRequestHandler 通过 KafkaApis 处理并放回该 Processor 对应的 response queue 这整个过程就完成了（建议阅读本文的时候结合最前面的流程图一起看）。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://cloud.tencent.com/developer/article/1329040" title="消息中间件—简谈Kafka中的NIO网络通信模型" target="_blank" rel="noopener">消息中间件—简谈Kafka中的NIO网络通信模型</a></p><p><a href="https://bbs.huaweicloud.com/blogs/4d192a25ea1311e79fc57ca23e93a89f" title="kafka源码解析之八：Broker分析" target="_blank" rel="noopener">kafka源码解析之八：Broker分析</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;开源分布式消息队列—Kafka，具备高吞吐量和高并发的特性，其网络通信层是如何做到消息的高效传输的呢？为了解开自己心中的疑虑，就查阅了Kafka的Network通信模块的源码，乘机会写本篇文章。&lt;br&gt; 本文主要通过对Kafka源码的分析来简述其Reactor的多线程网络通
      
    
    </summary>
    
      <category term="大数据" scheme="http://yoursite.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="kafka" scheme="http://yoursite.com/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://yoursite.com/2018/11/24/hello-world/"/>
    <id>http://yoursite.com/2018/11/24/hello-world/</id>
    <published>2018-11-24T10:23:51.900Z</published>
    <updated>2018-11-24T10:23:51.902Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
    
  </entry>
  
</feed>
