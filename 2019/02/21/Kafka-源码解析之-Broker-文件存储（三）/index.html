<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="记录技术路上的点滴"><title>Kafka-源码解析之-Broker文件存储（三） | Steffen's Blog</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.3.1/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Kafka-源码解析之-Broker文件存储（三）</h1><a id="logo" href="/.">Steffen's Blog</a><p class="description">唐良运</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Kafka-源码解析之-Broker文件存储（三）</h1><div class="post-meta">Feb 21, 2019<span> | </span><span class="category"><a href="/categories/大数据/">大数据</a></span></div><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#一、Kafka结构层级概述"><span class="toc-number">1.</span> <span class="toc-text">一、Kafka结构层级概述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#二、Kafka文件存储机制分析"><span class="toc-number">2.</span> <span class="toc-text">二、Kafka文件存储机制分析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-topic中partition存储分布"><span class="toc-number">2.1.</span> <span class="toc-text">2.1 topic中partition存储分布</span></a></li></ol></li></ol></div></div><div class="post-content"><h2 id="一、Kafka结构层级概述"><a href="#一、Kafka结构层级概述" class="headerlink" title="一、Kafka结构层级概述"></a>一、Kafka结构层级概述</h2><p><strong>摘要：消息存储对于每一款消息队列都非常重要，那么Kafka在这方面是如何来设计做到高效的呢？</strong></p>
<p>  Kafka这款分布式消息队列<strong>使用文件系统和操作系统的页缓存（page cache）分别存储和缓存消息</strong>，摒弃了Java的堆缓存机制，同时<strong>将随机写操作改为顺序写</strong>，再<strong>结合Zero-Copy的特性</strong>极大地改善了IO性能。<br>  而提起磁盘的文件系统，相信很多对硬盘存储了解的同学都知道：“一块SATA RAID-5阵列磁盘的线性写速度可以达到几百M/s，而随机写的速度只能是100多KB/s，线性写的速度是随机写的上千倍”，由此可以看出对磁盘写消息的速度快慢关键还是取决于我们的使用方法。<br>  鉴于此，Kafka的数据存储设计是建立在对文件进行追加的基础上实现的，因为是顺序追加，通过O(1)的磁盘数据结构即可提供消息的持久化，并且这种结构对于即使是数以TB级别的消息存储也能够保持长时间的稳定性能。在理想情况下，只要磁盘空间足够大就一直可以追加消息。此外，Kafka也能够通过配置让用户自己决定已经落盘的持久化消息保存的时间，提供消息处理更为灵活的方式。</p>
<p>下面将从Kafka文件存储机制和物理结构角度，分析Kafka是如何实现高效文件存储，及实际应用效果。</p>
<p>Kafka部分名词解释如下：</p>
<ul>
<li>（1）Broker：消息中间件处理节点，一个Kafka节点就是一个broker，一个或者多个Broker可以组成一个Kafka集群；</li>
<li>（2）Topic：主题是对一组消息的抽象分类，比如例如page view日志、click日志等都可以以topic的形式进行抽象划分类别。在物理上，不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可使得数据的生产者或消费者不必关心数据存于何处；</li>
<li>（3）Partition：每个主题又被分成一个或者若干个分区（Partition）。每个分区在本地磁盘上对应一个文件夹，分区命名规则为主题名称后接“—”连接符，之后再接分区编号，分区编号从0开始至分区总数减-1；</li>
<li>（4）LogSegment：每个分区又被划分为多个日志分段（LogSegment）组成，日志段是Kafka日志对象分片的最小单位；LogSegment算是一个逻辑概念，对应一个具体的日志文件（“.log”的数据文件）和一个索引文件（“.index”，表示偏移量索引文件）组成；日志文件是一个包含FileMessageSet的文件集实际的消息。索引文件是一个OffsetIndex，它从逻辑偏移量映射到物理文件位置。每个段都有一个基偏移量baseOffset，基偏移量是这个段中的任何消息的最小偏移量，而且大于上一段中的任何偏移量。</li>
<li>（5）Offset：每个partition中都由一系列有序的、不可变的消息组成，这些消息被顺序地追加到partition中。每个消息都有一个连续的序列号称之为offset—偏移量，用于在partition内唯一标识消息（并不表示消息在磁盘上的物理位置）；</li>
<li>（6）Message：消息是Kafka中存储的最小最基本的单位，即为一个commit log，由一个固定长度的消息头和一个可变长度的消息体组成；</li>
</ul>
<h2 id="二、Kafka文件存储机制分析"><a href="#二、Kafka文件存储机制分析" class="headerlink" title="二、Kafka文件存储机制分析"></a>二、Kafka文件存储机制分析</h2><p>分析过程分为以下4个步骤：</p>
<ol>
<li>topic中partition存储分布</li>
<li>partiton中文件存储方式</li>
<li>partiton中segment文件存储结构</li>
<li>在partition中如何通过offset查找message</li>
</ol>
<p>通过上述4过程详细分析，我们就可以清楚认识到kafka文件存储机制的奥秘。</p>
<h3 id="2-1-topic中partition存储分布"><a href="#2-1-topic中partition存储分布" class="headerlink" title="2.1 topic中partition存储分布"></a>2.1 topic中partition存储分布</h3><p>在三台虚拟机上搭建完成Kafka的集群后（Kafka Broker节点数量为3个），通过在Kafka Broker节点的/bin下执行以下的命令即可创建主题和指定数量的分区以及副本：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./kafka-topics --create --zookeeper <span class="number">127.0</span>.0.1:<span class="number">2181</span> --replication-factor <span class="number">3</span> --partitions  <span class="number">3</span> --topic CommPair</span><br></pre></td></tr></table></figure>
<p>创建完主题、分区和副本后可以查到出主题的状态（该方式主要列举了主题所有分区对应的副本以及ISR列表信息）：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">./kafka-topics --describe --zookeeper <span class="number">127.0</span>.0.1:<span class="number">2181</span> --topic CommPair</span><br><span class="line">Topic:CommPair  PartitionCount:<span class="number">3</span>        ReplicationFactor:<span class="number">1</span>     Configs:</span><br><span class="line">        Topic: CommPair Partition: <span class="number">0</span>    Leader: <span class="number">60</span>      Replicas: <span class="number">60</span>    Isr: <span class="number">60</span></span><br><span class="line">        Topic: CommPair Partition: <span class="number">1</span>    Leader: <span class="number">62</span>      Replicas: <span class="number">62</span>    Isr: <span class="number">62</span></span><br><span class="line">        Topic: CommPair Partition: <span class="number">2</span>    Leader: <span class="number">60</span>      Replicas: <span class="number">60</span>    Isr: <span class="number">60</span></span><br></pre></td></tr></table></figure>
<p>通过在Kafka的config/server.properties配置文件中“log.dirs”指定的日志数据存储目录下存在三个分区目录，同时在每个分区目录下存在很多对应的日志数据文件和日志索引文件文件，具体如下：</p>
<p>1、分区目录文件<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">drwxr-x--- <span class="number">2</span> root root <span class="number">4096</span> Jul <span class="number">26</span> <span class="number">19</span>:<span class="number">35</span> CommPair-<span class="number">0</span></span><br><span class="line">drwxr-x--- <span class="number">2</span> root root <span class="number">4096</span> Jul <span class="number">24</span> <span class="number">20</span>:<span class="number">15</span> CommPair-<span class="number">1</span></span><br><span class="line">drwxr-x--- <span class="number">2</span> root root <span class="number">4096</span> Jul <span class="number">24</span> <span class="number">20</span>:<span class="number">15</span> CommPair-<span class="number">2</span></span><br></pre></td></tr></table></figure></p>
<p>2、分区目录中的日志数据文件和日志索引文件<br><img src="/2019/02/21/Kafka-源码解析之-Broker-文件存储（三）/segment.png" alt="kafka数据文件和索引文件"></p>
<p>由上面可以看出，每个分区在物理上对应一个文件夹，分区的命名规则为主题名后接“—”连接符，之后再接分区编号，分区编号从0开始，编号的最大值为分区总数减1。每个分区又有1至多个副本，分区的副本分布在集群的不同代理上，以提高可用性。从存储的角度上来说，分区的每个副本在逻辑上可以抽象为一个日志（Log）对象，即分区副本与日志对象是相对应的。</p>
<ul>
<li>每个partion(目录)相当于一个巨型文件被平均分配到多个大小相等segment(段)数据文件中。但每个段segment file消息数量不一定相等，这种特性方便old segment file快速被删除。</li>
<li>每个partiton只需要支持顺序读写就行了，segment文件生命周期由服务端配置参数决定。</li>
</ul>
<p>这样做的好处就是能快速删除无用文件，有效提高磁盘利用率。</p>
<p>下图是在三个Kafka Broker节点所组成的集群中分区的主/备份副本的物理分布情况图：<br><img src="/2019/02/21/Kafka-源码解析之-Broker-文件存储（三）/kafka副本分区分布.png" alt="kafka副本分区分布"></p>
<p>为了进一步查看“.index”偏移量索引文件、“.log”日志数据文件，可以执行下面的命令将二进制分段的索引和日志数据文件内容转换为字符型文件：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># 1、执行下面命令即可将日志数据文件内容dump出来</span><br><span class="line">###kafka-run-class kafka.tools.DumpLogSegments --files /data1/kafka/data/CommPair-0/00000000001050905938.index --print-data-log &gt; 00000000001050905938_txt.log</span><br><span class="line">###kafka-run-class kafka.tools.DumpLogSegments --files /data1/kafka/data/CommPair-0/00000000001050905938.log --print-data-log &gt; 00000000001050905938_txt.index</span><br><span class="line"></span><br><span class="line">#2、dump出来的具体日志数据内容</span><br><span class="line">###tail -20 00000000001050905938_txt.log</span><br><span class="line">Dumping /data1/kafka/data/CommPair-<span class="number">0</span>/<span class="number">00000000001050905938</span>.log</span><br><span class="line">Starting offset: <span class="number">1050905938</span></span><br><span class="line">offset: <span class="number">1050905938</span> position: <span class="number">0</span> isvalid: <span class="keyword">true</span> payloadsize: <span class="number">127</span> magic: <span class="number">1</span> compresscodec: NoCompressionCodec crc: <span class="number">2108247934</span> payload: <span class="number">00000102</span>-<span class="number">363</span>aa04e-<span class="number">4467</span>-<span class="number">41</span>a9-<span class="number">828</span>d-b131281ca9b6^<span class="number">2019</span>-<span class="number">01</span>-<span class="number">22</span> <span class="number">14</span>:<span class="number">15</span>:<span class="number">32</span>^<span class="number">2019</span>-<span class="number">01</span>-<span class="number">22</span> <span class="number">14</span>:<span class="number">21</span>:<span class="number">02</span>^UDP^<span class="number">172.16</span>.140.202^<span class="number">49633</span>^<span class="number">224.0</span>.0.252^<span class="number">5355</span></span><br><span class="line">...</span><br><span class="line">offset: <span class="number">1050906189</span> position: <span class="number">37479</span> isvalid: <span class="keyword">true</span> payloadsize: <span class="number">126</span> magic: <span class="number">1</span> compresscodec: NoCompressionCodec crc: <span class="number">2291970542</span> payload: <span class="number">00000102</span>-<span class="number">363</span>aa04e-<span class="number">4467</span>-<span class="number">41</span>a9-<span class="number">828</span>d-b131281ca9b6^<span class="number">2019</span>-<span class="number">01</span>-<span class="number">22</span> <span class="number">14</span>:<span class="number">20</span>:<span class="number">04</span>^<span class="number">2019</span>-<span class="number">01</span>-<span class="number">22</span> <span class="number">14</span>:<span class="number">26</span>:<span class="number">03</span>^UDP^<span class="number">172.16</span>.140.41^<span class="number">54911</span>^<span class="number">224.0</span>.0.252^<span class="number">5355</span></span><br><span class="line"></span><br><span class="line">###tail -20 00000000001050905938_txt.index</span><br><span class="line">Dumping /data1/kafka/data/CommPair-<span class="number">0</span>/<span class="number">00000000001050905938</span>.index</span><br><span class="line">offset: <span class="number">1050906189</span> position: <span class="number">37479</span></span><br><span class="line">offset: <span class="number">1050906505</span> position: <span class="number">86271</span></span><br><span class="line">offset: <span class="number">1050906759</span> position: <span class="number">125398</span></span><br><span class="line">offset: <span class="number">1050907068</span> position: <span class="number">172701</span></span><br></pre></td></tr></table></figure></p>
<p>由上面dump出来的偏移量索引文件和日志数据文件的具体内容可以分析出来，偏移量索引文件中存储着大量的索引元数据，日志数据文件中存储着大量消息结构中的各个字段内容和消息体本身的值。索引文件中的元数据postion字段指向对应日志数据文件中message的实际位置（即为物理偏移地址）。</p>
<p>####1.日志数据文件</p>
<p>Kafka将生产者发送给它的消息数据内容保存至日志数据文件中，该文件以该段的基准偏移量左补齐0命名，文件后缀为“.log”。分区中的每条message由offset来表示它在这个分区中的偏移量，这个offset并不是该Message在分区中实际存储位置，而是逻辑上的一个值（Kafka中用8字节长度来记录这个偏移量），但它却唯一确定了分区中一条Message的逻辑位置，同一个分区下的消息偏移量按照顺序递增（这个可以类比下数据库的自增主键）。另外，从dump出来的日志数据文件的字符值中可以看到消息体的各个字段的内容值。</p>
<p>####2.偏移量索引文件</p>
<p>如果消息的消费者每次fetch都需要从1G大小（默认值）的日志数据文件中来查找对应偏移量的消息，那么效率一定非常低，在定位到分段后还需要顺序比对才能找到。Kafka在设计数据存储时，为了提高查找消息的效率，故而为分段后的每个日志数据文件均使用稀疏索引的方式建立索引，这样子既节省空间又能通过索引快速定位到日志数据文件中的消息内容。偏移量索引文件和数据文件一样也同样也以该段的基准偏移量左补齐0命名，文件后缀为“.index”。<br> 从上面dump出来的偏移量索引内容可以看出，索引条目用于将偏移量映射成为消息在日志数据文件中的实际物理位置，每个索引条目由offset和position组成，每个索引条目可以唯一确定在各个分区数据文件的一条消息。其中，Kafka采用稀疏索引存储的方式，每隔一定的字节数建立了一条索引，可以通过“index.interval.bytes”设置索引的跨度；<br> 有了偏移量索引文件，通过它，Kafka就能够根据指定的偏移量快速定位到消息的实际物理位置。具体的做法是，根据指定的偏移量，使用二分法查询定位出该偏移量对应的消息所在的分段索引文件和日志数据文件。然后通过二分查找法，继续查找出小于等于指定偏移量的最大偏移量，同时也得出了对应的position（实际物理位置），根据该物理位置在分段的日志数据文件中顺序扫描查找偏移量与指定偏移量相等的消息。下面是Kafka中分段的日志数据文件和偏移量索引文件的对应映射关系图（其中也说明了如何按照起始偏移量来定位到日志数据文件中的具体消息）。<br><img src="/2019/02/21/Kafka-源码解析之-Broker-文件存储（三）/index-data.png" alt="kafka索引文件与数据文件对应关系"></p>
<p>segment的索引文件中存储着大量的元数据，数据文件中存储着大量消息，索引文件中的元数据指向对应数据文件中的message的物理偏移地址。以索引文件中的3，497为例，在数据文件中表示第3个message（在全局partition表示第368772个message），以及该消息的物理偏移地址为497。</p>
<p>从上述图3了解到segment data file由许多message组成，下面详细说明message物理结构如下：<br><img src="/2019/02/21/Kafka-源码解析之-Broker-文件存储（三）/messgae.png" alt="kafka message物理结构"></p>
<p>参数说明：</p>
<p>关键字    解释说明<br>8 byte offset    在parition(分区)内的每条消息都有一个有序的id号，这个id号被称为偏移(offset),它可以唯一确定每条消息在parition(分区)内的位置。即offset表示partiion的第多少message<br>4 byte message size    message大小<br>4 byte CRC32    用crc32校验message<br>1 byte “magic”    表示本次发布Kafka服务程序协议版本号<br>1 byte “attributes”    表示为独立版本、或标识压缩类型、或编码类型。<br>4 byte key length    表示key的长度,当key为-1时，K byte key字段不填<br>K byte key    可选<br>value bytes payload    表示实际消息数据。</p>
<p>###2.4 在partition中如何通过offset查找message</p>
<p>例如读取offset=368776的message，需要通过下面2个步骤查找。</p>
<p>第一步查找segment file 上述图2为例，其中00000000000000000000.index表示最开始的文件，起始偏移量(offset)为0.第二个文件00000000000000368769.index的消息量起始偏移量为368770 = 368769 + 1.同样，第三个文件00000000000000737337.index的起始偏移量为737338=737337 + 1，其他后续文件依次类推，以起始偏移量命名并排序这些文件，只要根据offset <strong>二分查找</strong>文件列表，就可以快速定位到具体文件。 当offset=368776时定位到00000000000000368769.index|log</p>
<p>第二步通过segment file查找message 通过第一步定位到segment file，当offset=368776时，依次定位到00000000000000368769.index的元数据物理位置和00000000000000368769.log的物理偏移地址，然后再通过00000000000000368769.log顺序查找直到offset=368776为止。</p>
<p>从上述图3可知这样做的优点，segment index file采取稀疏索引存储方式，它减少索引文件大小，通过mmap可以直接内存操作，稀疏索引为数据文件的每个对应message设置一个元数据指针,它比稠密索引节省了更多的存储空间，但查找起来需要消耗更多的时间。</p>
<p>###总结<br>Kafka中读写message有如下特点:</p>
<p>写message</p>
<p>消息从java堆转入page cache(即物理内存)。<br>由异步线程刷盘,消息从page cache刷入磁盘。<br>读message</p>
<p>消息直接从page cache转入socket发送出去。<br>当从page cache没有找到相应数据时，此时会产生磁盘IO,从磁 盘Load消息到page cache,然后直接从socket发出去<br>Kafka高效文件存储设计特点</p>
<p>Kafka把topic中一个parition大文件分成多个小文件段，通过多个小文件段，就容易定期清除或删除已经消费完文件，减少磁盘占用。<br>通过索引信息可以快速定位message和确定response的最大大小。<br>通过index元数据全部映射到memory，可以避免segment file的IO磁盘操作。<br>通过索引文件稀疏存储，可以大幅降低index文件元数据占用空间大小。</p>
<p>###参考：</p>
<ul>
<li><a href="https://tech.meituan.com/2015/01/13/kafka-fs-design-theory.html" title="Kafka文件存储机制那些事" target="_blank" rel="noopener">Kafka文件存储机制那些事</a></li>
<li><a href="http://matt33.com/2016/03/08/kafka-store/" title="Kafka之数据存储" target="_blank" rel="noopener">Kafka之数据存储</a></li>
<li><a href="https://blog.csdn.net/jewes/article/details/42970799" title="Kafka的Log存储解析" target="_blank" rel="noopener">Kafka的Log存储解析</a></li>
<li><a href="https://cloud.tencent.com/developer/article/1329038" title="消息中间件—Kafka数据存储（一）" target="_blank" rel="noopener">消息中间件—Kafka数据存储（一）</a></li>
</ul>
</div><div class="tags"><a href="/tags/kafka/">kafka</a></div><div class="post-nav"><a class="next" href="/2018/11/26/Kafka-最佳实践之-Producer-性能调优（二）/">Kafka-最佳实践之-Producer-性能调优（二）</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.baidu.com/baidu" method="get" accept-charset="utf-8" target="_blank"><input type="search" name="word" maxlength="20" placeholder="Search"><input type="hidden" name="si" value="http://yoursite.com"><input name="tn" type="hidden" value="bds"><input name="cl" type="hidden" value="3"><input name="ct" type="hidden" value="2097152"><input name="s" type="hidden" value="on"></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/大数据/">大数据</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/kafka/" style="font-size: 15px;">kafka</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/02/21/Kafka-源码解析之-Broker-文件存储（三）/">Kafka-源码解析之-Broker文件存储（三）</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/26/Kafka-最佳实践之-Producer-性能调优（二）/">Kafka-最佳实践之-Producer-性能调优（二）</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/26/Kafka-最佳实践之-Broker-性能调优（一）/">Kafka-最佳实践之-Broker-性能调优（一）</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/26/Kafka-源码解析之-Producer-NIO网络模型（二）/">Kafka-源码解析之-Producer NIO网络模型（二）</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/24/Kafka-源码解析之-Server-1-N-M-网络处理模型（一）/">Kafka 源码解析之 Server 1+N+M 网络处理模型（一）</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://tech.meituan.com/" title="美团技术博客" target="_blank">美团技术博客</a><ul></ul><a href="http://jm.taobao.org/categories/" title="阿里中间件团队博客" target="_blank">阿里中间件团队博客</a><ul></ul><a href="http://lxw1234.com/" title="lxw的技术天地" target="_blank">lxw的技术天地</a><ul></ul><a href="http://hbasefly.com/" title="范欣欣~有态度的HBase" target="_blank">范欣欣~有态度的HBase</a><ul></ul><a href="http://orchome.com" title="Kafka技术博客~OrcHome" target="_blank">Kafka技术博客~OrcHome</a><ul></ul><a href="http://cwiki.apachecn.org/pages/viewpage.action?pageId=4260364" title="Elasticsearch 5.4 中文文档" target="_blank">Elasticsearch 5.4 中文文档</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2019 <a href="/." rel="nofollow">Steffen's Blog.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>